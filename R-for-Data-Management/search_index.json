[["index.html", "Data Management with R Prerequisites", " Data Management with R Dae Ho Kim 2020-12-06 Prerequisites This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). The bookdown package can be installed from CRAN or Github: install.packages(&quot;bookdown&quot;) # or the development version # devtools::install_github(&quot;rstudio/bookdown&quot;) Remember each Rmd file contains one and only one chapter, and a chapter is defined by the first-level heading #. To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],["data-import.html", "Chapter 1 Data Import and Export 1.1 Data Import 1.2 Data Export 1.3 Read Tabular Data의 보충설명", " Chapter 1 Data Import and Export 1.1 Data Import 1.1.1 준비하기 이 장에서는 tidyverse 의 핵심 구성요소인 readr 패키지를 사용하여 플랫 파일을 불러오는 방법을 학습한다. # install.packages(&quot;tidyverse&quot;) library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.0 -- ##  ggplot2 3.3.2  purrr 0.3.4 ##  tibble 3.0.4  dplyr 1.0.2 ##  tidyr 1.1.2  stringr 1.4.0 ##  readr 1.4.0  forcats 0.5.0 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() 1.1.2 시작하기 readr패키지의 함수 대부분은 플랫 파일을 데이터 프레임(엄밀히 말하면 tibble)으로 바꾸는 것과 연관이 있다. read_csv() 는 쉼표(,)로 구분된 파일을 읽고, read_tsv() 는 탭-구분 파일을 읽는다. read_delim()은 임의의 구분자로 된 파일을 읽는다. read_fwf() 는 고정 너비 파일을 읽는다. 필드 너비는 fwf_widths() 를 이용하여, 필드 위치는 fwf_positions() 를 이용하여 지정할 수 있다. read_table() 은 고정 너비 파일의 일반적 변형 형태인 열이 공백으로 구분된 파일을 읽는다. read_log() 는 Apache 스타일의 로그 파일을 읽는다. (하지만 read_log() 기반으로 구축되어 더 많은 유용한 도구를 제공하는 webreadr 도 확인하라.) 이 함수들은 문법이 모두 비슷하다. 하나를 익히면 나머지는 쉽게 사용할 수 있다. 이 장의 나머지 부분에서는 read_csv()에 초점을 맞출 것이다. CSV 파일은 가장 일반적인 형태의 데이터 저장 형태일 뿐 아니라 read_csv() 를 이해하면 readr 의 다른 모든 함수에 쉽게 적용할 수 있다. 1.1.2.1 첫 번째 인수 : 불러올 파일 경로 지정 read_csv() 의 첫 번째 인수가 가장 중요한데 바로 불러올 파일의 경로다. heights &lt;- read_csv(&quot;data1/heights.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## earn = col_double(), ## height = col_double(), ## sex = col_character(), ## ed = col_double(), ## age = col_double(), ## race = col_character() ## ) heights ## # A tibble: 1,192 x 6 ## earn height sex ed age race ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 50000 74.4 male 16 45 white ## 2 60000 65.5 female 16 58 white ## 3 30000 63.6 female 16 29 white ## 4 50000 63.1 female 16 91 other ## 5 51000 63.4 female 17 39 white ## 6 9000 64.4 female 15 26 white ## 7 29000 61.7 female 12 49 white ## 8 32000 72.7 male 17 46 white ## 9 2000 72.0 male 15 21 hispanic ## 10 27000 72.2 male 12 26 white ## # ... with 1,182 more rows read_csv()를 실행하면 각 열의 이름과 유형을 제공하는 ‘열 사양, cols’이 화면 출력된다. 이는 readr 패키지에서 중요한 부분이다. 파일 파싱하기에서 다시 살펴보겠다. 인라인(in-line) CSV 파일이 첫 번째 인수가 될 수도 있다. 이것은 readr 로 실험해 볼 때와 다른 사람들과 공유할 재현 가능한 예제를 만들 때 유용하다. read_csv(&quot;a,b,c 1,2,3 4,5,6&quot;) ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 1.1.2.2 다른 인수들 1.1.2.2.1 skip = 인수와 comment = 인수 : 메타 데이터 지정 두 경우 모두 read_csv() 는 데이터의 첫 번째 줄을 “열 이름”으로 사용한다. 이는 매우 일반적인 규칙이다. 이 동작을 조정해야 하는 경우는 두 가지이다. 파일 앞 부분에 ** 메타 데이터가 몇 줄이 있는 경우**가 있다. skip = n 을 사용하여 첫 n 줄을 건너 뛸 수 있다. 또는 comment = \"#\" 을 사용하여 # 으로 시작하는 모든 줄을 무시할 수 있다. read_csv(&quot;메타 데이터 첫번째 행 메타 데이터 두번째 행 x,y,z 1,2,3&quot;, skip = 2) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 skip = 2로 인해 첫 두 줄은 데이터로 읽혀지지 않았음을 알 수 있다. read_csv(&quot;# 건너뛰고 싶은 주석 x,y,z 1,2,3&quot;, comment = &quot;#&quot;) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 comment = “#”로 인해, 첫째 줄의 내용이 데이터로 읽혀지지 않았음을 알 수 있다. 1.1.2.2.2 col_names = 인수 : 첫 줄의 컬럼 제목 사용여부 데이터에 열 이름이 없을 수 있다. col_names = FALSE 를 사용하면 read_csv()가 첫 행을 헤드로 취급하지 않고 대신 X1에서 Xn까지 순차적으로 컬럼 이름을 붙인다. read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = FALSE) ## # A tibble: 2 x 3 ## X1 X2 X3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 read_csv(&quot;1,2,3\\n4,5,6&quot;, col_names = c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;)) ## # A tibble: 2 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 6 (\"\\n\" 은 새 줄을 추가하는 편리한 단축키이다. 이 때, 컬럼 제목은 지정이 되지 않았기 때문에, 자동으로 X1, X2, X3라고 부여된다. 다른 방법으로는 col_names 에 열 이름으로 사용할 문자형 벡터를 전달할 수도 있다. 1.1.2.2.3 na = 인수 : 결측값의 처리 방법 일반적으로 조정이 필요한 또 다른 옵션은 na 이다. 파일에서 결측값을 나타내는데 사용되는 값(들)을 지정한다. read_csv(&quot;a,b,c\\n1,2,.&quot;, na = &quot;.&quot;) ## # A tibble: 1 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 1 2 NA 여기까지 배운 것들로 실제로 마주하게 될 CSV 파일의 75% 정도를 불러올 수 있다. 또한 탭으로 구분된 파일을 read_tsv() 를 사용하여, 혹은 고정간격 파일을 read_fwf() 를 사용하여 불러오는 데도 쉽게 적용할 수 있다. 더 복잡한 파일을 읽으려면 readr 이 각 열을 파싱하여 R 벡터로 바꾸는 방법에 대해 자세히 배워야한다. 1.1.2.3 base R과 비교 R을 이전에 사용한 사람은 우리가 read.csv() 를 사용하지 않는 이유가 궁금할 것이다. base 패키지의 함수보다 readr패키지의 함수가 좋은 이유는 다음과 같다. 일반적으로 base 함수보다 훨씬 더(~10배) 빠르다. 오래 걸리는 작업은 진행 표시줄을 통해 상황을 알 수 있다. raw speed로 작업하려면 data.table::fread() 를 사용해보라. 이 함수는 tidyverse 에 잘 어울리지는 않지만, 훨씬 더 빠를 수 있다. 티블(tibble)을 생성한다. 문자 벡터를 팩터형으로 변환하지도, 행 이름을 사용하거 나 열 이름을 변경하지도 않는다. base R 함수는 변환, 변경하기 때문에 늘 불편하다. (R version 4.0 이후에는 factor 변환은 옵션임) 좀 더 재현 가능하다. base R 함수는 운영체제 및 환경 변수의 일부 동작을 상속하므로 자신의 컴퓨터에서 작동하는 불러오기 코드가 다른 사람의 컴퓨터에서 작동하지 않을 수 있다. 1.1.2.4 다른 함수들의 이용은 [별도의 파일 참고…] 1.1.2.5 연습문제 필드(데이터 항목)가 “|” 로 분리된 파일을 읽으려면 어떤 함수를 사용하겠는가? {-} delim=\"|\"를 인수로 하는 read_delim() 함수를 사용한다. file &lt;- &quot;data1/dates_delimeter.csv&quot; read_delim(file, delim = &quot;|&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## fmt1 = col_character(), ## fmt2 = col_character(), ## fmt3 = col_date(format = &quot;&quot;), ## fmt4 = col_double(), ## decision_time = col_character() ## ) ## # A tibble: 3 x 5 ## fmt1 fmt2 fmt3 fmt4 decision_time ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 01/15/89 December 8, 2015 2015-02-27 20090101 Approved 10-10-15 07:15:55 ## 2 02/13/92 January 22, 2012 2016-11-15 20080819 Denied 09-27-11 14:57:23 ## 3 03/15/84 March 3, 2010 2017-12-25 20071011 Approved 04-24-15 02:03:03 ** data 디렉토리의 dates_delimeter1.csv ~ dates_delimeter5.csv 파일들도 연습해 보기 바람. ** read_csv() 와 read_tsv() 가 공통으로 가진 인수는 file, skip, comment 외에 또 무엇이 있는가? 두 함수의 공통 인수를 찾기 위해 다음을 수행한다. union(names(formals(read_csv)), names(formals(read_tsv))) ## [1] &quot;file&quot; &quot;col_names&quot; &quot;col_types&quot; &quot;locale&quot; ## [5] &quot;na&quot; &quot;quoted_na&quot; &quot;quote&quot; &quot;comment&quot; ## [9] &quot;trim_ws&quot; &quot;skip&quot; &quot;n_max&quot; &quot;guess_max&quot; ## [13] &quot;progress&quot; &quot;skip_empty_rows&quot; col_names 와 col_types : 컬럼 이름을 지정과 그 컬럼을 어떻게 parse할 지를 지정한다. locale : 인코딩과 관련한 것들의 지정 또 십진수 표시를 “,”로 할 찌 “.”으로 할 지의 지정에 사용된다. na 와 quoted_na : 벡터를 파싱할 때 어떤 문자열이 결측치로 처리될 지를 지정한다. trim_ws : 파싱하기 전에 셀의 앞 뒤로 공백문자를 제거 n_max : 읽어 들일 행의 갯수 지정 guess_max : 컬럼 형을 추측할 때 몇 개의 행을 사용할 지를 지정 progress : 진행 막대를 표시할 지를 결정 read_fwf() 에서 가장 중요한 인수는 무엇인가? 고정너비 형식의 파일을 불러오는 read_fwf()의 가장 중요한 인수는 데이터 열의 시작과 끝을 함수에게 알려주는 col_position= 인수이다. CSV 파일의 문자열에 쉼표가 포함되는 경우가 있다. 그것들이 문제를 일으 키지 않게 하려면 \" 혹은 '와 같은 인용 문자로 둘러싸일 필요가 있다. read_csv() 는 인용 문자가 \"라고 가정한다. 이를 변경하려면 read_delim() 을 대신 사용하면 된다. 다음 텍스트를 데이터프레임으로 읽으려면 어떤 인수를 설정해야하는가? x &lt;- &quot;x,y\\n1,&#39;a,b&#39;&quot; read_delim(x, &quot;,&quot;, quote = &quot;&#39;&quot;) ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a,b read_delim()함수를 사용하려면, 구분자를 지정해야 한다. 이 경우의 구분자는 “,”이며, quote =인수의 값은 “‘“. x &lt;- &quot;x,y\\n1,&#39;a,b&#39;&quot; read_delim(x, &quot;,&quot;, quote = &quot;&#39;&quot;) ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a,b x를 “,” 기호로 데이터 요소들을 구분하고, 문자열 데이터는 “'\" 로 묶여 있음(quote=\"'\")을 지정한다. x, y : 컬럼 제목 x와 y \\n : 줄 바꾸기 1, ‘a,b’ : 데이터 요소로 1과 a,b 다음 각 인라인 CSV 파일에 어떤 문제가 있는지 확인하라. 코드를 실행하면 어떻게 되는가? read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 -- 2 columns 3 columns literal data ## 2 -- 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 4 5 read_csv(&quot;a,b,c\\n1,2\\n1,2,3,4&quot;) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 -- 3 columns 2 columns literal data ## 2 -- 3 columns 4 columns literal data ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 NA ## 2 1 2 3 read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 a closing quote at end of file literal data ## 1 -- 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv2(&quot;a;b\\n1;3&quot;) ## i Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use `read_delim()` for more control. ## # A tibble: 1 x 2 ## a b ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3 두 개의 열만 “a”와 “b”라는 헤더가 있는데, 데이터 요소는 3개이다. 따라서 마지막 요소의 값은 자동 삭제가 된다. read_csv(&quot;a,b\\n1,2,3\\n4,5,6&quot;) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 -- 2 columns 3 columns literal data ## 2 -- 2 columns 3 columns literal data ## # A tibble: 2 x 2 ## a b ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 ## 2 4 5 셋 째의 경우는 의도가 분명치 않다. \"1 은 삭제되는데, 이는 “로 닫히지 않았기 때문이다 그리고 a컬럼은 정수형으로 처리된다. read_csv(&quot;a,b\\n\\&quot;1&quot;) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 a closing quote at end of file literal data ## 1 -- 2 columns 1 columns literal data ## # A tibble: 1 x 2 ## a b ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 &lt;NA&gt; “a”와 “b” 모두는 비수치 문자열을 포함하고 있기 때문에 모두 문자 벡터로 처리된다. 이는 의도적으로 각각의 열에 “1,2”와 “a,b” 값을 할당하는 것이다. read_csv(&quot;a,b\\n1,2\\na,b&quot;) ## # A tibble: 2 x 2 ## a b ## &lt;chr&gt; &lt;chr&gt; ## 1 1 2 ## 2 a b 데이터가 컴마(,)가 아닌 세미콜론(;)으로 구분되어 있으면, read_csv2()함수를 이용한다: read_csv(&quot;a;b\\n1;3&quot;) ## # A tibble: 1 x 1 ## `a;b` ## &lt;chr&gt; ## 1 1;3 read_csv2(&quot;a;b\\n1;3&quot;) ## i Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use `read_delim()` for more control. ## # A tibble: 1 x 2 ## a b ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3 첫 번째의 경우, read_csv() 함수는 a;b가 컬럼 제목이고, 1;3은 이 컬럼의 데이터인 것으로 읽는다. 두 번째의 경우, read_csv2() 함수는 데이터 구분자로 세미콜론(;)을 사용하기 때문에, a;b는 a컬럼과 b컬럼으로, 1;3은 이 컬럼의 데이터로 1과 3인 것으로 읽는다. 1.1.3 벡터 파싱하기 readr이 디스크에서 파일을 읽는 방법에 대해 깊이 알아보기 전에, 잠깐 벗어나서 parse_*() 함수에 대해 살펴볼 필요가 있다. 1.1.3.1 파싱 함수의 사용 예 이 함수들은 문자형 벡터를 입력으로 하여 논리형, 정수형 또는 날짜형과 같은 좀 더 특수화된 벡터를 반환한다. 1.1.3.1.1 문자형 벡터를 논리형 벡터로 파싱하기. a &lt;- (parse_logical(c(&quot;TRUE&quot;, &quot;FALSE&quot;, &quot;NA&quot;))) a ## [1] TRUE FALSE NA class(a) ## [1] &quot;logical&quot; str(a) ## logi [1:3] TRUE FALSE NA 문자열 데이터 c(\"TRUE\", \"FALSE\", \"NA\")를 parse_logical() 함수가 논리형(logical)으로 변환해 준다. 1.1.3.1.2 문자형 벡터를 숫자형 벡터로 파싱하기 b &lt;- parse_integer(c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)) b ## [1] 1 2 3 class(b) ## [1] &quot;integer&quot; str(b) ## int [1:3] 1 2 3 문자열 데이터 c(\"1\", \"2\", \"3\")을 parse_integer() 함수가 정수형(integer)으로 변환해 준다. 1.1.3.1.3 문자형 벡터를 날짜형 벡터로 파싱하기 c &lt;- parse_date(c(&quot;2010-01-01&quot;, &quot;1979-10-14&quot;)) c ## [1] &quot;2010-01-01&quot; &quot;1979-10-14&quot; class(c) ## [1] &quot;Date&quot; str(c) ## Date[1:2], format: &quot;2010-01-01&quot; &quot;1979-10-14&quot; 문자열 데이터 c(\"2010-01-01\", \"1979-10-14\")을 parse_date() 함수가 날짜형(Date)으로 변환해 준다. 1.1.3.2 파서 함수의 인수 사용 예 tidyverse의 모든 함수와 마찬가지로, parse_*() 함수는 동일한 형태이다. 즉, 첫 번째 인수는 파싱할 문자형 벡터이며 NA = 인수는 결측값으로 처리되어야 하는 문자열을 지정한다. parse_integer(c(&quot;1&quot;, &quot;231&quot;, &quot;.&quot;, &quot;456&quot;), na = &quot;.&quot;) ## [1] 1 231 NA 456 파싱에 실패하면 경고 메시지가 나타난다. x &lt;- parse_integer(c(&quot;123&quot;, &quot;345&quot;, &quot;abc&quot;, &quot;123.45&quot;)) ## Warning: 2 parsing failures. ## row col expected actual ## 3 -- an integer abc ## 4 -- no trailing characters 123.45 3번째 요소(3)의 경우 정수형이어야 하는데 “abc”로 입력되었음을 경고함. 4번째 요소(4)의 경우 허락되지 않는 문자가 따라와서 .45를 경고함. 이런 경우에는 출력에서 누락될 것이다. x ## [1] 123 345 NA NA ## attr(,&quot;problems&quot;) ## # A tibble: 2 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 3 NA an integer abc ## 2 4 NA no trailing characters 123.45 3번째와 4번째 행의 요소의 경우, 결측치(NA)로 처리됨을 알 수 있다. problem() 함수의 활용 파싱에 실패한 경우가 많으면 problems() 를 사용하여 실패 전체를 가져와야 한다. problems() 이 반환한 티블(tibble)을 dplyr로 작업할 수 있다. problems(x) ## # A tibble: 2 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 3 NA an integer abc ## 2 4 NA no trailing characters 123.45 1.1.3.3 파서 함수의 종류 이 함수들은 독립적으로도 유용하지만, readr 패키지의 중요한 구성요소이기도 하다. 이 절에서는 개별 파서(parser)가 어떻게 동작하는지를 우선 배우고, 다음 절에서 개별 파서들이 어떻게 구성되어 파일 전체를 파싱하는지 살펴볼 것이다. 파서를 잘 활용하려면, 어떤 종류가 있는지, 각종 입력 유형을 어떻게 다루는지를 잘 이해해야 한다. 위의 그림에서 보듯이 특별히 중요한 8개의 파서 함수가 있다. parse_logical() 과 parse_integer() 는 각각 논리형 및 정수형을 파싱한다. 기본적으로 이 파서에 잘못될 수 있는 것은 없으므로 여기서 더 설명하지 않겠다. parse_double() 은 엄격한 수치형 파서이고, parse_number() 는 유연한 수치형 파서이다. 이들은 예상보다 더 복잡하다. 왜냐하면 세계 여러 지역이 각자 다른 방식으로 숫자를 쓰기 때문이다. parse_character() 는 너무 단순해서 필요 없을 것 같다고 생각할지도 모른다. 그러나 어떤 복잡성 때문에 이 파서가 매우 중요하다. 바로 문자 인코딩이 그것이다. parse_factor() 는 팩터형을 생성하는데, 팩터형은 R이 미리 정해지고 알려진 값으로 범주형 변수를 나타내기 위해 사용하는 데이터 구조이다. parse_datetime() , parse_date() , parse_time() 을 사용하면 다양한 날짜와 시간 데이터를 파싱할 수 있다. 날짜를 쓰는 방법은 다양하기 때문에 이 함수들이 가장 복잡하다. 다음 절들에서 더 자세히 살펴보기로 하자. 1.1.3.4 숫자 파싱 숫자 파싱하는 것은 간단한 것처럼 보이지만, 까다로운 세 가지 문제가 있다. 세계 여러 지역에서 사람들은 숫자를 다르게 쓴다. 예를 들어, 어떤 국가에서는 실수의 정수 부분과 소수 부분 사이에 . 를 쓰고 다른 국가에서는 , 를 쓴다. (decimal_mark) 숫자는 ‘$1000,’ ‘10%’ 와 같이 단위를 나타내는 다른 문자가 붙어있을 때가 많다. 숫자는 ‘1,000,000’ 과 같이 쉽게 읽을 수 있도록 ‘그룹화’ 문자가 포함되는 경우가 많다. 이러한 그룹화 문자는 국가마다 다르다. (grouping_mark) 1.1.3.4.1 천 단위와 소숫점의 처리 첫 번째 문제를 해결하기 위해서 readr은 지역에 따라 파싱 옵션을 지정하는 객체인 ‘로캘(locale)’이라는 개념을 사용한다. 숫자를 파싱할 때 가장 중요한 옵션은 소수점으로 사용하는 문자이다. 새로운 로캘을 생성하고 decimal_mark 인수를 설정하여 기본값인 . 를 다른 값으로 재정의할 수 있다. 숫자의 파싱에 있어서, 천 단위(grouping mark)의 표시와 소숫점(decimal mark)의 표시가 지역에 따라 다름을 잘 알고 있어야 한다. parse_double(&quot;1.23&quot;) ## [1] 1.23 parse_double(&quot;1,23&quot;, locale = locale(decimal_mark = &quot;,&quot;)) ## [1] 1.23 readr 의 기본 로캘은 미국 중심인데, 왜냐하면 일반적으로 R 은 미국 중심이기 때문이다 (즉, base R의 문서가 미국식 영어로 작성되었다). 다른 방법은 운영체제의 기본값을 추측하여 시도하는 것이다. 이러한 방법은 잘 동작하지 않고, 더 중요한 것은 코드가 취약하게 된다. 자신의 컴퓨터에서 동작하더라도 코드를 다른 국가의 동료에게 이메일로 보낼 때 오류가 발생할 수 있다. 1.1.3.4.2 통화 및 백분율 처리 두 번째 문제를 처리하는 parse_number() 는 숫자 앞뒤의 숫자가 아닌 문자 (non-numeric character) 를 무시한다. 통화 및 백분율에 특히 유용하지만, 텍스트에 포함 된 숫자를 추출하는 데도 효과적이다. 화페 단위, %, 문자열 등을 모두 무시한다. parse_number(&quot;$100&quot;) ## [1] 100 parse_number(&quot;20%&quot;) ## [1] 20 parse_number(&quot;It cost $123.45&quot;) ## [1] 123.45 1.1.3.4.3 국가 및 대륙별 차이 마지막 문제는 parse_number() 와 locale= 인수를 조합하여, parse_number() 가 “.”을 무시하게(locale(grouping_mark = \".\") 함으로써 해결할 수 있다. 1.1.3.4.3.1 미주 방식 미주방식 : grouping mark는 ,, decimal mark는 .를 사용 parse_number(&quot;$123,456,789&quot;) ## [1] 123456789 1.1.3.4.3.2 유럽의 많은 국가 방식 미주방식 : grouping mark는 ., decimal mark는 ,를 사용 parse_number(&quot;123.456.789&quot;, locale = locale(grouping_mark = &quot;.&quot;)) ## [1] 123456789 1.1.3.4.3.3 스위스 방식 미주방식 : grouping mark는 ' 혹은 (공란), decimal mark는 .를 사용. parse_number(&quot;123&#39;456&#39;789&quot;, locale = locale(grouping_mark = &quot;&#39;&quot;)) ## [1] 123456789 1.1.3.4.4 decimal_mark와 grouping_mark의 관련성 소숫점 표시(decimal mark)와 그루핑 마크(grouping mark)를 같은 문자를 설정하면, locale은 에러를 발생한다: # locale(decimal_mark = &quot;.&quot;, grouping_mark = &quot;.&quot;) # – 에러: decimal_mark and grouping_mark must be different 추가정보: 경고메시지(들): In strsplit(info, “”) : 이 로케일에서는 입력문자열 3는 유효하지 않습니다 실행이 정지되었습니다 decimal mark와 grouping mark는 같은 부호를 사용하면 안됨. locale() ## &lt;locale&gt; ## Numbers: 123,456.78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM locale(decimal_mark = &quot;,&quot;) ## &lt;locale&gt; ## Numbers: 123.456,78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM locale(decimal_mark = &quot;.&quot;) ## &lt;locale&gt; ## Numbers: 123,456.78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM locale(grouping_mark = &quot;.&quot;) ## &lt;locale&gt; ## Numbers: 123.456,78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM locale(grouping_mark = &quot;,&quot;) ## &lt;locale&gt; ## Numbers: 123,456.78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM decima mark를 ,로 지정하면, 자동으로 grouping mark는 .으로 바뀐다. 반대의 경우도 마찬가지다. 1.1.3.5 문자열 파싱 1.1.3.5.1 문자의 ASCII 코드 parse_character() 는 정말 단순해 보인다. 입력을 단순히 반환하는 것 아닌가. 그런데 불행하게도 삶은 그렇게 호락호락하지 않다. 같은 문자열을 나타내는 방법은 여러 가지이다. 이게 무슨 이야기인지 이해하려면 컴퓨터가 문자열을 표시하는 방법에 대해 깊고 상세하게 들어가야 한다. R에서는 charToRaw() 를 사용하여 문자열의 기본 표현을 볼 수 있다. charToRaw(&quot;Hadley&quot;) ## [1] 48 61 64 6c 65 79 charToRaw(&quot;대한민국&quot;) ## [1] b4 eb c7 d1 b9 ce b1 b9 각 16진수값은 정보 바이트를 나타낸다. 예를 들면 48 은 H를 나타내고, 61 은 a 를 나타낸다. 영문은 글자 하나가 1 바이트 : 즉, H의 ASCII 코드는 48 한글은 글자 하나가 2 바이트 : 대의 ASCII 코드는 b4 eb가 된다. 1.1.3.5.2 16진수 코드의 인코딩 16진수 수치를 문자로 매핑하는 것을 인코딩이라고 하며, 앞의 인코딩은 ASCII 라고 한다. ASCII 는 정보 교환을 위한 미국 표준 코드(American Standard Code for Information Interchange)의 줄임말이며 따라서 영문자를 잘 표현한다. 영어가 아닌 다른 언어의 경우 더욱 복잡해진다. 컴퓨터 시대 초창기에는 비영어권 문자 인코딩을 위한 여러 표준 규격이 있었다. 문자열을 정확하게 해석하기 위해서는 값과 인코딩을 모두 알아야했다. 예를 들어 두 가지 일반적인 인코딩은 Latin1 (ISO-8859-1, 서유럽 언어들에서 사용)과 Latin2 (ISO-8859-2, 동유럽 언어들에서 사용)이다. Latin1에서 바이트 b1 은 ‘±’이지만, Latin2 에서는 ‘ą’이다! 다행히 오늘날에는 거의 모든 곳에서 지원되는 하나의 표준인 UTF-8이 있다. UTF-8 은 오늘날 인간이 사용하는 거의 모든 문자와 기타 기호들(예: 이모티콘)을 인코딩할 수 있다. readr 은 모든 곳에서 UTF-8 을 사용한다. 데이터를 읽을 때 UTF-8 이라고 가정하며, 쓸 때는 항상 사용한다. UTF-8 은 좋은 기본값이지만, 이를 인식하지 못하는 구형 시스템에서 생성된 데이터에 사용할 수 없다. 이런 상황이면 문자열을 화면 출력할 때 이상하게 보인다. 한 두 개의 문자만 엉망이 될 수도 있고, 완전히 외계어들을 볼 수도 있다. 다음의 예를 보자. x1 &lt;- &quot;El Ni\\xf1o was particularly bad this year&quot; x1 ## [1] &quot;El Ni\\xf1o was particularly bad this year&quot; x2 &lt;- &quot;\\x82\\xb1\\x82\\xf1\\x82\\xc9\\x82\\xbf\\x82\\xcd&quot; x2 ## [1] &quot;궞귪궸궭궼&quot; x3 &lt;- &quot;\\xb4\\xeb\\xc7\\xd1\\xb9\\xce\\xb1\\xb9&quot; x3 ## [1] &quot;대한민국&quot; x1의 경우 일부 문자의 파싱이 안되었음. x2의 경우 파싱이 제대로 되지 않았음. 즉, 코드가 불일치함을 보여줌. 문제를 해결하려면 parse_character() 에서 인코딩을 지정해야 한다. parse_character(x1, locale = locale(encoding = &quot;Latin1&quot;)) ## [1] &quot;El Nino was particularly bad this year&quot; parse_character(x2, locale = locale(encoding = &quot;Shift-JIS&quot;)) ## [1] &quot;こんにちは&quot; parse_character(x3, locale = locale(encoding = &quot;EUC-KR&quot;)) ## [1] &quot;대한민국&quot; encoding =인수를 이용하여 코드를 지정해 줌. 1.1.3.5.3 인코딩 방식의 추출 올바른 인코딩을 어떻게 찾을 수 있을까? 운이 좋다면 데이터 문서의 어딘가 에 포함되었을 것이다. 하지만 불행하게도 그런 경우는 거의 없으므로, readr 는 guess_encoding() 을 제공하여 사용자가 알아낼 수 있도록 도와준다. 이것은 완벽하지도 않고, (앞의 사례와 달리) 텍스트가 많아야 더 잘 작동하지만, 한번 시도해볼 만한 방법이다. 올바른 인코딩을 찾기 전에 몇 가지 다른 인코딩을 시도해보라. guess_encoding(charToRaw(x1)) ## # A tibble: 2 x 2 ## encoding confidence ## &lt;chr&gt; &lt;dbl&gt; ## 1 ISO-8859-1 0.46 ## 2 ISO-8859-9 0.23 guess_encoding(charToRaw(x2)) ## # A tibble: 1 x 2 ## encoding confidence ## &lt;chr&gt; &lt;dbl&gt; ## 1 KOI8-R 0.42 guess_encoding(charToRaw(x3)) ## # A tibble: 4 x 2 ## encoding confidence ## &lt;chr&gt; &lt;dbl&gt; ## 1 IBM420_ltr 0.5 ## 2 ISO-8859-6 0.42 ## 3 windows-1256 0.37 ## 4 IBM420_rtl 0.25 guess_encoding() 의 첫 번째 인수로는 파일의 경로, 혹은 이 예제와 같이 원시 벡터 (문자열이 이미 R에 있는 경우 유용함)가 될 수 있다. 인코딩은 방대하고 복잡한 주제이며, 여기서 우리는 단지 겉핥기만 한 것이다. 더 배우고 싶으면 Encoding 에서 자세한 설명을 읽어보길 추천한다. 1.1.3.6 factor 형 R 은 factor 형을 사용하여, 가질 수 있는 값을 미리 알고 있는 범주형 변수를 나타낸다. 예상치 못한 값이 있을 때마다 경고를 생성하려면 parse_factor()에 가질 수 있는 레벨 벡터를 지정하면 된다. fruit &lt;- c(&quot;apple&quot;, &quot;banana&quot;) parse_factor(c(&quot;apple&quot;, &quot;banana&quot;, &quot;bananana&quot;), levels = fruit) ## Warning: 1 parsing failure. ## row col expected actual ## 3 -- value in level set bananana ## [1] apple banana &lt;NA&gt; ## attr(,&quot;problems&quot;) ## # A tibble: 1 x 4 ## row col expected actual ## &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 3 NA value in level set bananana ## Levels: apple banana bananana의 경우 fruit의 요소가 아니기 때문에 NA(결측치)로 처리됨. 그러나 입력값에 문제가 많이 있는 경우에는, 그 입력값을 우선 문자형 벡터로 남겨두고 문자열과 팩터형에서 배울 도구를 사용하여 정리하는 것이 쉬울 때가 많다. 1.1.3.7 데이트형, 데이트-타임형, 타임형 파싱 원하는 것이 date (1970-01-01 이후의 일 수), date-time (1970-01-01 자정 이후의 초), time (자정 이후의 초)인지에 따라 세 가지 파서 중에서 선택하면 된다. 추가 인수 없는 각 파서의 동작은 다음과 같다. 1.1.3.7.1 parse_datetime 함수 parse_datetime()은 ISO 8601 date-time을 입력으로 한다. ISO 8601은 국제 표준인데 날짜가 가장 큰 것부터 가장 작은 것(즉, 년, 월, 일, 시, 분, 초)으로 구성된다. parse_datetime(&quot;2010-10-01T2010&quot;) ## [1] &quot;2010-10-01 20:10:00 UTC&quot; ISO 8601은 가장 중요한 날짜/시간 표준이며, 날짜와 시간을 자주 다루는 경우 ISO 8601을 읽어볼 것을 추천한다. 1.1.3.7.1.1 날짜 파싱 parse_date() 는 네 자리 연도, - 또는 /, 월, - 또는 /, 날짜를 입력으로 한다. parse_datetime(&quot;20101010&quot;) ## [1] &quot;2010-10-10 UTC&quot; parse_date(&quot;2010-10-01&quot;) ## [1] &quot;2010-10-01&quot; 1.1.3.7.1.2 시간 파싱 parse_time() 은 시 : 분 그리고 선택적으로 :, 초, 선택적 a.m./p.m. 표시를 입력으로 한다. - base R에는 시간 데이터를 위한 좋은 내장 클래스가 없기 때문에, 우리는 hms 패키지에서 제공하는 클래스를 사용한다. # install.packages(&quot;hms&quot;) library(hms) parse_time(&quot;01:10 am&quot;) ## 01:10:00 parse_time(&quot;20:10:01&quot;) ## 20:10:01 1.1.3.7.1.3 format 인수의 활용 이러한 기본 설정으로 주어진 데이터를 처리하지 못한다면 다음의 요소들로 이루어진 자신만의 날짜-시간 형식(format)을 만들어 쓸 수 있다. Year %Y (4 자리). %y (2 자리); 00-69 -&gt; 2000-2069, 70-99 -&gt; 1970-1999. Month %m (2 자리). %b (“Jan”과 같이 축약된 명칭). %B (전체 명칭, “January”). Day %d (2 자리). %e (선택적 선행 공백). Time %H 0-23 시간. %I 0-12, %p와 함께 사용해야 함. %p AM/PM 구분자. %M 분. %S 정수 초. %OS 실수 초. %Z 시간대 (이름, 예 America/Chicago). 참고: 줄임말에 주의하라. ‘EST’는 일광 절약 시간제가 없는 캐나다 표준 시간대임을 주의하라. 그것은 동부 표준시가 아니다! 시간대에서 이를 다시 살펴보겠다. %z (UTC 와의 오프셋, 예: +0800). 숫자가 아닌 문자 %. 숫자가 아닌 문자 하나를 건너뛴다. %* 숫자가 아닌 문자 모두를 건너뛴다. 1.1.3.7.1.4 날짜 형식의 지정 (숫자) 올바른 포맷을 파악하는 가장 좋은 방법은 문자형 벡터로 몇 가지 예제를 만들고, 파싱함수 중 하나로 테스트하는 것이다. parse_date(&quot;01/02/15&quot;, &quot;%m/%d/%y&quot;) ## [1] &quot;2015-01-02&quot; parse_date(&quot;01/02/15&quot;, &quot;%d/%m/%y&quot;) ## [1] &quot;2015-02-01&quot; parse_date(&quot;01/02/15&quot;, &quot;%y/%m/%d&quot;) ## [1] &quot;2001-02-15&quot; parse_date(&quot;2020년 06월 17일&quot;, &quot;%Y년 %m월 %d일&quot;) ## Warning: 1 parsing failure. ## row col expected actual ## 1 -- date like %Y년 %m월 %d일 2020&lt;U+00B3&gt;&lt;e2&gt; 06&lt;U+00BF&gt;&lt;f9&gt; 17&lt;c0&gt;&lt;cf&gt; ## [1] NA 1.1.3.7.1.5 날짜 형식의 지정 (알파벳 날짜명) 비영어권의 월 이름에 %b 또는 %B 를 사용하는 경우, locale()의 lang 인수를 설정해야 한다. date_names_langs()에 내장된 언어 목록을 보라. date_names_langs() ## [1] &quot;af&quot; &quot;agq&quot; &quot;ak&quot; &quot;am&quot; &quot;ar&quot; &quot;as&quot; &quot;asa&quot; &quot;az&quot; &quot;bas&quot; &quot;be&quot; &quot;bem&quot; &quot;bez&quot; ## [13] &quot;bg&quot; &quot;bm&quot; &quot;bn&quot; &quot;bo&quot; &quot;br&quot; &quot;brx&quot; &quot;bs&quot; &quot;ca&quot; &quot;cgg&quot; &quot;chr&quot; &quot;cs&quot; &quot;cy&quot; ## [25] &quot;da&quot; &quot;dav&quot; &quot;de&quot; &quot;dje&quot; &quot;dsb&quot; &quot;dua&quot; &quot;dyo&quot; &quot;dz&quot; &quot;ebu&quot; &quot;ee&quot; &quot;el&quot; &quot;en&quot; ## [37] &quot;eo&quot; &quot;es&quot; &quot;et&quot; &quot;eu&quot; &quot;ewo&quot; &quot;fa&quot; &quot;ff&quot; &quot;fi&quot; &quot;fil&quot; &quot;fo&quot; &quot;fr&quot; &quot;fur&quot; ## [49] &quot;fy&quot; &quot;ga&quot; &quot;gd&quot; &quot;gl&quot; &quot;gsw&quot; &quot;gu&quot; &quot;guz&quot; &quot;gv&quot; &quot;ha&quot; &quot;haw&quot; &quot;he&quot; &quot;hi&quot; ## [61] &quot;hr&quot; &quot;hsb&quot; &quot;hu&quot; &quot;hy&quot; &quot;id&quot; &quot;ig&quot; &quot;ii&quot; &quot;is&quot; &quot;it&quot; &quot;ja&quot; &quot;jgo&quot; &quot;jmc&quot; ## [73] &quot;ka&quot; &quot;kab&quot; &quot;kam&quot; &quot;kde&quot; &quot;kea&quot; &quot;khq&quot; &quot;ki&quot; &quot;kk&quot; &quot;kkj&quot; &quot;kl&quot; &quot;kln&quot; &quot;km&quot; ## [85] &quot;kn&quot; &quot;ko&quot; &quot;kok&quot; &quot;ks&quot; &quot;ksb&quot; &quot;ksf&quot; &quot;ksh&quot; &quot;kw&quot; &quot;ky&quot; &quot;lag&quot; &quot;lb&quot; &quot;lg&quot; ## [97] &quot;lkt&quot; &quot;ln&quot; &quot;lo&quot; &quot;lt&quot; &quot;lu&quot; &quot;luo&quot; &quot;luy&quot; &quot;lv&quot; &quot;mas&quot; &quot;mer&quot; &quot;mfe&quot; &quot;mg&quot; ## [109] &quot;mgh&quot; &quot;mgo&quot; &quot;mk&quot; &quot;ml&quot; &quot;mn&quot; &quot;mr&quot; &quot;ms&quot; &quot;mt&quot; &quot;mua&quot; &quot;my&quot; &quot;naq&quot; &quot;nb&quot; ## [121] &quot;nd&quot; &quot;ne&quot; &quot;nl&quot; &quot;nmg&quot; &quot;nn&quot; &quot;nnh&quot; &quot;nus&quot; &quot;nyn&quot; &quot;om&quot; &quot;or&quot; &quot;os&quot; &quot;pa&quot; ## [133] &quot;pl&quot; &quot;ps&quot; &quot;pt&quot; &quot;qu&quot; &quot;rm&quot; &quot;rn&quot; &quot;ro&quot; &quot;rof&quot; &quot;ru&quot; &quot;rw&quot; &quot;rwk&quot; &quot;sah&quot; ## [145] &quot;saq&quot; &quot;sbp&quot; &quot;se&quot; &quot;seh&quot; &quot;ses&quot; &quot;sg&quot; &quot;shi&quot; &quot;si&quot; &quot;sk&quot; &quot;sl&quot; &quot;smn&quot; &quot;sn&quot; ## [157] &quot;so&quot; &quot;sq&quot; &quot;sr&quot; &quot;sv&quot; &quot;sw&quot; &quot;ta&quot; &quot;te&quot; &quot;teo&quot; &quot;th&quot; &quot;ti&quot; &quot;to&quot; &quot;tr&quot; ## [169] &quot;twq&quot; &quot;tzm&quot; &quot;ug&quot; &quot;uk&quot; &quot;ur&quot; &quot;uz&quot; &quot;vai&quot; &quot;vi&quot; &quot;vun&quot; &quot;wae&quot; &quot;xog&quot; &quot;yav&quot; ## [181] &quot;yi&quot; &quot;yo&quot; &quot;zgh&quot; &quot;zh&quot; &quot;zu&quot; 한국은 ko 자신의 언어가 아직 포함되어 있지 않았으면 date_names() 를 사용하여 생성하라. parse_date(&quot;1 janvier 2015&quot;, &quot;%d %B %Y&quot;, locale = locale(&quot;fr&quot;)) ## [1] &quot;2015-01-01&quot; parse_date(&quot;20-06-17&quot;, &quot;%y-%m-%d&quot;) ## [1] &quot;2020-06-17&quot; parse_date(&quot;2020-06-17&quot;, &quot;%Y-%m-%d&quot;) ## [1] &quot;2020-06-17&quot; parse_date(&quot;2020년 06월 17일&quot;, &quot;%Y년 %m월 %d일&quot;) ## Warning: 1 parsing failure. ## row col expected actual ## 1 -- date like %Y년 %m월 %d일 2020&lt;U+00B3&gt;&lt;e2&gt; 06&lt;U+00BF&gt;&lt;f9&gt; 17&lt;c0&gt;&lt;cf&gt; ## [1] NA 1.1.4 연습문제 locale() 에서 가장 중요한 인수들은 무엇인가? locale()함수는 다음과 같은 인수들이 있다: 날짜와 시간 형식 : date_names, date_format, 그리고 time_format 시간대 : tz 숫자 : decimal_mark, grouping_mark 인코딩 : encoding decimal_mark 와 grouping_mark 를 동일 문자로 설정하려고 하면 어떻게 되는가? decimal_mark 를 ‘,’로 설정하면 grouping_mark 의 기본값은 어떻게 되는가? 소숫점 표시와 그루핑 마크가 같은 문자로 설정되어 있으면 locale은 에러를 발생시킨다: # locale(decimal_mark = &quot;.&quot;, grouping_mark = &quot;.&quot;) 소숫점 표시( decimal_mark )가 컴마(\",\")로 설정되어 잇으면, 그루핑 마크(grouping_mark)는 점(\".\")으로 설정된다. locale(decimal_mark = &quot;,&quot;) ## &lt;locale&gt; ## Numbers: 123.456,78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM 그루핑 마크(grouping_mark)가 컴마(\",\")으로 설정되어 있으면, 소숫점 표시( decimal_mark )는 점(\".\")으로 설정된다: locale(grouping_mark = &quot;,&quot;) ## &lt;locale&gt; ## Numbers: 123,456.78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM locale()의 date_format 및 time_format 옵션에 대해서는 논의하지 않았다. 이 들이 하는 일은 무엇인가? 이들이 유용할 수 있는 경우를 보여주는 예제를 작성해보라. 이것들은 디폴트의 날짜와 시간 형식을 제공한다. readr vignette 는 날짜를 파싱하기 위해 이 함수들을 이용하는 것에 대하여 다루고 있다: 날짜는 언어 특유의 요일과 월 이름 그리고 AM/PM에 대한 서로 다른 표기법을 가지고 있을 수 있기 때문이다. locale() ## &lt;locale&gt; ## Numbers: 123,456.78 ## Formats: %AD / %AT ## Timezone: UTC ## Encoding: UTF-8 ## &lt;date_names&gt; ## Days: Sunday (Sun), Monday (Mon), Tuesday (Tue), Wednesday (Wed), Thursday ## (Thu), Friday (Fri), Saturday (Sat) ## Months: January (Jan), February (Feb), March (Mar), April (Apr), May (May), ## June (Jun), July (Jul), August (Aug), September (Sep), October ## (Oct), November (Nov), December (Dec) ## AM/PM: AM/PM 프랑스 날짜를 파싱한 readr vignette의 예를 들면 다음과 같다: parse_date(&quot;1 janvier 2015&quot;, &quot;%d %B %Y&quot;, locale = locale(&quot;fr&quot;)) ## [1] &quot;2015-01-01&quot; parse_date(&quot;14 oct. 1979&quot;, &quot;%d %b %Y&quot;, locale = locale(&quot;fr&quot;)) ## [1] &quot;1979-10-14&quot; 확실히 시간 형식은 사용되지 않지만, 날짜 형식은 열의 데이터 형식을 파악하는데 사용된다. 가장 많이 읽는 파일 형식에 대한 설정을 압축한 새로운 로캘 객체를 만들어 보라. 설정될 수 있는 상이한 변수들에 대해 알고 싶으면 ?locale()를 이용하여 locale() 도움말을 참조한다. 호주를 예를 들어 보겠다. 02/02/2007으로 ‘January 2, 2006’을 의미하는 날짜 형식이 “(d)d/mm/yyyy”라는 것을 제외하면, 대부분의 디폴트 값이 유효하다. 그러나, 드폴트 locale은 날짜를 February 1, 2006으로 파싱할 것이다. parse_date(&quot;02/01/2006&quot;) ## Warning: 1 parsing failure. ## row col expected actual ## 1 -- date like 02/01/2006 ## [1] NA 호주의 날짜를 정확히 파싱하기 위해서는 새로운 locale 오브젝트를 정의해야 한다: au_locale &lt;- locale(date_format = &quot;%d/%m/%Y&quot;) locale을 au_locale로 하고 parse_date()를 사용하면 날짜를 정확히 파싱할 것이다: parse_date(&quot;02/01/2006&quot;, locale = au_locale) ## [1] &quot;2006-01-02&quot; read_csv() 와 read_csv2() 은 무엇이 다른가? 구분자의 차이이다. read_csv()함수는 컴마를 구분자로 사용하면 반면에 read_csv2() 함수는 세미콜론(;)을 사용한다. 세미콜론을 사용하는 것은 컴마가 소숫점으로 사용(예를 들어 유럽에서 처럼)될 때 유용하다. 유럽에서 사용되는 가장 일반적인 인코딩은 무엇인가? 아시아에서 가장 많이 사용되는 인코딩은 무엇인가? 구글 검색해서 알아보라. 아랍어와 베트남어는 ISO와 윈도우즈 표준을 가지고 있다. 다른 주요 아시어 언어는 그들 자신만의 표준을 가지고 있다: 일본어 : JIS X 0208, Shift JIS, ISO-2022-JP 중국어 : GB 2312, GBK, GB 18030 한국어 : KS X 1001, EUC-KR, ISO-2022-KR stringi::stri_enc_detect의 문서에 있는 목록은 가장 보통의 인코딩을 지원하기 때문에 인코딩 목록을 잘 보여주고 있다. 서유럽 라틴 언어 : ISO-8859-1, Windows-1250 (also CP-1250 for code-point) 동유럽 라틴 언어 : ISO-8859-2, Windows-1252 그리스어 : ISO-8859-7 터키어 : ISO-8859-9, Windows-1254 히브리어 : ISO-8859-8, IBM424, Windows 1255 러시아어 : Windows 1251 일본어 : Shift JIS, ISO-2022-JP, EUC-JP 한국어 : ISO-2022-KR, EUC-KR 중국어 : GB18030, ISO-2022-CN (Simplified), Big5 (Traditional) 아랍어 : ISO-8859-6, IBM420, Windows 1256 문자열 인코딩에 대한 보다 상세한 내용은 다음의 사이트를 참고하라. Wikipedia 페이지 Character encoding Unicode CLDR 프로젝트 What is the most common encoding of each language (Stack Overflow) “What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text,” http://kunststube.net/encoding/. 텍스트 인코딩을 다루는 프로그램들은 다음과 같다: readr::guess_encoding() stringi::str_enc_detect() iconv chardet (Python) 올바른 형식 문자열을 생성하여 다음 날짜와 시간을 파싱하라. d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 t1 &lt;- &quot;1705&quot; t2 &lt;- &quot;11:15:10.12 PM&quot; The correct formats are: parse_date(d1, &quot;%B %d, %Y&quot;) ## [1] &quot;2010-01-01&quot; parse_date(d2, &quot;%Y-%b-%d&quot;) ## [1] &quot;2015-03-07&quot; parse_date(d3, &quot;%d-%b-%Y&quot;) ## [1] &quot;2017-06-06&quot; parse_date(d4, &quot;%B %d (%Y)&quot;) ## [1] &quot;2015-08-19&quot; &quot;2015-07-01&quot; parse_date(d5, &quot;%m/%d/%y&quot;) ## [1] &quot;2014-12-30&quot; parse_time(t1, &quot;%H%M&quot;) ## 17:05:00 parse_time(t2, &quot;%H:%M:%OS %p&quot;) ## 23:15:10.12 1.1.5 파일 파싱하기 이제까지 개별 벡터를 파싱하는 방법을 배웠으므로, 처음으로 돌아가서 readr을 이용하여 파일을 파싱하는 방법을 알아볼 차례이다. 이 절에서는 다음의 두 방법을 배운다. readr이 각 열의 유형을 자동으로 추측하는 방법. 기본 사양을 재정의하는 방법. 1.1.5.1 전략 readr은 휴리스틱 방법을 사용하여 각 열의 유형을 파악한다. 첫 번째 1000행을 읽고 (적절히 보수적인) 휴리스틱 방법을 사용하여 각 열의 유형을 찾는다. guess_parser()(readr의 추정을 반환)와 parse_guess() (앞의 추정을 사용하여 열을 파싱)를 사용하여 문자형 벡터에 이 과정을 재현해볼 수 있다. guess_parser(&quot;2010-10-01&quot;) ## [1] &quot;date&quot; guess_parser(&quot;15:01&quot;) ## [1] &quot;time&quot; guess_parser(c(&quot;TRUE&quot;, &quot;FALSE&quot;)) ## [1] &quot;logical&quot; guess_parser(c(&quot;1&quot;, &quot;5&quot;, &quot;9&quot;)) ## [1] &quot;double&quot; guess_parser(c(&quot;12,352,561&quot;)) ## [1] &quot;number&quot; str(parse_guess(&quot;2010-10-10&quot;)) ## Date[1:1], format: &quot;2010-10-10&quot; parse_***의 ***을 결정하기 곤란한 경우 guess_parse() 함수 활용 이 휴리스틱 방법은 다음 유형들을 각각 시도하여 일치하는 항목을 찾으면 멈춘다. 논리형: “F,” “T,” “FALSE,” “TRUE”만 포함. 정수형: 수치형 문자(와 -)만 포함. 더블형: (4.5e-5와 같은 숫자를 포함하는) 유효한 더블형만 포함. 수치형: 내부에 그룹화 마크가 있는 유효한 더블형을 포함. 타임형: time_format의 기본형식과 일치. 데이트형: date_format의 기본형식과 일치. 데이트-시간형: ISO8601 날짜. 이러한 규칙 중 어느 것도 적용되지 않으면 해당 열은 문자열 벡터로 그대로 남는다. 1.1.5.2 문제점 큰 파일의 경우 이러한 기본값이 항상 잘 작동하지는 않는다. 두 가지 문제가 있다. 처음 1,000 행이 특수한 경우이어서 readr이 충분히 일반적이지 않은 유형으로 추측할 수 있다. 예를 들어 첫 번째 1,000개의 행에 정수만 있는 더블형 열이 있을 수 있다. 열에 결측값이 많이 있을 수 있다. 첫 번째 1,000 개의 행에 NA 만 있는 경우 readr 이 문자형 벡터로 추측했지만, 여러분은 좀 더 구체적으로 파싱하고 싶을 수 있다. readr에는 이러한 두 가지 문제를 모두 보여주는 까다로운 CSV 가 포함되어 있다. challenge &lt;- read_csv(readr_example(&quot;challenge.csv&quot;)) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_logical() ## ) ## Warning: 1000 parsing failures. ## row col expected actual file ## 1001 y 1/0/T/F/TRUE/FALSE 2015-01-16 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1002 y 1/0/T/F/TRUE/FALSE 2018-05-18 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1003 y 1/0/T/F/TRUE/FALSE 2015-09-05 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1004 y 1/0/T/F/TRUE/FALSE 2012-11-28 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1005 y 1/0/T/F/TRUE/FALSE 2020-01-13 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## .... ... .................. .......... ................................................................ ## See problems(...) for more details. problems(challenge) ## # A tibble: 1,000 x 5 ## row col expected actual file ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1001 y 1/0/T/F/TRUE/F~ 2015-01~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 2 1002 y 1/0/T/F/TRUE/F~ 2018-05~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 3 1003 y 1/0/T/F/TRUE/F~ 2015-09~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 4 1004 y 1/0/T/F/TRUE/F~ 2012-11~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 5 1005 y 1/0/T/F/TRUE/F~ 2020-01~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 6 1006 y 1/0/T/F/TRUE/F~ 2016-04~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 7 1007 y 1/0/T/F/TRUE/F~ 2011-05~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 8 1008 y 1/0/T/F/TRUE/F~ 2020-07~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 9 1009 y 1/0/T/F/TRUE/F~ 2011-04~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## 10 1010 y 1/0/T/F/TRUE/F~ 2010-05~ &#39;C:/Program Files/R/R-4.0.3/library/rea~ ## # ... with 990 more rows challenge.csv 파일은 readr 패키지가 제공하는 예제 데이터 세트임. read_csv()에서 열에 대한 데이터 타입을 지정하지 않아 y컬럼의 값이 모두 NA로 인식함. [**] readr_example() 함수는 challenge.csv 파일이 저장된 폴더의 경로를 확인함. (패키지에 포함된 파일의 경로를 찾아 주는 readr_example() 을 사용한 것에 주목하라.) 두 가지가 출력되었다. 첫 번째 1,000 개의 행을 보고 생성된 열 상세 내용과 첫 다섯 개의 파싱 오류가 그것이다. 발생한 문제들을 ‘problems()’ 로 명시적으로 추출하여 더 깊이 탐색하는 것은 좋은 방법이다. readr_example(&quot;challenge.csv&quot;) ## [1] &quot;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&quot; 1.1.5.3 문제 해결 전략 문제가 남아있지 않을 때까지 열 단위로 작업하는 것은 좋은 전략이다. x 열에 파싱 문제가 많다는 것을 알 수 있다. 정수값 다음에 따라오는 문자가 있었던 것이다. 이는 더블형 파서를 사용해야 함을 암시한다. 이 호출을 수정하기 위해 먼저 열 사양을 복사하여 원래 호출에 붙여 넣어보라. 1.1.5.3.1 x 컬럼 타입을 정수로, 그리고 y컬럼을 문자형으로 지정 x는 정수형, y는 문자형으로 지정해 보기로 한다. challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_integer(), y = col_character() ) ) ## Warning: 1000 parsing failures. ## row col expected actual file ## 1001 x no trailing characters 0.23837975086644292 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1002 x no trailing characters 0.41167997173033655 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1003 x no trailing characters 0.7460716762579978 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1004 x no trailing characters 0.723450553836301 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## 1005 x no trailing characters 0.614524137461558 &#39;C:/Program Files/R/R-4.0.3/library/readr/extdata/challenge.csv&#39; ## .... ... ...................... ................... ................................................................ ## See problems(...) for more details. 1.1.5.3.2 x 컬럼 타입을 실수형 그리고 y컬럼을 문자형으로 지정 그런 다음 x 열의 유형을 ‘col_double()’로 조정할 수 있다. challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_double(), y = col_character() ) ) tail(challenge) ## # A tibble: 6 x 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 0.805 2019-11-21 ## 2 0.164 2018-03-29 ## 3 0.472 2014-08-04 ## 4 0.718 2015-08-16 ## 5 0.270 2020-02-04 ## 6 0.608 2019-01-06 첫 번째 문제는 해결되었지만, 마지막 몇 행을 보면 날짜가 문자형 벡터(&lt;chr&gt;)로 저장되었다. 1.1.5.3.3 x 컬럼 타입을 실수형 그리고 y컬럼을 날짜형으로 지정 y 열을 데이트형(col_date())으로 설정하여 이를 수정할 수 있다. challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_double(), y = col_date() ) ) tail(challenge) ## # A tibble: 6 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 0.805 2019-11-21 ## 2 0.164 2018-03-29 ## 3 0.472 2014-08-04 ## 4 0.718 2015-08-16 ## 5 0.270 2020-02-04 ## 6 0.608 2019-01-06 모든 parse_xyz() 함수는 해당하는 col_xyz() 함수를 가지고 있다. 데이터가 이미 R 의 문자형 벡터인 경우에는 parse_xyz() 를 사용하면 되고, readr 이 데이터를 불러오는 방법을 설정할 경우에는 col_xyz() 를 사용하면 된다. col_types 를 항상 설정하여 readr 이 생성하는 출력물로부터 만들어 나가는 것을 강력히 추천한다. 이렇게 하면 일관되고 재현할 수 있는 데이터 불러오기 스크립트를 갖게 된다. 기본값으로 추측하여 데이터를 읽는다면 데이터 변경 시 readr 은 과거 설정으로 읽게 될 것이다. 정말로 엄격하게 하고 싶다면 stop_for_problems() 를 사용하라. 파싱 문제가 생기면 오류를 내며 스크립트를 중단할 것이다. 1.1.5.4 기타 전략 파일을 파싱하는 데 도움이 되는 몇 가지 다른 일반적인 전략이 있다. 앞의 예제에서 우리는 단지 운이 없었다. 즉, 기본값보다 한 행만 더 살펴보면 한 번에 정확하게 파싱할 수 있다. challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), guess_max = 1001) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_date(format = &quot;&quot;) ## ) 모든 열을 문자형 벡터로 읽으면 문제를 쉽게 진단할 수 있는 경우가 많다. challenge2 &lt;- read_csv(readr_example(&quot;challenge.csv&quot;), col_types = cols(.default = col_character()) ) 이 방법은 type_convert() 와 함께 사용하면 특히 유용한데, 이 함수는 휴리스틱한 파싱 방법을 데이터프레임의 문자형 열에 적용한다. tribble() 함수의 활용 df &lt;- tribble( ~x, ~y, &quot;1&quot;, &quot;1.21&quot;, &quot;2&quot;, &quot;2.32&quot;, &quot;3&quot;, &quot;4.56&quot; ) df ## # A tibble: 3 x 2 ## x y ## &lt;chr&gt; &lt;chr&gt; ## 1 1 1.21 ## 2 2 2.32 ## 3 3 4.56 1.1.5.4.1 열 유형을 주의 type_convert(df) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_double() ## ) ## # A tibble: 3 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.21 ## 2 2 2.32 ## 3 3 4.56 매우 큰 파일을 읽는 경우, n_max 를 10,000 또는 100,000 과 같이 작은 숫자로 설정할 수 있다. 이렇게 하면 일반적인 문제를 해결하는 동시에 반복작업을 가속화할 수 있다. 파싱에 중대한 문제가 있는 경우에는 read_lines() 을 이용하여 라인으로 이루어진 문자형 벡터로 읽거나 read_file() 을 이용하여 길이가 1인 문자형 벡터로 읽는 것이 더 쉬울 수 있다. 그런 다음 나중에 배울 문자열 파싱 방법을 사용하여 좀 더 특이한 포맷을 파싱하면 된다. 1.2 Data Export 1.2.1 write_csv() write_csv(challenge, &quot;data1/out/challenge.csv&quot;) challenge ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows write_csv(challenge, &quot;data1/out/challenge-2.csv&quot;) read_csv(&quot;data1/out/challenge-2.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_logical() ## ) ## Warning: 1000 parsing failures. ## row col expected actual file ## 1001 y 1/0/T/F/TRUE/FALSE 2015-01-16 &#39;data1/out/challenge-2.csv&#39; ## 1002 y 1/0/T/F/TRUE/FALSE 2018-05-18 &#39;data1/out/challenge-2.csv&#39; ## 1003 y 1/0/T/F/TRUE/FALSE 2015-09-05 &#39;data1/out/challenge-2.csv&#39; ## 1004 y 1/0/T/F/TRUE/FALSE 2012-11-28 &#39;data1/out/challenge-2.csv&#39; ## 1005 y 1/0/T/F/TRUE/FALSE 2020-01-13 &#39;data1/out/challenge-2.csv&#39; ## .... ... .................. .......... ........................... ## See problems(...) for more details. ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;lgl&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows 1.2.2 write_rds() write_rds(challenge, &quot;data1/out/challenge.rds&quot;) read_rds(&quot;data1/out/challenge.rds&quot;) ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows RDS, Rdata, Rda의 차이점에 대하여 알아보자… R 데이터 용량 줄이기 1.2.3 write_feather() library(feather) write_feather(challenge, &quot;data1/out/challenge.feather&quot;) read_feather(&quot;data1/out/challenge.feather&quot;) ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows feather 파일 앞의 예에서 불러온 challenge.csv 데이터 세트를 data1/out 폴더에 저장해 보기로 한다. challenge &lt;- read_csv( readr_example(&quot;challenge.csv&quot;), col_types = cols( x = col_double(), y = col_date() ) ) tail(challenge) ## # A tibble: 6 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 0.805 2019-11-21 ## 2 0.164 2018-03-29 ## 3 0.472 2014-08-04 ## 4 0.718 2015-08-16 ## 5 0.270 2020-02-04 ## 6 0.608 2019-01-06 readr에는 디스크에 데이터를 다시 기록하는 데 유용한 함수인 write_csv() 와 write_tsv() 가 있다. 두 함수 모두 다음 동작을 통해 출력 파일이 올바르게 다시 읽힐 수 있게 한다. - 항상 UTF-8로 문자열을 인코딩한다. - 날짜와 날짜-시간을 ISO 8601 형식으로 저장하여 어디에서든 쉽게 파싱될 수 있게 한다. 또한, CSV 파일을 엑셀로 내보내려면 write_excel_csv() 를 사용하면 된다. 이는 파일의 시작 부분에 특수 문자(‘byte order mark’)를 작성하여, UTF-8 인코딩을 사용하고 있음을 엑셀에 전달한다. 인수 가장 중요한 인수는 x (저장할 데이터프레임)와 path (그 데이터프레임을 저장할 위치)이다. 결측값을 지정하는 인수, na= 와 기존 파일에 첨부할지를 지정하는 인수 append= 도 있다. write_csv(challenge, &quot;data1/out/challenge.csv&quot;) 1.2.4 read_csv()와 read_rds()의 비교 CSV 로 저장하면 데이터의 유형 정보가 없어진다는 것에 유의하라. 즉, plain text 파일로 저장이 된다. challenge ## # A tibble: 2,000 x 2 ## x y ## &lt;dbl&gt; &lt;date&gt; ## 1 404 NA ## 2 4172 NA ## 3 3004 NA ## 4 787 NA ## 5 37 NA ## 6 2332 NA ## 7 2489 NA ## 8 1449 NA ## 9 3665 NA ## 10 3863 NA ## # ... with 1,990 more rows write_csv(challenge, &quot;data1/out/challenge-2.csv&quot;) challenge1 &lt;- read_csv(&quot;data1/out/challenge-2.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## x = col_double(), ## y = col_logical() ## ) ## Warning: 1000 parsing failures. ## row col expected actual file ## 1001 y 1/0/T/F/TRUE/FALSE 2015-01-16 &#39;data1/out/challenge-2.csv&#39; ## 1002 y 1/0/T/F/TRUE/FALSE 2018-05-18 &#39;data1/out/challenge-2.csv&#39; ## 1003 y 1/0/T/F/TRUE/FALSE 2015-09-05 &#39;data1/out/challenge-2.csv&#39; ## 1004 y 1/0/T/F/TRUE/FALSE 2012-11-28 &#39;data1/out/challenge-2.csv&#39; ## 1005 y 1/0/T/F/TRUE/FALSE 2020-01-13 &#39;data1/out/challenge-2.csv&#39; ## .... ... .................. .......... ........................... ## See problems(...) for more details. str(challenge1) ## tibble [2,000 x 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ x: num [1:2000] 404 4172 3004 787 37 ... ## $ y: logi [1:2000] NA NA NA NA NA NA ... ## - attr(*, &quot;problems&quot;)= tibble [1,000 x 5] (S3: tbl_df/tbl/data.frame) ## ..$ row : int [1:1000] 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 ... ## ..$ col : chr [1:1000] &quot;y&quot; &quot;y&quot; &quot;y&quot; &quot;y&quot; ... ## ..$ expected: chr [1:1000] &quot;1/0/T/F/TRUE/FALSE&quot; &quot;1/0/T/F/TRUE/FALSE&quot; &quot;1/0/T/F/TRUE/FALSE&quot; &quot;1/0/T/F/TRUE/FALSE&quot; ... ## ..$ actual : chr [1:1000] &quot;2015-01-16&quot; &quot;2018-05-18&quot; &quot;2015-09-05&quot; &quot;2012-11-28&quot; ... ## ..$ file : chr [1:1000] &quot;&#39;data1/out/challenge-2.csv&#39;&quot; &quot;&#39;data1/out/challenge-2.csv&#39;&quot; &quot;&#39;data1/out/challenge-2.csv&#39;&quot; &quot;&#39;data1/out/challenge-2.csv&#39;&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. x = col_double(), ## .. y = col_logical() ## .. ) x 컬럼은 실수형으로 불러왔으나, y 컬럼은 logical 형으로 불러왔다. 이런 이유로 중간 결과를 캐싱하기에 CSV 파일을 신뢰할 수 없다. 불러올 때마다 열 사양을 다시 만들어야 한다. 즉, parsing을 해 주어야 한다. 여기에는 두 가지 대안이 있다. write_rds() 와 read_rds() 는 베이스 함수인 readRDS() 와 saveRDS() 의 래퍼 함수들이다. 이들은 RDS 라는 R 의 커스텀 바이너리 형식으로 데이터를 저장한다. write_rds(challenge, &quot;data1/out/challenge.rds&quot;) challenge2 &lt;- read_rds(&quot;data1/out/challenge.rds&quot;) write_rds() 함수로 challenge 데이터 세트를 data 폴더에 challenge.rds에 export 했다. read_rds() 함수를 이용하여 data1/out/challenge.rds 파일을 challenge2 변수로 import 했다. challenge2의 데이터 구조를 확인해 보자. str(challenge2) ## tibble [2,000 x 2] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ x: num [1:2000] 404 4172 3004 787 37 ... ## $ y: Date[1:2000], format: NA NA ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. x = col_double(), ## .. y = col_date(format = &quot;&quot;) ## .. ) str(challenge2)으로 challenge2의 데이터 구조를 확인해 보면, 컬럼들의 데이터 타입이 실수형과 날짜형으로 되어 있음을 알 수 있다. 즉, parsing이 필요없다. feather 패키지는 다른 프로그래밍 언어와 공유할 수 있는 빠른 바이너리 파일 형식을 구현한다. library(feather) write_feather(challenge, &quot;data1/out/challenge.feather&quot;) challenge3 &lt;- read_feather(&quot;data1/out/challenge.feather&quot;) str(challenge3) ## tibble [2,000 x 2] (S3: tbl_df/tbl/data.frame) ## $ x: num [1:2000] 404 4172 3004 787 37 ... ## $ y: Date[1:2000], format: NA NA ... x 컬럼과 y 컬럼의 데이터 타입을 잘 읽어 들였다. feather 는 RDS 보다 대체적으로 빠르며 R 외부에서도 사용할 수 있다. RDS 는 리스트-열을 지원하지만 feather 는 현재 지원하지 않는다. 따라서, R에서 처리한 데이터 세트는 단순히 csv 파일이 아닌 RDS 파일로 저장하는 것이 좋다. {-} 1.3 Read Tabular Data의 보충설명 1.3.1 read_csv()의 예 데이터가 컴마(,)로 분리된 경우 write_file(x = &quot;a,b,c\\n1,2,3\\n4,5,NA&quot;, path=&quot;data1/out/file.csv&quot;) # file.csv 파일의 생성 ## Warning: The `path` argument of `write_file()` is deprecated as of readr 1.4.0. ## Please use the `file` argument instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. data &lt;- read_csv(&quot;data1/out/file.csv&quot;) # file.csv 파일 불러오기 ## ## -- Column specification -------------------------------------------------------- ## cols( ## a = col_double(), ## b = col_double(), ## c = col_double() ## ) data ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 NA 1.3.2 read_csv2()의 예 데이터가 세미콜론(;)로 분리된 경우 write_file(x = &quot;a;b;c\\n1;2;3\\n4;5;NA&quot;, path=&quot;data1/out/file2.csv&quot;) # file2.csv 파일의 생성 data2 &lt;- read_csv2(&quot;data1/out/file2.csv&quot;) # file2.csv 파일 불러오기 ## i Using &#39;,&#39; as decimal and &#39;.&#39; as grouping mark. Use `read_delim()` for more control. ## ## -- Column specification -------------------------------------------------------- ## cols( ## a = col_double(), ## b = col_double(), ## c = col_double() ## ) data2 ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 NA 1.3.3 read_delim()의 예 특정의 구분자를 사용하는 경우. 예를 들어 선문자(|)를 구분자로 사용하는 경우 write_file(x = &quot;a|b|c\\n1|2|3\\n4|5|NA&quot;, path=&quot;data1/out/file.txt&quot;) # file.txt 파일의 생성 data3 &lt;- read_delim(&quot;data1/out/file.txt&quot;, delim=&quot;|&quot; ) # file.txt 파일 불러오기 ## ## -- Column specification -------------------------------------------------------- ## cols( ## a = col_double(), ## b = col_double(), ## c = col_double() ## ) data3 ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 NA 1.3.4 read_fwf()의 예 데이터가 고정 너비 간격으로 분리된 경우 write_file(x = &quot;2 4 6\\n1 2 3\\n4 5 NA&quot;, path=&quot;data1/out/file.fwf&quot;) # file.fwf 파일의 생성 # 1. Guess based on position of empty columns data4 &lt;- read_fwf(&quot;data1/out/file.fwf&quot;, fwf_empty(&quot;data1/out/file.fwf&quot;, col_names = c(&quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V2 = col_double(), ## V3 = col_double() ## ) data4 ## # A tibble: 3 x 3 ## V1 V2 V3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 4 6 ## 2 1 2 3 ## 3 4 5 NA # 2. A vector of field widths data5 &lt;- read_fwf(&quot;data1/out/file.fwf&quot;, fwf_widths(c(2, 2, 2), col_names = c(&quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V2 = col_double(), ## V3 = col_double() ## ) ## Warning: 2 parsing failures. ## row col expected actual file ## 1 V3 1 chars 1 &#39;data1/out/file.fwf&#39; ## 2 V3 1 chars 1 &#39;data1/out/file.fwf&#39; data5 ## # A tibble: 3 x 3 ## V1 V2 V3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 4 6 ## 2 1 2 3 ## 3 4 5 NA # 3. Paired vectors of start and end positions data6 &lt;- read_fwf(&quot;data1/out/file.fwf&quot;, fwf_positions(c(1, 5), c(2, 7), c(&quot;V1&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V3 = col_double() ## ) ## Warning: 3 parsing failures. ## row col expected actual file ## 1 V3 1 chars 1 &#39;data1/out/file.fwf&#39; ## 2 V3 1 chars 1 &#39;data1/out/file.fwf&#39; ## 3 V3 2 chars 2 &#39;data1/out/file.fwf&#39; data6 ## # A tibble: 3 x 2 ## V1 V3 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 6 ## 2 1 3 ## 3 4 NA # 4. Named arguments with start and end positions data7 &lt;- read_fwf(&quot;data1/out/file.fwf&quot;, fwf_cols(V1 = c(1, 1), V3 = c(5, 5))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V3 = col_character() ## ) data7 ## # A tibble: 3 x 2 ## V1 V3 ## &lt;dbl&gt; &lt;chr&gt; ## 1 2 6 ## 2 1 3 ## 3 4 N ** data7의 경우 마지막 데이터가 NA(결측치)로 V3 = C(5,5)에 의해 첫 글자 N만 읽어 들이게 되고, V3 컬럼은 문자형이 된다. # 5. Named arguments with column widths data8 &lt;- read_fwf(&quot;data1/out/file.fwf&quot;, fwf_cols(V1 = 2, V2 = 2, V3 = 1)) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V2 = col_double(), ## V3 = col_character() ## ) data8 ## # A tibble: 3 x 3 ## V1 V2 V3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2 4 6 ## 2 1 2 3 ## 3 4 5 N **앞의 data7과 같은 현상임. [예제] 데이터가 다음과 같이 고정 너비 간격으로 분리된 경우 (“file1.fwf”) 11aa222 33bb444 55cc666 예제의 풀이) write_file(x = &quot;11aa222\\n33bb444\\n55cc666&quot;, path=&quot;data1/out/file1.fwf&quot;) # file1.fwf 파일의 생성 ## 1. Guess based on position of empty columns d1 &lt;- read_fwf(&quot;data1/out/file1.fwf&quot;, fwf_empty(&quot;data1/out/file1.fwf&quot;, col_names = c(&quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_character(), ## V2 = col_character(), ## V3 = col_character() ## ) ## Warning: 3 parsing failures. ## row col expected actual file ## 1 -- 3 columns 1 columns &#39;data1/out/file1.fwf&#39; ## 2 -- 3 columns 1 columns &#39;data1/out/file1.fwf&#39; ## 3 -- 3 columns 1 columns &#39;data1/out/file1.fwf&#39; View(d1) # 2. A vector of field widths d2 &lt;- read_fwf(&quot;data1/out/file1.fwf&quot;, fwf_widths(c(2, 2, 3), col_names = c(&quot;V1&quot;, &quot;V2&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V2 = col_character(), ## V3 = col_double() ## ) d2 ## # A tibble: 3 x 3 ## V1 V2 V3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 11 aa 222 ## 2 33 bb 444 ## 3 55 cc 666 # 3. Paired vectors of start and end positions d3 &lt;- read_fwf(&quot;data1/out/file1.fwf&quot;, fwf_positions(c(1, 5), c(2, 7), c(&quot;V1&quot;, &quot;V3&quot;))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V3 = col_double() ## ) d3 ## # A tibble: 3 x 2 ## V1 V3 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 11 222 ## 2 33 444 ## 3 55 666 # 4. Named arguments with start and end positions d4 &lt;- read_fwf(&quot;data1/out/file1.fwf&quot;, fwf_cols(V1 = c(1, 2), V3 = c(5, 7))) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V3 = col_double() ## ) d4 ## # A tibble: 3 x 2 ## V1 V3 ## &lt;dbl&gt; &lt;dbl&gt; ## 1 11 222 ## 2 33 444 ## 3 55 666 # 5. Named arguments with column widths d5 &lt;- read_fwf(&quot;data1/out/file1.fwf&quot;, fwf_cols(V1 = 2, V2 = 2, V3 = 3)) ## ## -- Column specification -------------------------------------------------------- ## cols( ## V1 = col_double(), ## V2 = col_character(), ## V3 = col_double() ## ) d5 ## # A tibble: 3 x 3 ## V1 V2 V3 ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 11 aa 222 ## 2 33 bb 444 ## 3 55 cc 666 1.3.5 read_tsv()의 예 데이터가 탭(\\t)으로 분리되어 있는 경우 write_file(x = &quot;a\\tb\\tc\\n1\\t2\\t3\\n4\\t5\\tNA&quot;, path=&quot;data1/out/file.tsv&quot;) # file.tsv 파일의 생성 data9 &lt;- read_tsv(&quot;data1/out/file.tsv&quot;) # file.tsv 파일 불러오기 ## ## -- Column specification -------------------------------------------------------- ## cols( ## a = col_double(), ## b = col_double(), ## c = col_double() ## ) data9 ## # A tibble: 2 x 3 ## a b c ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 ## 2 4 5 NA "],["df-tibble-factor.html", "Chapter 2 Dataframe, Tibble and Factor 2.1 Data Frame 2.2 tibble 2.3 Factor", " Chapter 2 Dataframe, Tibble and Factor 2.1 Data Frame 데이터 프레임은 R의 핵심적인 자료구조이다. 엑셀과 같이 숫자, 문자 등 다양한 데이터를 하나의 테이블에 담을 수 있는 자료구조이다. 이를 잘 활용하면 엑셀의 기능들을 R에서도 자유자제로 사용할 수 있다. library(tidyverse) 2.1.1 데이터 프레임의 생성 2.1.1.1 data.frame()함수 이용 먼저 데이터 데이터 프레임을 생성하는 방법은 다음과 같다. df &lt;- data.frame(col1=c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;) , col2=c(2, 4, 6, 8, 10)) df ## col1 col2 ## 1 a 2 ## 2 b 4 ## 3 c 6 ## 4 d 8 ## 5 e 10 df의 데이터 내용 보기 1) R Studio의 Global Environment의 Data에서 마우스로 df를 클릭하는 방법 2) View(df) 2.1.1.2 data.frame() 함수의 형식 data.frame(..., row.names = NULL, check.rows = FALSE, check.names = TRUE, fix.empty.names = TRUE, stringsAsFactors = default.stringsAsFactors())` 주요 인수 : ... : 이 인수는 폼 값이나 tag = value 형태이다. 구성 요소명(컬럼 명)은 tag 이름으로 또는 deparsed 인수 자체로 생성된다. row.names = : NULL, 단일 정수, 또는 행 이름으로 사용될 컬럼을 지정하는 문자열, 또는 데이터 프레임을 위한 행 이름을 주는 문자 또는 정수 벡터 check.rows = : FALSE 값이 디폴트 값. TRUE이면, 행들에 대한 길이와 이름에 대한 일관성 검토하고 위배되면 데이터 프레임을 생성하지 않는다. check.names = : 논리값. TRUE이면 데이터 프레임에 있는 변수 이름들이 문법적으로 타당하고 증복이 없는 변수 이름들인지 검토한다. 필요하면 (make.names에 의해) 조정된다. fix.empty.names = : 논리값 이름이 붙여지지 않은 컬럼(someName = arg 형태로 지정되지 않으면)이 자동으로 생성된 이름이나 name”.”을 가지고 있는지를 나타내는 논리값. “” 이름이 유지되어야 하지만 check.names가 false일 때에도 FALSE로 설정되어야 한다. stringsAsFactors = default.stringsAsFactors() : 버전 4.0.0 이후로 기능이 없어짐. 이전 버전의 경우, 디폴트로 문자 벡터 컬럼의 경우 factor 형으로 생성되었음. 2.1.1.3 컬럼명을 지정하지 않은 경우 df1 &lt;- data.frame(1:5, letters[1:5]) str(df1) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ X1.5 : int 1 2 3 4 5 ## $ letters.1.5.: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df1 ## X1.5 letters.1.5. ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e df1의 첫 번째 컬럼의 값은 1:5, 두 번째 컬럼의 값은 letters[1:5]으로 지정하고 있으나, 컬럼명을 지정하지 않음. 자동으로 첫 번째 컬럼명은 x1.5으로 그리고 두 번째 컬럼명은 letters.1.5으로 자동생성된다. df2 &lt;- data.frame(1:5, letters[1:5], fix.empty.names = FALSE) str(df2) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ : int 1 2 3 4 5 ## $ : chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df2 ## ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e fix.empty.names = FALSE 옵션을 설정하면, 컬럼명이 자동생성되지 않고 공란(“”)으로 남는다. 2.1.1.4 컬럼명을 지정한 경우 df3 &lt;- data.frame(a = 1:5, b = letters[1:5]) str(df3) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ a: int 1 2 3 4 5 ## $ b: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df3 ## a b ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e df3는 데이터 값과 더불어 각 컬럼의 이름(a와 b)을 지정하여 생성되었다. 2.1.1.5 row.names을 a로 지정한 경우 df4 &lt;- data.frame(a = 1:5, b = letters[1:5], row.names = &quot;a&quot;) str(df4) ## &#39;data.frame&#39;: 5 obs. of 1 variable: ## $ b: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df4 ## b ## 1 a ## 2 b ## 3 c ## 4 d ## 5 e df4는 row.names = “a”로 a를 행이름으로 지정하고 있다. 따라서 df4를 출력해 보면 a의 값(1:5)들이 행의 이름임을 알 수 있다. 즉, df4는 컬럼이 하나인 데이터 프레임이다. 2.1.1.6 row.names을 b로 지정한 경우 df5 &lt;- data.frame(a = 1:5, b = letters[1:5], row.names = &quot;b&quot;) str(df5) ## &#39;data.frame&#39;: 5 obs. of 1 variable: ## $ a: int 1 2 3 4 5 df5 ## a ## a 1 ## b 2 ## c 3 ## d 4 ## e 5 df5는 row.names = “b”로 b를 행이름으로 지정하고 있다. 따라서 df5를 출력해 보면 b의 값들(letters[1:5])이 행의 이름임을 알 수 있다. 즉, df5는 컬럼이 하나인 데이터 프레임이다. 2.1.1.7 각 컬럼의 행의 길이가 다른 경우 다음과 같이 a컬럼은 요소가 6개, b컬럼은 요소가 5개로 지정되는 경우에는, 데이터 프레임이 생성되지 않는다. 즉, 데이터 세트가 사각형 형태가 안된다. 이러한 데이터 구조를 만들고 싶다면, 리스트 구조를 이용해야 한다. df6 &lt;- data.frame(a = 1:6, b = letters[1:5]) ## Error in data.frame(a = 1:6, b = letters[1:5]): arguments imply differing number of rows: 6, 5 str(df6) ## Error in str(df6): 객체 &#39;df6&#39;를 찾을 수 없습니다 df6 ## Error in eval(expr, envir, enclos): 객체 &#39;df6&#39;를 찾을 수 없습니다 2.1.1.8 컬럼명이 같은 경우 : check.names = 인수의 사용 check.names = TRUE 인수를 사용하는 경우, df7 &lt;- data.frame(a = 1:5, a = letters[1:5], check.names = TRUE) str(df7) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ a : int 1 2 3 4 5 ## $ a.1: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df7 ## a a.1 ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 두 개의 컬럼명이 모두 a로 되어 있다. df7의 경우는 check.names = TRUE로 옵션을 설정하여, 컬럼명이 자동 조정되었다. check.names = FALSE 인수를 사용하는 경우, df8 &lt;- data.frame(a = 1:5, a = letters[1:5], check.names = FALSE) str(df8) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ a: int 1 2 3 4 5 ## $ a: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df8 ## a a ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e 두 개의 컬럼명이 모두 a로 되어 있다. df8의 경우는 check.names = FASLE로 옵션을 설정하여, 컬럼명이 조정되지 않았다. 2.1.2 데이터 프레임의 구조 데이터 프레임의 구조는 str() 함수로 파악할 수 있다. 2.1.2.1 dataframe의 구조(structure) 파악하기 str() 함수에 대한 도움말 보기. ? str() ## starting httpd help server ... done 앞에서 생성한 df1 데이터 보기 : head() 함수 이용 head(df1) ## X1.5 letters.1.5. ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e df1의 데이터 구조 파악하기 : str() 함수 str(df1) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ X1.5 : int 1 2 3 4 5 ## $ letters.1.5.: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... df1의 통계적 요약 정보 파악 : summary() 함수 summary(df1) ## X1.5 letters.1.5. ## Min. :1 Length:5 ## 1st Qu.:2 Class :character ## Median :3 Mode :character ## Mean :3 ## 3rd Qu.:4 ## Max. :5 2.1.2.2 iris 데이터 세트 iris 데이터 세트의 데이터 구조 확인 str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... iris 데이터 세트의 첫 6개 행 데이터 보기 head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa head(iris, n=10) : iris 데이터 세트의 첫 10개 행을 볼 수 있다. n = 인수로 행의 갯수를 조절할 수 있다. tail(iris, n=10) : iris 데이터 세트의 마지막 10개 행을 볼 수 있다. n = 인수로 행의 갯수를 조절할 수 있다. iris 데이터 세트의 통계적 요약 정보 summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## 5개의 컬럼별로 통계적 요약 정보인 min, 1st Qu., Median, Mean, 3rd Qu., Max. 등의 요약 정보를 출력한다. 2.1.3 행/열 추가하기 2.1.3.1 두 벡터를 각각 행(row)으로 하는 데이터 프레임의 생성 두 개의 벡터 데이터 세트 vec1 &lt;- c(&#39;one&#39;,&#39;two&#39;,&#39;three&#39;) vec2 &lt;- c(1,2,3) 두 벡터를 결합하여 데이터 프레임 만들기 d &lt;- data.frame(rbind(vec1,vec2)); d ## X1 X2 X3 ## vec1 one two three ## vec2 1 2 3 str(d) ## &#39;data.frame&#39;: 2 obs. of 3 variables: ## $ X1: chr &quot;one&quot; &quot;1&quot; ## $ X2: chr &quot;two&quot; &quot;2&quot; ## $ X3: chr &quot;three&quot; &quot;3&quot; 데이터 프레임 d의 행 이름은 자동으로 벡터의 이름(vec1, vec2)으로 지정된다. 반면에 컬럼 이름은 x1, x2, x3 등으로 자동 부여된다. 2.1.3.2 두 벡터를 각각 열(column)으로 하는 데이터 프레임의 생성 이번에는, 두 벡터를 각각 column으로 하는 dataframe을 만들고 싶으면? : cbind() 두 개의 벡터 데이터 세트 vec1 &lt;- c(&#39;one&#39;,&#39;two&#39;,&#39;three&#39;); vec1 ## [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; vec2 &lt;- c(1,2,3); vec2 ## [1] 1 2 3 cbind()를 이용하여 두 개 벡터를 컬럼으로 결합하여 vec 데이터 세트를 만든다. vec &lt;- cbind(vec1, vec2); vec ## vec1 vec2 ## [1,] &quot;one&quot; &quot;1&quot; ## [2,] &quot;two&quot; &quot;2&quot; ## [3,] &quot;three&quot; &quot;3&quot; class(vec) ## [1] &quot;matrix&quot; &quot;array&quot; vec는 문자형 행렬/배열 임을 알 수 있다. 결합된 vec 데이터 세트를 data.frame() 함수를 이용하여 데이터 프레임으로 바꾼다. df &lt;- data.frame(vec) df ## vec1 vec2 ## 1 one 1 ## 2 two 2 ## 3 three 3 str(df) ## &#39;data.frame&#39;: 3 obs. of 2 variables: ## $ vec1: chr &quot;one&quot; &quot;two&quot; &quot;three&quot; ## $ vec2: chr &quot;1&quot; &quot;2&quot; &quot;3&quot; 생성된 df의 컬럼 이름은 두 개의 벡터 이름이 자동으로 지정된다. 앞에서 cbind()의 사용은 사족 두 개의 벡터 데이터 세트 vec1 &lt;- c(&#39;one&#39;,&#39;two&#39;,&#39;three&#39;); vec1 ## [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; vec2 &lt;- c(1,2,3); vec2 ## [1] 1 2 3 cbind()를 이용하여 두 개 벡터를 컬럼으로 결합하여 vec 데이터 세트를 만드는 과정을 생략하고, data.frame() 함수에 두 개의 벡터를 입력하여 데이터 프레임을 생성할 수 있다. df &lt;- data.frame(vec1, vec2) df ## vec1 vec2 ## 1 one 1 ## 2 two 2 ## 3 three 3 str(df) ## &#39;data.frame&#39;: 3 obs. of 2 variables: ## $ vec1: chr &quot;one&quot; &quot;two&quot; &quot;three&quot; ## $ vec2: num 1 2 3 vec1 컬럼은 문자형(chr)으로 생성이 되었고, vec2 컬럼은 숫자형(num)으로 생성이 됨을 알 수 있다. 문자형 컬럼을 factor형으로 만들고 싶은 경우에는 stringsAsFactors = T를 인수로 이용한다. df &lt;- data.frame(vec1, vec2, stringsAsFactors = T) df ## vec1 vec2 ## 1 one 1 ## 2 two 2 ## 3 three 3 str(df) ## &#39;data.frame&#39;: 3 obs. of 2 variables: ## $ vec1: Factor w/ 3 levels &quot;one&quot;,&quot;three&quot;,..: 1 3 2 ## $ vec2: num 1 2 3 vec1 컬럼의 데이터 유형이 Factor로 바뀌었다. 2.1.3.3 데이터 프레임에 새로운 컬럼 추가 다음과 같이 새로운 컬럼을 추가할 수도 있다. df &lt;- data.frame(col1=c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;) , col2=c(2, 4, 6, 8, 10)) df$col3 &lt;- c(1,2,3,4,5) df ## col1 col2 col3 ## 1 a 2 1 ## 2 b 4 2 ## 3 c 6 3 ## 4 d 8 4 ## 5 e 10 5 df$col3 &lt;- c(1,2,3,4,5) : 2개의 컬럼으로 구성된 df1에 col3 컬럼을 추가한다. 그 값은 c(1, 2, 3, 4, 5). 2.1.3.4 데이터 프레임의 컬럼 삭제 다음과 같이 기존의 컬럼을 제거할 수 있다. df &lt;- data.frame(col1 = c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;), col2 = c(2, 4, 6, 8, 10)) df$col2 &lt;- NULL df ## col1 ## 1 a ## 2 b ## 3 c ## 4 d ## 5 e 제거하고자 하는 컬럼의 값을 NULL로 대입해 주면 된다. 2.1.4 행과 열 접근하기 2.1.4.1 데이터 세트 df &lt;- data.frame(col1=c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;) , col2=c(2, 4, 6, 8, 10)) 2.1.4.2 컬럼 이름으로 접근하기 df$col1 #column이름으로 접근하기 ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; 2.1.4.3 인덱싱 : 위치(행/열 번호)로 접근하기 행 번호 접근 : 첫번째 행의 모든 열 df[1,] ## col1 col2 ## 1 a 2 [행 번호,열 번호]로 구성되는 대괄호 안에서 열 번호를 생략하면 모든 열을 표시 열 번호 접근 : 2번째 열의 모든 행 df[,2] ## [1] 2 4 6 8 10 [행 번호,열 번호]로 구성되는 대괄호 안에서 행 번호를 생략하면 모든 행을 표시 2.1.5 연습문제 R에 기본 내장되어 있는 iris 데이터를 활용하여 아래 질문에 답하시오. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa 첫번째, 3번째 컬럼을 선택하시오. head(iris[, c(1, 3)]) ## Sepal.Length Petal.Length ## 1 5.1 1.4 ## 2 4.9 1.4 ## 3 4.7 1.3 ## 4 4.6 1.5 ## 5 5.0 1.4 ## 6 5.4 1.7 3번째 컬럼을 빼고 선택하시오. head(iris[, -3]) ## Sepal.Length Sepal.Width Petal.Width Species ## 1 5.1 3.5 0.2 setosa ## 2 4.9 3.0 0.2 setosa ## 3 4.7 3.2 0.2 setosa ## 4 4.6 3.1 0.2 setosa ## 5 5.0 3.6 0.2 setosa ## 6 5.4 3.9 0.4 setosa 각 row의 Sepal.Length와 Sepal.Width의 값을 더하여 Sepal.Sum이라는 컬럼을 추가하시오. Sepal.Sum &lt;- iris$Sepal.Length + iris$Sepal.Width head(cbind(iris[, -3], Sepal.Sum)) ## Sepal.Length Sepal.Width Petal.Width Species Sepal.Sum ## 1 5.1 3.5 0.2 setosa 8.6 ## 2 4.9 3.0 0.2 setosa 7.9 ## 3 4.7 3.2 0.2 setosa 7.9 ## 4 4.6 3.1 0.2 setosa 7.7 ## 5 5.0 3.6 0.2 setosa 8.6 ## 6 5.4 3.9 0.4 setosa 9.3 참고) df[1,] 과 df[1, ,drop=T]의 차이는? df[1,] ## col1 col2 ## 1 a 2 class(df[1,]) ## [1] &quot;data.frame&quot; df[1,] : df의 첫 번째 행을 출력. 그 결과는 데이터 프레임 df[1, ,drop=T] ## $col1 ## [1] &quot;a&quot; ## ## $col2 ## [1] 2 class(df[1, ,drop=T]) ## [1] &quot;list&quot; df[1, , drop=T] : df의 첫 번째 행을 출력하되, drop=T에 의해 그 결과를 list로 출력함. 2.1.6 행과 열의 이름 지정하기 2.1.6.1 데이터 세트 df &lt;- data.frame(a=1:3,b=4:6,c=7:9); df ## a b c ## 1 1 4 7 ## 2 2 5 8 ## 3 3 6 9 2.1.6.2 컬럼 이름 확인 : colnames() 함수 colnames(df) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; df의 컬럼 이름이 a, b, c 임을 확인할 수 있다. 2.1.6.3 컬럼 이름 변경하기 colnames(df) &lt;- c(&#39;열1&#39;,&#39;열2&#39;,&#39;열3&#39;) colnames(df) ## [1] &quot;열1&quot; &quot;열2&quot; &quot;열3&quot; colnames(df) &lt;- c('열1','열2','열3') : 새로운 컬럼명 지정하기 2.1.6.4 행 이름 확인 : rownames() 함수 rownames(df) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; 2.1.6.5 행 이름 변경하기 rownames(df) &lt;- c(&#39;행1&#39;,&#39;행2&#39;,&#39;행3&#39;) rownames(df) ## [1] &quot;행1&quot; &quot;행2&quot; &quot;행3&quot; 2.1.6.6 행과 열의 이름 동시에 확인하기 : names() 함수 names(df) ## [1] &quot;열1&quot; &quot;열2&quot; &quot;열3&quot; 2.1.7 데이터 타입 변환 2.1.7.1 데이터 타입‘만’ 알고 싶을때 : class() 함수 데이터 타입은 class() 함수로 확인할 수 있다. 숫자형 벡터 class(c(1,2)) ## [1] &quot;numeric&quot; 문자형 벡터 class(c(&quot;a&quot;, &quot;b&quot;)) ## [1] &quot;character&quot; 논리형 벡터 class(c(T, FALSE)) ## [1] &quot;logical&quot; 날짜형 벡터 class(as.Date(c(&quot;2020-09-01&quot;, &quot;2020-09-31&quot;))) ## [1] &quot;Date&quot; 문자형의 날짜를 as.Date() 함수를 이용하여 날짜형(Date)로 변경해야 함. 행렬 class(matrix(c(1,2))) ## [1] &quot;matrix&quot; &quot;array&quot; 행렬은 배열의 특수한 형태임. 리스트 class(list(1,2)) ## [1] &quot;list&quot; list() 함수에 의해 데이터 구조가 리스트로 지정됨. 데이터 프레임 class(data.frame(1,2)) ## [1] &quot;data.frame&quot; 2.1.7.2 데이터 타입과 데이터 모양에 대한 추가정보까지 : str() 함수 str() 함수는 데이터의 구조에 대한 요약 정보를 보여준다. 2.1.7.2.1 숫자형 벡터 str(c(1,2)) ## num [1:2] 1 2 데이터 유형(num)과 요소의 갯수([1:2]), 그리고 데이터 값( 1 2 ) 등을 확인할 수 있다. 2.1.7.2.2 행렬 str(matrix(c(1,2))) ## num [1:2, 1] 1 2 데이터 유형(num), 요소의 갯수([1:2, 1]), 여기서 행의 갯수는 [1:2], 열의 갯수가 1개 임., 그리고 데이터 값( 1 2 ) 등을 확인할 수 있다. 2.1.7.2.3 리스트 str(list(c(1,2))) ## List of 1 ## $ : num [1:2] 1 2 List of 1 : 데이터 구조가 List'형, 컬럼의 갯수는1`개 $ : num [1:2] 1 2 : 컬럼 명이 지정되어 있지 않으며($ 다음에 컬럼 이름이 표시됨), 데이터 유형은 num, 요소의 갯수는 [1:2], 실제 데이터는 1 2 2.1.7.2.4 데이터 프레임 str(data.frame(1,2)) ## &#39;data.frame&#39;: 1 obs. of 2 variables: ## $ X1: num 1 ## $ X2: num 2 'data.frame': 1 obs. of 2 variables: : 데이터 구조는 data.frame, 행의 갯수는 1개(1 obs.), 열의 갯수는 2개(2 variables) $ X1: num 1 : 첫 번째 열은 X1($ X1), 이 열의 데이터 유형은 숫자형(num), 값은 1 $ X2: num 2 : 두 번째 열은 X2($ X2), 이 열의 데이터 유형은 숫자형(num), 값은 2 2.1.7.3 데이터 유형만 확인 2.1.7.3.1 숫자형 확인 : is.numeric() 함수 숫사형 벡터의 확인 is.numeric(c(1,2,3)) ## [1] TRUE 문자형 벡터의 확인 is.numeric(c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;)) ## [1] FALSE 2.1.7.3.2 행렬 확인 : is.matrix() 함수 is.matrix(matrix(c(1,2))) ## [1] TRUE 2.1.7.3.3 관련 함수들 다음 함수들을 사용하여 데이터 타입을 손쉽게 판단할 수 있다. 함수 설명 is.factor(x) 주어진 객체 x가 팩터인가 is.numeric(x) 주어진 객체 x가 숫자를 저장한 벡터인가 is.character(x) 주어진 객체 x가 문자열을 저장한 벡터인가 is.matrix(x) 주어진 객체 x가 행렬인가 is.array(x) 주어진 객체 x가 배열인가 is.data.frame(x) 주어진 객체 x가 데이터 프레임인가 2.1.7.4 데이터 구조간의 변환 2.1.7.4.1 list를 vector로 lst &lt;- list(1,2,3,4) unlist(lst) ## [1] 1 2 3 4 2.1.7.4.2 list를 dataframe으로 lst &lt;- list(x=c(1,2),y=c(3,4)) data.frame(lst) ## x y ## 1 1 3 ## 2 2 4 2.1.7.4.3 matrix를 데이터 프레임으로 mat &lt;- matrix(c(1,2,3,4), ncol=2) data.frame(mat) ## X1 X2 ## 1 1 3 ## 2 2 4 2.1.7.4.4 벡터를 factor로, factor를 벡터 문자열을 Factor로 x &lt;- c(&quot;m&quot;,&quot;f&quot;) as.factor(x) ## [1] m f ## Levels: f m Levels 로 Factor임을 확인함. Factor를 다시 숫자형으로 as.numeric(as.factor(x)) ## [1] 2 1 타입을 강제로 변환(Coercing)하고자 할 때도 있을 것이다. 문자열 벡터를 팩터로 변환하는 경우 등이 그 예다. 이러한 변환을 하는 한 가지 방법은 타입 이름이 ‘typename’이라 할 때 ‘as.typename( )’이라는 함수를 사용하는 것이다. 2.1.7.4.5 관련 함수 목록 다음에 관련 함수의 목록을 보였다. 함수 의미 as.factor(x) 주어진 객체 x를 팩터로 변환 as.numeric(x) 주어진 객체 x를 숫자를 저장한 벡터로 변환 as.character(x) 주어진 객체 x를 문자열을 저장한 벡터로 변환 as.matrix(x) 주어진 객체 x를 행렬로 변환 as.array(x) 주어진 객체 x를 배열로 변환 as.data.frame(x) 주어진 객체 x를 데이터 프레임으로 변환 2.1.8 연습문제 남, 여를 1,2 로 바꿔보자 vec &lt;- c(&#39;남&#39;,&#39;여&#39;,&#39;남&#39;,&#39;남&#39;,&#39;여&#39;) vec &lt;- ifelse(vec == &quot;남&quot;, &quot;여&quot;, &quot;남&quot;); vec ## [1] &quot;여&quot; &quot;남&quot; &quot;여&quot; &quot;여&quot; &quot;남&quot; 참고 : 남, 여를 2, 1 로 바꾸면? vec &lt;- c(&#39;남&#39;,&#39;여&#39;,&#39;남&#39;,&#39;남&#39;,&#39;여&#39;) as.numeric(factor(vec, levels=c(&#39;여&#39;,&#39;남&#39;))) ## [1] 2 1 2 2 1 2.1.9 실습 과제 첨부한 파일을 다운 받고 R에서 변수 data로 불러들여라. toyota_sample.csv data &lt;- read_csv(&quot;https://insightteller.tistory.com/attachment/cfile2.uf@99A3723359F55A7E16D9D1.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## Id = col_double(), ## Model = col_character(), ## Price = col_double(), ## Age = col_double(), ## Mfg_Month = col_double(), ## Mfg_Year = col_double(), ## KM = col_double(), ## Fuel_Type = col_character() ## ) data ## # A tibble: 7 x 8 ## Id Model Price Age Mfg_Month Mfg_Year KM Fuel_Type ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 TOYOTA Corolla 2.0 D4D H~ 13500 23 10 2002 46986 Diesel ## 2 2 TOYOTA Corolla 2.0 D4D H~ 13750 23 10 2002 72937 Diesel ## 3 3 TOYOTA Corolla 2.0 D4D H~ 13950 24 9 2002 41711 Diesel ## 4 4 TOYOTA Corolla 2.0 D4D H~ 14950 26 7 2002 48000 Diesel ## 5 5 TOYOTA Corolla 2.0 D4D H~ 13750 30 3 2002 38500 Diesel ## 6 6 TOYOTA Corolla 2.0 D4D H~ 12950 32 1 2002 61000 Diesel ## 7 7 ?TOYOTA Corolla 2.0 D4D ~ 16900 27 6 2002 94612 Diesel 2.1.10 apply() 함수 이해하기 행렬 혹은 data.frame에서 각 row, column에 대해 평균을 계산한다든지, 특정 함수를 적용하고 싶을 때가 있다. 이럴 때, 가장 기본적으로 생각하는 게 for() loop를 활용하여 각 row(혹은 column) 별로 함수를 적용하는 것이다. 예를 들어, mat &lt;- matrix(c(1,2,3,4,5,6,7,8,9), nrow=3) # 각 row의 평균을 계산하고 싶다면 for (i in seq(1:nrow(mat))){ print(mean(mat[i,])) } ## [1] 4 ## [1] 5 ## [1] 6 그런데 많은 양의 데이터를 for() loop 하는 것은 비효율적이다. 매번 for() loop를 돌 때마다 함수를 불러와야 하기 때문이다. 따라서 최대한 for() loop를 줄이는 것이 중요하다!! 그 때 사용하는 함수가 바로 apply() 함수이다. apply() 함수는 한 번만 함수를 불러와서 모든 데이터에 적용하기 때문에 훨씬 시간을 줄일 수 있다. 2.1.10.1 데이터 세트 mat &lt;- matrix(c(1,2,3,4,5,6,7,8,9), nrow=3) 2.1.10.2 행별로 함수 적용 : margin = 1 mat 데이터 세트의 행별(1) 평균값(mean) 산출 apply(mat, 1, mean) # mean이라는 함수를 row(1)로 적용 ## [1] 4 5 6 mat 데이터 세트의 행별(1) 범위(range) 산출 apply(mat, 1, range) # range 함수는 각행의 최소, 최댓값 2개를 반환함 ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 7 8 9 2.1.10.3 열별로 함수 적용 : margin = 2 mat 데이터 세트의 열별(2) 평균값(mean) 산출 apply(mat, 2, mean) # mean이라는 함수를 column(2) 별로 적용 ## [1] 2 5 8 2.1.11 연습문제 iris 데이터 세트에 적용해보자 apply() 함수를 활용하여 iris의 Species를 제외한 4개 변수에 대해 평균을 아래와 같이 계산하라. apply(iris[, -5], 2, mean) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 5.843333 3.057333 3.758000 1.199333 apply() 함수를 활용하여 Sepal.Length, Sepal.Width의 최소, 최대값을 아래와 같이 구하라. (최소, 최댓값을 구하는 함수는 range) apply(iris[, c(1,2)], 2, range) ## Sepal.Length Sepal.Width ## [1,] 4.3 2.0 ## [2,] 7.9 4.4 2.1.11.1 list, 벡터에 대한 for loop 계산 데이터 프레임과 마찬가지로 list, vector에 대해서도 for() loop를 최소화 하는 것이 좋다. 대신, apply()와 비슷하게 lapply(), sapply()를 사용한다. 좀 더 구체적으로 예를 들어보면, list(1,2,3)을 제곱한 값을 반환하고 싶다고 하자. 그런데 아래와 같이 계산하면 실행이 안 된다. list는 vector처럼 연산 함수가 적용되지 않기 떄문이다. 2.1.11.2 lapply() 함수와 sapply() 함수 이럴 때, for() loop이 아닌 lapply() 함수 또는 sapply()함수를 사용한다. `lapply(벡터 혹은 리스트, 함수)` `sapply(벡터 혹은 리스트, 함수)` 2.1.11.2.1 lapply() 함수 앞에 예를 들었듯이, list(1,2,3)을 제곱하고 싶다면, lst &lt;- list(1,2,3) lapply(lst, function(x){x^2}) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 9 2.1.11.2.2 sapply() 함수 그런데 lapply()의 결과는 list로 나오기 때문에, 벡터로 나오게 하고 싶다면 sapply()를 이용한다. sapply(lst, function(x){x^2}) ## [1] 1 4 9 2.1.11.2.3 iris 데이터 세트의 예 lapply() 함수를 이용하여, 모든 행에 대하여 1:4열의 합계(sum)를 구한다. lst &lt;- lapply(iris[, 1:4], sum) class(lst) ## [1] &quot;list&quot; sapply() 함수를 이용하여, 모든 행에 대하여 1:4열의 합계(sum)를 구한다. vec &lt;- sapply(iris[,1:4], sum) class(vec) ## [1] &quot;numeric&quot; lapply(), sapply()도 data.frame 에 적용할 수 있는데, apply()는 결과값이 data.frame인 반면, lapply(), sapply()는 결과값이 각각 list, vector 라는 차이가 있다. 그리고 기본적으로 각 column에 대해 함수가 적용된다. 좀 더 예를 들면, iris 데이터 세트의 각 열의 데이터 타입을 보고 싶다면? sapply(iris, class) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;numeric&quot; &quot;factor&quot; 3보다 큰 값을 갖는지 확인 y &lt;- sapply(iris[, 1:4], function(x){ x &gt; 3 }) head(y) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## [1,] TRUE TRUE FALSE FALSE ## [2,] TRUE FALSE FALSE FALSE ## [3,] TRUE TRUE FALSE FALSE ## [4,] TRUE TRUE FALSE FALSE ## [5,] TRUE TRUE FALSE FALSE ## [6,] TRUE TRUE FALSE FALSE 2.1.12 연습문제 iris 데이터를 0~1 사이 값으로 바꿔라. hint: 서로 다른 변수의 데이터가 scale이 다를 경우(어떤 변수는 -10~0 사이인데, 다른 변수는 10~1000인 경우), 정규분포를 활용한 정규화 뿐만 아니라, min, max를 활용하여 0~1사이로 바꾸는 방법도 있다. 즉, 다음 함수를 각 row에 적용하면 된다. (xmin(x)) / (max(x)min(x)) min &lt;- sapply(iris[, -5], min); min ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 4.3 2.0 1.0 0.1 max &lt;- sapply(iris[, -5], max); max ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 7.9 4.4 6.9 2.5 ran &lt;- max - min; ran ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 3.6 2.4 5.9 2.4 x &lt;- apply(iris[, -5], 1, function(x) {(x - min) / ran}) head(t(x)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## [1,] 0.22222222 0.6250000 0.06779661 0.04166667 ## [2,] 0.16666667 0.4166667 0.06779661 0.04166667 ## [3,] 0.11111111 0.5000000 0.05084746 0.04166667 ## [4,] 0.08333333 0.4583333 0.08474576 0.04166667 ## [5,] 0.19444444 0.6666667 0.06779661 0.04166667 ## [6,] 0.30555556 0.7916667 0.11864407 0.12500000 2.1.13 apply() 함수의 사촌들 이제부터는 apply() 함수와 비슷한 원리지만, 각 상황에 맞게 tapply(), mapply() 가 있는데, 자주 사용되지는 않지만, 간단히 살펴보기로 한다. 2.1.13.1 tapply() tapply() : 각 집단에 따라 데이터를 처리하고 싶을때 str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... tapply(iris$Sepal.Length, iris$Species, mean) ## setosa versicolor virginica ## 5.006 5.936 6.588 2.1.14 연습문제 Species 별 Sepal.Width 의 분산은? tapply(iris$Sepal.Width, iris$Species, var) ## setosa versicolor virginica ## 0.14368980 0.09846939 0.10400408 2.1.14.1 mapply() 여러 벡터에 동일한 함수를 적용하고 싶을때 사용한다. 아래와 같이 최대공약수를 구하는 함수 gcd()가 있다고 하자. gcd &lt;- function(a,b) { if (b==0) return(a) else return(gcd(b, a%%b)) } gcd(6,4) ## [1] 2 그러나, 아래와 같이 두 벡터의 각 원소간 값을 input으로 하고 싶을때 아래와 같은 문법은 오류가 발생합니다. gcd(c(3,6,9), c(12,15,18)) ## Warning in if (b == 0) return(a) else return(gcd(b, a%%b)): length &gt; 1 이라는 조 ## 건이 있고, 첫번째 요소만이 사용될 것입니다 ## Warning in if (b == 0) return(a) else return(gcd(b, a%%b)): length &gt; 1 이라는 조 ## 건이 있고, 첫번째 요소만이 사용될 것입니다 ## Warning in if (b == 0) return(a) else return(gcd(b, a%%b)): length &gt; 1 이라는 조 ## 건이 있고, 첫번째 요소만이 사용될 것입니다 ## [1] 3 6 9 이 경우 mapply() 함수 활용 mapply(gcd, c(3,6,9), c(12,15,18)) ## [1] 3 3 9 **최대공약수 함수** : 여기서 중요한 부분은 “**유클리드 호제법**”이다. 간단히 말하자면, &quot;**두 양의 정수 A &gt;= B에 대해, A가 B의 배수인 경우에 최대공약수는 B이며, 그렇지 않은 경우에는 최대공약수는 B와 A%%B (A를 B로 나눈 나머지)의 최대공약수이다.**&quot;라고 할 수 있습니다. 이를 코드로 표현하면 다음과 같다. gcd &lt;- function(a,b) { if (b==0) return(a) else return(gcd(b, a%%b)) } 출처: https://kjwsx23.tistory.com/259 [香格里拉] [참고 : Sampling] 기계학습 모델링을 사용하다 보면, 무작위로 데이터를 추출해야 할 경우가 생긴다. 이럴 때 sample() 함수를 사용한다. # 1~10에서 무작위로 5개 추출 sample(1:10, 5) # 중복 허락 하지 않고. ## [1] 5 3 7 10 2 sample(1:10, 5, replace=T) # 중복을 허락해서 추출 ## [1] 6 4 8 4 10 iris 데이터에서 임의로 전체의 15% 데이터 추출하기 index &lt;- 1:nrow(iris) # 1부터 iris 행의 개수 train_idx &lt;- sample(index, round(nrow(iris)*0.15)) head(iris[train_idx,]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 150 5.9 3.0 5.1 1.8 virginica ## 89 5.6 3.0 4.1 1.3 versicolor ## 39 4.4 3.0 1.3 0.2 setosa ## 52 6.4 3.2 4.5 1.5 versicolor ## 149 6.2 3.4 5.4 2.3 virginica ## 23 4.6 3.6 1.0 0.2 setosa 출처: https://insightteller.tistory.com/entry/R-기초-실습-3-dataframe?category=628138 [Be a Insight teller] Reference Concatenating a list of data frames 2.2 tibble 티블(tibbles)은 데이터 프레임을 현대적으로 재구성한 것이다. 이것은 시간 성능 테스트를 통과했고, 데이터 프레임이 가지고 있던 편리했지만 지금은 불만스러운 특징들(예를 들어, 문자 벡터를 factor 형으로 변환하는 것)을 제거하고 있다. 티블은 tidyverse 생태계를 구성하는 한 멤버로 tidyverse를 설치하게 되면 즉시 활용할 수 있다. 데이터프레임을 생성하고, 강제변환시키고, 외부 데이터를 데이터프레임으로 가져오는 방법에 사용되는 함수를 비교하면 다음과 같다. 작업유형 데이터프레임 명령어 티블 명령어 생성 data.frame() data_frame(), tibble(), tribble() 강제변환 (Coercion) as.data.frame() as_tibble() 데이터 불러오기 read.*() read_delim(), read_csv(), read_csv2(), read_tsv() 2.2.1 티블 생성 tibble() 은 데이터 프레임을 생성하는 좋은 방법이다. 데이터 프레임의 좋은 점들을 압축하고 있다. tribble() 함수를 사용해서 좀 더 직관적으로 데이터프레임을 생성할 수도 있다. 2.2.1.1 데이터 프레임과 티블 생성 2.2.1.1.1 데이터프레임(data.frame)의 생성 : data.frame() 함수 df &lt;- data.frame(1:5, letters[1:5]) str(df) ## &#39;data.frame&#39;: 5 obs. of 2 variables: ## $ X1.5 : int 1 2 3 4 5 ## $ letters.1.5.: chr &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... 2.2.1.1.2 티블(tibble)**의 생성 : tibble() 함수 벡터 데이터 세트 a_value &lt;- 1:5; a_value ## [1] 1 2 3 4 5 b_value &lt;- letters[1:5]; b_value ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; 벡터 결합에 의한 티블의 생성 tb1 &lt;- tibble(a = a_value, b = b_value); tb1 ## # A tibble: 5 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e str(tb1) ## tibble [5 x 2] (S3: tbl_df/tbl/data.frame) ## $ a: int [1:5] 1 2 3 4 5 ## $ b: chr [1:5] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; ... 티블의 생성 tb2 &lt;- tribble( ~a, ~b, #---|---- 1, &quot;a&quot;, 2, &quot;b&quot;) tb2 ## # A tibble: 2 x 2 ## a b ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b str(tb2) ## tibble [2 x 2] (S3: tbl_df/tbl/data.frame) ## $ a: num [1:2] 1 2 ## $ b: chr [1:2] &quot;a&quot; &quot;b&quot; ~a, ~b : 컬럼의 지정 #---|---- : 컬럼 이름과 데이터 구분을 위해 삽입. #로 R은 주석 처리함. 1, \"a\", : 이하는 데이터 값 2.2.1.2 데이터 프레임을 티블로 변환하기 : as_tibble() 함수 데이터프레임을 티블로 강제 변환해야 할 경우가 있다. as_tibble() 를 사용하면 된다. str(iris) # 데이터 프레임 ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... str(as_tibble(iris)) # 티블 ## tibble [150 x 5] (S3: tbl_df/tbl/data.frame) ## $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... 2.2.1.3 개별 벡터를 티블로 만들기 tibble() 을 사용하여 개별 벡터로부터 새로운 티블을 만들 수 있다. tibble() 은 길이가 1인 입력을 자동으로 재사용하며, 여기에서 보이는 것처럼, 방금 만든 변수를 참조할 수도 있다. tb1 &lt;- tibble( x = 1:5, y = 1, z = x ^ 2 + y ) tb1 ## # A tibble: 5 x 3 ## x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 2 ## 2 2 1 5 ## 3 3 1 10 ## 4 4 1 17 ## 5 5 1 26 z 컬럼은 계산된 컬럼(computed column)이다. 2.2.1.4 tribble()로 티블 만들기 티블을 만드는 또 다른 방법은 tribble() (전치된(transposed) 티블의 줄임말)을 사용하는 것이다. tribble() 은 코드로 데이터 입력을 하기 위해 고안되었다. 열 헤더는 공식으로 정의되고 (즉, ~로 시작), 데이터은 쉼표로 구분된다. 이렇게 하면 적은 양의 데이터를 읽기 쉬운 형태로 배치할 수 있다. 2.2.1.4.1 티블 생성 tribble( ~x, ~y, ~z, #--|--|---- &quot;a&quot;, 2, 3.6, &quot;b&quot;, 1, 8.5 ) ## # A tibble: 2 x 3 ## x y z ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 2 3.6 ## 2 b 1 8.5 컬럼명을 지정할 때, ~ 를 이용한다. 각 컬럼의 데이터 타입( &lt;chr&gt;, &lt;dbl&gt;, &lt;dbl&gt; )은 자동으로 인식하여 결정된다. 2.2.1.5 tibble()의 특징 data.frame() 에 비해 tibble() 은 동작의 규모가 훨씬 작다는 것에 주의해야 한다. 즉, 입력의 유형을 절대로 변경하지 않고 (예를 들어, 문자열을 팩터형으로 변환하지 않는다!), 변수의 이름을 바꾸거나, 행 이름을 생성하지 않는다. tibble()은 입력 데이터의 데이터 타입을 변경하지 않는다. (즉, stringsAsFactors = FALSE이 필요하지 않다!). 문자형 변수를 이용하는데 보다 편리하다. letters ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; tibble(x = letters) ## # A tibble: 26 x 1 ## x ## &lt;chr&gt; ## 1 a ## 2 b ## 3 c ## 4 d ## 5 e ## 6 f ## 7 g ## 8 h ## 9 i ## 10 j ## # ... with 16 more rows 이러한 점이 list 형 컬럼의 사용을 용이하게 해 준다: tbl &lt;- tibble(x = 1:3, y = list(1:5, 1:10, 1:20)) tbl$y ## [[1]] ## [1] 1 2 3 4 5 ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[3]] ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 tbl$y[1] ## [[1]] ## [1] 1 2 3 4 5 tbl$y[[1]] ## [1] 1 2 3 4 5 list 형의 컬럼은 do() 함수에 의해 보통 생성되지만, 수작업으로 생성하는 것이 유용할 수 있다. do() 함수의 이용 예 : [참고 바람] by_cyl &lt;- group_by(mtcars, cyl) do(by_cyl, head(., 2)) ## # A tibble: 6 x 11 ## # Groups: cyl [3] ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## 2 24.4 4 147. 62 3.69 3.19 20 1 0 4 2 ## 3 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 4 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 5 18.7 8 360 175 3.15 3.44 17.0 0 0 3 2 ## 6 14.3 8 360 245 3.21 3.57 15.8 0 0 3 4 models &lt;- by_cyl %&gt;% do(mod = lm(mpg ~ disp, data = .)) models ## # A tibble: 3 x 2 ## # Rowwise: ## cyl mod ## &lt;dbl&gt; &lt;list&gt; ## 1 4 &lt;lm&gt; ## 2 6 &lt;lm&gt; ## 3 8 &lt;lm&gt; summarise(models, rsq = summary(mod)$r.squared) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 3 x 1 ## rsq ## &lt;dbl&gt; ## 1 0.648 ## 2 0.0106 ## 3 0.270 models %&gt;% do(data.frame(coef = coef(.$mod))) ## # A tibble: 6 x 1 ## # Rowwise: ## coef ## &lt;dbl&gt; ## 1 40.9 ## 2 -0.135 ## 3 19.1 ## 4 0.00361 ## 5 22.0 ## 6 -0.0196 models %&gt;% do(data.frame( var = names(coef(.$mod)), coef(summary(.$mod))) ) ## # A tibble: 6 x 5 ## # Rowwise: ## var Estimate Std..Error t.value Pr...t.. ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 40.9 3.59 11.4 0.00000120 ## 2 disp -0.135 0.0332 -4.07 0.00278 ## 3 (Intercept) 19.1 2.91 6.55 0.00124 ## 4 disp 0.00361 0.0156 0.232 0.826 ## 5 (Intercept) 22.0 3.35 6.59 0.0000259 ## 6 disp -0.0196 0.00932 -2.11 0.0568 models &lt;- by_cyl %&gt;% do( mod_linear = lm(mpg ~ disp, data = .), mod_quad = lm(mpg ~ poly(disp, 2), data = .) ) models ## # A tibble: 3 x 3 ## # Rowwise: ## cyl mod_linear mod_quad ## &lt;dbl&gt; &lt;list&gt; &lt;list&gt; ## 1 4 &lt;lm&gt; &lt;lm&gt; ## 2 6 &lt;lm&gt; &lt;lm&gt; ## 3 8 &lt;lm&gt; &lt;lm&gt; compare &lt;- models %&gt;% do(aov = anova(.$mod_linear, .$mod_quad)) compare$aov ## [[1]] ## Analysis of Variance Table ## ## Model 1: mpg ~ disp ## Model 2: mpg ~ poly(disp, 2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 9 71.509 ## 2 8 47.784 1 23.726 3.9722 0.08139 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## [[2]] ## Analysis of Variance Table ## ## Model 1: mpg ~ disp ## Model 2: mpg ~ poly(disp, 2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 5 12.5424 ## 2 4 7.4506 1 5.0918 2.7336 0.1736 ## ## [[3]] ## Analysis of Variance Table ## ## Model 1: mpg ~ disp ## Model 2: mpg ~ poly(disp, 2) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 12 62.183 ## 2 11 47.551 1 14.632 3.3848 0.09292 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 tibble()은 변수의 이름을 조정하지 않는다. 티블은 R 변수명으로는 유효하지 않은 이름(비구문론적 이름)도 열 이름으로 가질 수 있다. 예를 들어, 문자로 시작하지 않거나 공백과 같은 비정상적인 문자가 포함될 수 있다. 이 변수들을 참조하려면 역따옴표(backticks, ``)로 감싸야 한다. names(data.frame(&quot;crazy name&quot; = 1)) ## [1] &quot;crazy.name&quot; names(tibble(&#39;crazy name&#39; = 1)) ## [1] &quot;crazy name&quot; tb &lt;- tibble( `:)` = &quot;smile&quot;, ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) tb ## # A tibble: 1 x 3 ## `:)` ` ` `2000` ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 smile space number - `names(data.frame(&quot;crazy name&quot; = 1))`와 같이 데이터 프레임의 경우는 컬럼명에 공란을 허용하지 않으며, 자동으로 공란을 점(`.`)으로 변경하여 `crazy.name`으로 컬럼명을 조정한다. - `names(tibble(&#39;crazy name&#39; = 1))`와 같이 `tibble()` 함수는 공란이 있는 컬럼명을 허용한다. - `tb`의 경우, 컬럼명에 기호, 공란 그리고 숫자 등이 허용됨을 알 수 있다. 다만, 컬럼명을 지정할 때 역따옴표(` )를 사용한다. - `ggplot2`, `dplyr` 및 `tidyr` 과 같은 다른 패키지에서 이러한 변수로 작업할 때도 역따옴표(` )가 필요하다. tibble()은 인수들을 천천히 그리고 순차적으로 평가한다: tibble(x = 1:5, y = x ^ 2) ## # A tibble: 5 x 2 ## x y ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 4 ## 3 3 9 ## 4 4 16 ## 5 5 25 tibble()은 row.names()를 사용하지 않는다. 타이디 데이터의 중요한 점은 일관되게 변수를 저장한다는 것이다. 따라서 이것은 변수를 특별한 속성으로 저장하지 않는다. tibble() 길이가 1인 벡터만을 리싸이클(recycling, 자동 반복) 한다. 이 보다 더 큰 길이의 벡터를 리싸이클링하는 것은 종종 버그의 원인이 된다. 2.2.2 강제변환(Coercion) tibble()함수를 보완하기 위해, 티블은 오브젝트를 티블로 변환하기 위해 as.data.frame()함수보다 더 단순한 as_tibble()함수를 제공하고 있다. 그리고 실제로 as.data.frame() 함수와 같이 작동하지만 do.call(cbind, lapply(x, data.frame))과 비슷하다. 즉, 각 요소들을 하나의 데이터 프레임으로 변환한 다음 cbind() 함수로 그것들을 함께 결합해 준다. as_tibble()함수가 성능 향상을 위해 작성되었다: l &lt;- replicate(26, sample(100), simplify = FALSE) names(l) &lt;- letters timing &lt;- bench::mark( as_tibble(l), as.data.frame(l), check = FALSE ) timing ## # A tibble: 2 x 6 ## expression min median `itr/sec` mem_alloc `gc/sec` ## &lt;bch:expr&gt; &lt;bch:tm&gt; &lt;bch:tm&gt; &lt;dbl&gt; &lt;bch:byt&gt; &lt;dbl&gt; ## 1 as_tibble(l) 147us 195.6us 4608. 1.8KB 8.26 ## 2 as.data.frame(l) 942us 1.12ms 850. 4.91KB 8.32 as.data.frame()의 처리 속도는 상호작용으로 사용될 때 병목현상의 일어나지 않지만, 하나의 tidy 데이터 프레임에 많은 정제되지 않은 데이터를 입력할 때는 문제가 될 수 있다. 2.2.3 티블과 데이터 프레임의 비교 티블과 데이터 프레임 사이에는 3가지의 중요한 차이점이 있다 : 화면 출력, 서브세팅, 자동 반복 원칙 등 2.2.3.1 화면 출력(Printing) 티블을 출력하면, 처음의 10개 행과 한 화면에 맞게 모든 열을 보여준다. 또한 각 열의 데이터 타입을 요약해서 보여주고, 폰트 스타일과 강조를 위한 색상을 사용한다. tibble(x = -5:1000) ## # A tibble: 1,006 x 1 ## x ## &lt;int&gt; ## 1 -5 ## 2 -4 ## 3 -3 ## 4 -2 ## 5 -1 ## 6 0 ## 7 1 ## 8 2 ## 9 3 ## 10 4 ## # ... with 996 more rows 티블은 큰 데이터 프레임을 화면출력할 때 실수로 콘솔을 넘어가지 않도록 설계되었다. 그러나 때로는 기본 디스플레이보다 더 많은 출력이 필요하곤 한다. 도움이 되는 몇 가지 옵션이 있다. options 를 설정하여 기본 출력 동작을 제어할 수도 있다. options(tibble.print_max = n, tibble.print_min = m): n 행 이상이 있는 경우, m행만 출력한다. 모든 행을 표시하려면 options(dplyr.print_min = Inf) 을 사용하라. # 최소 10줄 options(tibble.print_max = 20, tibble.print_min = 10) tibble(a = 1:26, b = letters) ## # A tibble: 26 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e ## 6 6 f ## 7 7 g ## 8 8 h ## 9 9 i ## 10 10 j ## # ... with 16 more rows # 최소 3줄 options(tibble.print_max = 5, tibble.print_min = 3) tibble(a = 1:26, b = letters) ## # A tibble: 26 x 2 ## a b ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c ## # ... with 23 more rows 첫 번째 티블의 경우, 행의 갯수가 26개로 20개(`tibble.print_max = 20)를 초과하므로, 10개의 행(tibble.print_min = 10)만 출력하고 있다. 두 번째 티블의 경우, 행의 갯수가 26개로 5개(`tibble.print_max = 5)를 초과하므로, 3개의 행(tibble.print_min = 3)만 출력하고 있다. options(tibble.width = Inf) 을 사용하면 화면 너비와 상관없이 모든 열을 출력한다. nycflights13::flights %&gt;% print(n = 10, width = Inf) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## 7 2013 1 1 555 600 -5 913 854 ## 8 2013 1 1 557 600 -3 709 723 ## 9 2013 1 1 557 600 -3 838 846 ## 10 2013 1 1 558 600 -2 753 745 ## arr_delay carrier flight tailnum origin dest air_time distance hour minute ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 11 UA 1545 N14228 EWR IAH 227 1400 5 15 ## 2 20 UA 1714 N24211 LGA IAH 227 1416 5 29 ## 3 33 AA 1141 N619AA JFK MIA 160 1089 5 40 ## 4 -18 B6 725 N804JB JFK BQN 183 1576 5 45 ## 5 -25 DL 461 N668DN LGA ATL 116 762 6 0 ## 6 12 UA 1696 N39463 EWR ORD 150 719 5 58 ## 7 19 B6 507 N516JB EWR FLL 158 1065 6 0 ## 8 -14 EV 5708 N829AS LGA IAD 53 229 6 0 ## 9 -8 B6 79 N593JB JFK MCO 140 944 6 0 ## 10 8 AA 301 N3ALAA LGA ORD 138 733 6 0 ## time_hour ## &lt;dttm&gt; ## 1 2013-01-01 05:00:00 ## 2 2013-01-01 05:00:00 ## 3 2013-01-01 05:00:00 ## 4 2013-01-01 05:00:00 ## 5 2013-01-01 06:00:00 ## 6 2013-01-01 05:00:00 ## 7 2013-01-01 06:00:00 ## 8 2013-01-01 06:00:00 ## 9 2013-01-01 06:00:00 ## 10 2013-01-01 06:00:00 ## # ... with 336,766 more rows 2.2.3.2 서브세팅(Subsetting) 티블은 data.frame 보다 좀 더 엄격하다. 절대로 부분 매칭을 사용하지 않으며, 접근하려는 열이 존재하지 않는 경우에는 경고를 생성한다. 변수 하나(단일 열)를 추출하려면 새로운 도구인 $ 및 [[]] 이 필요하다. [[]] 는 이름이나 위치로 추출할 수 있다. $ 는 이름으로만 추출할 수 있지만 타이핑을 조금 덜 해도 된다. 2.2.3.2.1 데이터 세트 set.seed(1234) df &lt;- tibble( x = runif(5), y = rnorm(5) ) df ## # A tibble: 5 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.114 0.359 ## 2 0.622 -0.730 ## 3 0.609 0.0357 ## 4 0.623 0.113 ## 5 0.861 1.43 2.2.3.2.2 이름으로 추출 df$x ## [1] 0.1137034 0.6222994 0.6092747 0.6233794 0.8609154 df[[&quot;x&quot;]] ## [1] 0.1137034 0.6222994 0.6092747 0.6233794 0.8609154 2.2.3.2.3 위치로 추출 df[[1]] ## [1] 0.1137034 0.6222994 0.6092747 0.6233794 0.8609154 2.2.3.2.4 파이프 연산자(%&gt;%)의 사용 파이프 연산자(%&gt;%)를 사용하는 경우, 특별한 플레이스홀더(placeholder)인 .를 사용해야 한다. df %&gt;% .$x ## [1] 0.1137034 0.6222994 0.6092747 0.6233794 0.8609154 df %&gt;% .[[&quot;x&quot;]] ## [1] 0.1137034 0.6222994 0.6092747 0.6233794 0.8609154 2.2.3.2.5 []의 사용 []는 항상 또 다른 티블을 반환한다. 이러한 특징을 데이터 프레임과 비교하면, 데이터 프레임은 어떨 때는 데이터 프레임을 또 어떨 때는 벡터를 반환한다: # data.frame() 함수 df1 &lt;- data.frame(x = 1:3, y = 3:1) class(df1[, 1:2]) # 데이터 프레임 ## [1] &quot;data.frame&quot; class(df1[, 1]) # 벡터 ## [1] &quot;integer&quot; # tibble() 함수 df2 &lt;- tibble(x = 1:3, y = 3:1) class(df2[, 1:2]) # tibble ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; class(df2[, 1]) # tibble ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 2.2.3.2.6 $의 사용 티블은 $를 사용하는데 있어서 엄격하다. 절대로 부분 매칭을 사용하지 않으며, 접근하려는 열이 존재하지 않는 경우에는 경고를 생성하거나 NULL을 반환한다. # data.frame() 함수 df &lt;- data.frame(abc = 1) df$a # &#39;abc&#39; 열의 첫 글자로 부분 매칭을 함 ## [1] 1 # tibble() 함수 df2 &lt;- tibble(abc = 1) df2$a # NULL과 경고메시지 출력 ## Warning: Unknown or uninitialised column: `a`. ## NULL df 변수의 경우, data.frame() 함수를 사용하고 있으며, 이 경우 df$a는 abc 컬럼명을 부분 매칭하고 있다. df2 변수의 경우, tibble() 함수를 사용하고 있으며, 이 경우 df$a는 부분 매칭을 허용하지 않는다. 따라서 NULL과 경고 메시지를 출력한다. 2.2.3.2.7 drop = 옵션의 사용 1.4.1 버전 이후, 티블은 더 이상 drop = 인수를 무시하지 않는다: # data.frame() 함수 d1 &lt;- data.frame(a = 1:3) d1[, &quot;a&quot;] ## [1] 1 2 3 d1[, &quot;a&quot;, drop = TRUE] # &#39;drop = TRUE&#39;가 디폴트 ## [1] 1 2 3 d1[, &quot;a&quot;, drop = FALSE] ## a ## 1 1 ## 2 2 ## 3 3 # tibble() 함수 d2 &lt;- tibble(a = 1:3) d2[, &quot;a&quot;] ## # A tibble: 3 x 1 ## a ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 d2[, &quot;a&quot;, drop = TRUE] ## [1] 1 2 3 d2[, &quot;a&quot;, drop = FALSE] # &#39;drop = FALSE&#39;가 디폴트 ## # A tibble: 3 x 1 ## a ## &lt;int&gt; ## 1 1 ## 2 2 ## 3 3 - `d1` 변수의 경우, `data.frame()` 함수를 사용하여 생성되었으며, 이 경우 요소 검색 시에 `drop = TRUE` 옵션이 작동하지 않는다. - `d2` 변수의 경우, `tibble()` 함수를 사용하여 생성되었으며, 이 경우 요소 검색 시에 `drop = TRUE` 옵션이 작동한다. 2.2.3.3 자동 반복 (Recycling) 티블을 생성할 때 오직 길이가 1인 값만이 자동 반복된다. 길이가 1이 아닌 첫 번째 열이 티블의 행 갯수를 결정하며, 충돌이 되면 에러가 발생한다. 이러한 점은 또한 때때로 프로그램에 있어서 중요한 0 개의 행을 가진 티블로 확장된다: tibble(a = 1, b = 1:3) ## # A tibble: 3 x 2 ## a b ## &lt;dbl&gt; &lt;int&gt; ## 1 1 1 ## 2 1 2 ## 3 1 3 tibble(a = 1:3, b = 1) ## # A tibble: 3 x 2 ## a b ## &lt;int&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 1 ## 3 3 1 # tibble(a = 1:3, c = 1:2) # Error : Tibble columns must have compatible sizes. tibble(a = 1, b = integer()) # A tibble: 0 x 2 (0행, 2열) ## # A tibble: 0 x 2 ## # ... with 2 variables: a &lt;dbl&gt;, b &lt;int&gt; tibble(a = integer(), b = 1) # A tibble: 0 x 2 (0행, 2열) ## # A tibble: 0 x 2 ## # ... with 2 variables: a &lt;int&gt;, b &lt;dbl&gt; 2.2.4 이전 코드와 상호작용 일부 오래된 함수는 티블에서 동작하지 않는다. 이러한 함수를 사용하려면 as.data.frame() 를 사용하여 티블을 data.frame 으로 되돌려야 한다. tb &lt;- tibble( `:)` = &quot;smile&quot;, ` ` = &quot;space&quot;, `2000` = &quot;number&quot; ) tb1 &lt;- as.data.frame(tb) tb1 ## :) 2000 ## 1 smile space number str(tb1) ## &#39;data.frame&#39;: 1 obs. of 3 variables: ## $ :) : chr &quot;smile&quot; ## $ : chr &quot;space&quot; ## $ 2000: chr &quot;number&quot; class(tb1) ## [1] &quot;data.frame&quot; - 오래된 함수 중 일부가 티블에서 작동하지 않는 주된 이유는 `[` 함수 때문이다. - 여기에서는 `[` 를 많이 사용하지 않는데, `dplyr::filter()` 와 `dplyr::select()` 가 더 명확한 코드로 해결할 수 있기 때문이다. - ([벡터 서브셋하기](https://sulgik.github.io/r4ds/tibble.html#vector-subsetting)에서 좀 더 자세히 알 수 있다). base R의 데이터프레임을 사용하면 [ 는 어떨 때는 데이터프레임을 반환하고, 또 어떨 때는 벡터를 반환한다. 티블에서 [ 는 항상 다른 티블을 반환한다. 2.2.5 외부 데이터 가져오기 (importing) .csv 파일 변수명이 흥미롭게 된 파일데이터를 기존 read.csv() 함수와 read_csv() 함수로 각각 불러오는 경우를 비교하여 보자. read_csv()가 원본 데이터를 깔끔하게 가져올 뿐만 아니라 속도도 빠르다. 2.2.5.1 read_lines() 함수  벡터** file_url &lt;- &quot;https://gist.githubusercontent.com/theoroe3/8bc989b644adc24117bc66f50c292fc8/raw/f677a2ad811a9854c9d174178b0585a87569af60/tibbles_data.csv&quot; read_lines(file_url) ## [1] &quot;&lt;-,8,%,name&quot; &quot;1,2,0.25,t&quot; &quot;2,4,0.25,h&quot; &quot;3,6,0.25,e&quot; &quot;4,8,0.25,o&quot; 2.2.5.2 read.csv() 함수  데이터프레임** read.csv() 함수는 외부 데이터를 가져올 때, 데이터 프레임 형태로 가져온다 read.csv(file_url) ## X.. X8 X. name ## 1 1 2 0.25 t ## 2 2 4 0.25 h ## 3 3 6 0.25 e ## 4 4 8 0.25 o 2.2.5.3 read_csv() 함수  티블** read_csv() 함수는 외부 데이터를 가져올 때, 티블 형태로 가져온다. read_csv(file_url) ## ## -- Column specification -------------------------------------------------------- ## cols( ## `&lt;-` = col_double(), ## `8` = col_double(), ## `%` = col_double(), ## name = col_character() ## ) ## # A tibble: 4 x 4 ## `&lt;-` `8` `%` name ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 2 0.25 t ## 2 2 4 0.25 h ## 3 3 6 0.25 e ## 4 4 8 0.25 o 2.2.6 연습문제 어떤 객체가 티블 인지 알 수 있는 방법은 무엇인가? (힌트: 일반 데이터프레임인 mtcars 를 화면 출력해보라.) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 # mtcars as.tibble(mtcars) ## Warning: `as.tibble()` is deprecated as of tibble 2.0.0. ## Please use `as_tibble()` instead. ## The signature and semantics have changed, see `?as_tibble`. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## # A tibble: 32 x 11 ## mpg cyl disp hp drat wt qsec vs am gear carb ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 4 4 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 4 1 ## # ... with 29 more rows class(mtcars) ## [1] &quot;data.frame&quot; data.frame 과 이에 해당하는 티블에서 다음 연산들을 비교하고 차이를 밝혀보라. 차이점은 무엇인가? 데이터프레임의 기본 동작이 혼란스러운 점은 무엇인가? df &lt;- data.frame(abc = 1, xyz = &quot;a&quot;) df$x ## [1] &quot;a&quot; df[, &quot;xyz&quot;] ## [1] &quot;a&quot; df[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## abc xyz ## 1 1 a 두 번쨰의 df$x의 경우 컬럼명에 x가 없지만 컬럼명과 부분 매칭을 해서 xyz 컬럼의 값들을 출력하고 있다. tibble() 함수를 이용하면 부분 매칭이 허용되지 않는다. tbl &lt;- tibble(abc = 1, xyz = &quot;a&quot;) tbl$x # 컬럼명의 부분 매칭을 허용하지 않음. ## Warning: Unknown or uninitialised column: `x`. ## NULL tbl[, &quot;xyz&quot;] ## # A tibble: 1 x 1 ## xyz ## &lt;chr&gt; ## 1 a tbl[, c(&quot;abc&quot;, &quot;xyz&quot;)] ## # A tibble: 1 x 2 ## abc xyz ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a 객체에 변수 이름을 저장하고 있는 경우 (예: var &lt;- \"mpg\"), 티블에서 이 참조 변수를 어떻게 추출할 수 있는가? mtcars ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160.0 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160.0 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108.0 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258.0 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360.0 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225.0 105 2.76 3.460 20.22 1 0 3 1 ## Duster 360 14.3 8 360.0 245 3.21 3.570 15.84 0 0 3 4 ## Merc 240D 24.4 4 146.7 62 3.69 3.190 20.00 1 0 4 2 ## Merc 230 22.8 4 140.8 95 3.92 3.150 22.90 1 0 4 2 ## Merc 280 19.2 6 167.6 123 3.92 3.440 18.30 1 0 4 4 ## Merc 280C 17.8 6 167.6 123 3.92 3.440 18.90 1 0 4 4 ## Merc 450SE 16.4 8 275.8 180 3.07 4.070 17.40 0 0 3 3 ## Merc 450SL 17.3 8 275.8 180 3.07 3.730 17.60 0 0 3 3 ## Merc 450SLC 15.2 8 275.8 180 3.07 3.780 18.00 0 0 3 3 ## Cadillac Fleetwood 10.4 8 472.0 205 2.93 5.250 17.98 0 0 3 4 ## Lincoln Continental 10.4 8 460.0 215 3.00 5.424 17.82 0 0 3 4 ## Chrysler Imperial 14.7 8 440.0 230 3.23 5.345 17.42 0 0 3 4 ## Fiat 128 32.4 4 78.7 66 4.08 2.200 19.47 1 1 4 1 ## Honda Civic 30.4 4 75.7 52 4.93 1.615 18.52 1 1 4 2 ## Toyota Corolla 33.9 4 71.1 65 4.22 1.835 19.90 1 1 4 1 ## Toyota Corona 21.5 4 120.1 97 3.70 2.465 20.01 1 0 3 1 ## Dodge Challenger 15.5 8 318.0 150 2.76 3.520 16.87 0 0 3 2 ## AMC Javelin 15.2 8 304.0 150 3.15 3.435 17.30 0 0 3 2 ## Camaro Z28 13.3 8 350.0 245 3.73 3.840 15.41 0 0 3 4 ## Pontiac Firebird 19.2 8 400.0 175 3.08 3.845 17.05 0 0 3 2 ## Fiat X1-9 27.3 4 79.0 66 4.08 1.935 18.90 1 1 4 1 ## Porsche 914-2 26.0 4 120.3 91 4.43 2.140 16.70 0 1 5 2 ## Lotus Europa 30.4 4 95.1 113 3.77 1.513 16.90 1 1 5 2 ## Ford Pantera L 15.8 8 351.0 264 4.22 3.170 14.50 0 1 5 4 ## Ferrari Dino 19.7 6 145.0 175 3.62 2.770 15.50 0 1 5 6 ## Maserati Bora 15.0 8 301.0 335 3.54 3.570 14.60 0 1 5 8 ## Volvo 142E 21.4 4 121.0 109 4.11 2.780 18.60 1 1 4 2 t_cars &lt;- as_tibble(mtcars) var &lt;- &quot;mpg&quot; t_cars$var # NULL과 경고 메시지 출력 ## Warning: Unknown or uninitialised column: `var`. ## NULL t_cars[[var]] ## [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 ## [16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 ## [31] 15.0 21.4 이렇게 티블의 컬럼을 변수명으로 하여 검색하려 할 때에, $를 사용하면 NULL과 경고 메시지가 출력된다. 다음의 데이터프레임에서 비구문론적 이름을 참조하는 방법을 연습해보라. 1 이라는 이름의 변수를 추출하기. 1 vs 2 의 산점도를 플롯팅 하기. 열 2 를 열 1 로 나누어, 3 이라는 새로운 열을 생성하기. 열의 이름을 one, two, three 로 변경하기. test &lt;- tibble( `1` = 1:10, `2` = `1` * 2 + rnorm(length(`1`)) ) ## 1. test[[&quot;1&quot;]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## 2. ggplot(test, aes(x = `1`, y = `2`)) + geom_point() ## 3. mutate(test, `3` = `2` / `1`) ## # A tibble: 10 x 3 ## `1` `2` `3` ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.00 1.00 ## 2 2 3.22 1.61 ## 3 3 6.06 2.02 ## # ... with 7 more rows # 또는 test[[&quot;3&quot;]] &lt;- test$`2` / test$`1` ## 4. test &lt;- rename(test, one = `1`, two = `2`, three = `3`) glimpse(test) ## Rows: 10 ## Columns: 3 ## $ one &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ## $ two &lt;dbl&gt; 1.001614, 3.223746, 6.064459, 8.959494, 9.889715, 11.488990, ... ## $ three &lt;dbl&gt; 1.001614, 1.611873, 2.021486, 2.239874, 1.977943, 1.914832, 1... tibble::enframe() 은 어떤 동작을 하는가? 언제 사용하겠는가? tibble::enframe() 은 이름이 붙여진 벡터를 name 컬럼과 value 컬럼으로 구성되는 데이터 프레임으로 변환한다. enframe(c(a = &quot;A&quot;, b = &quot;B&quot;, c = &quot;C&quot;)) ## # A tibble: 3 x 2 ## name value ## &lt;chr&gt; &lt;chr&gt; ## 1 a A ## 2 b B ## 3 c C 티블의 바닥글(footer)에 화면출력되는 열 이름의 개수를 제어하는 옵션은 무엇인가? n_extra 인수가 열 이름의 갯수를 제어한다. (? print.tbl 참고) mtcars2 &lt;- as_tibble(cbind(mtcars, mtcars), .name_repair = &quot;unique&quot;) ## New names: ## * mpg -&gt; mpg...1 ## * cyl -&gt; cyl...2 ## * disp -&gt; disp...3 ## * hp -&gt; hp...4 ## * drat -&gt; drat...5 ## * ... print(mtcars2, n = 4, n_extra = 4) ## # A tibble: 32 x 22 ## mpg...1 cyl...2 disp...3 hp...4 drat...5 wt...6 qsec...7 vs...8 am...9 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 ## # ... with 28 more rows, and 13 more variables: gear...10 &lt;dbl&gt;, ## # carb...11 &lt;dbl&gt;, mpg...12 &lt;dbl&gt;, cyl...13 &lt;dbl&gt;, ... print(mtcars2, n = 4, n_extra = 10) ## # A tibble: 32 x 22 ## mpg...1 cyl...2 disp...3 hp...4 drat...5 wt...6 qsec...7 vs...8 am...9 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 21 6 160 110 3.9 2.62 16.5 0 1 ## 2 21 6 160 110 3.9 2.88 17.0 0 1 ## 3 22.8 4 108 93 3.85 2.32 18.6 1 1 ## 4 21.4 6 258 110 3.08 3.22 19.4 1 0 ## # ... with 28 more rows, and 13 more variables: gear...10 &lt;dbl&gt;, ## # carb...11 &lt;dbl&gt;, mpg...12 &lt;dbl&gt;, cyl...13 &lt;dbl&gt;, disp...14 &lt;dbl&gt;, ## # hp...15 &lt;dbl&gt;, drat...16 &lt;dbl&gt;, wt...17 &lt;dbl&gt;, qsec...18 &lt;dbl&gt;, ## # vs...19 &lt;dbl&gt;, ... 예를 들기 위해, mtcars 데이터 세트를 cbind() 함수를 이용하여 컬럼의 폭을 두 배로 늘렸다. n = 4 인수를 이용하여 출력할 행의 갯수를 제한하였다. n_extra = 인수를 이용하여 추가적인 컬럼에 대한 정보의 출력 갯수를 제어하였다. References https://statkclee.github.io/data-science/data-handling-tibble.html https://m.blog.naver.com/PostView.nhn?blogId=2000051148&amp;logNo=221188223533&amp;proxyReferer=https:%2F%2Fwww.google.com%2F dtplyr: dplyr의 편리함과 data.table의 속도를 그대로! : data.table, dplyr, dtplyr 의 속도비교 dtplyr: Data Table Back-End for ‘dplyr’ 2.3 Factor 2.3.1 범주형 자료 R에서 범주형 자료(Categorical Data)를 다룰 때는 문자형 자료와 잘 구별할 수 있어야 한다. 미리 범주형인지 문자형인지 확인하고 적절하게 분석 목적에 맞게끔 변환시켜야 한다. 이러한 과정들이 모두 데이터 전처리의 일부이다. 쉽게 표현하면, “vector(숫자형) + level(문자형) = factor” 2.3.2 Factor의 요소 및 특징 level vector의 index. (그런데, level도 벡터이다.) char 형이 기본값. first level이 선형 모델링시 가장 basic level로 간주됨. ex] levels = c(“yes,” “no”) 특징 : 명목형 변수를 저장할 때에 메모리를 아껴준다. ex) “MALE,” “MALE,” “FEMALE” … 로 저장해주기 보다는 1, 1, 2, … 로 저장하고, 1 = MALE, 2 = FEMALE로 level로 묶어주는 것이 좀 더 메모리상에서 효율적 일반 vector와는 다르게 level을 설정 가능 levels을 통해 한번에 “척”하고 변경이 가능 2.3.3 factor() 함수의 형식 factor() 함수의 기본적인 형식 : factor(x = character(), levels, labels = levels, exclude = NA, ordered = is.ordered(x), nmax = NA) where, x : 소수의 구별되는 값들로 구성되는 데이터 벡터 levels : as.character(x)에 의해 처리된 문자열 데이터의 유일 값들로, x의 오름차순으로 정렬된 것. 이는 sort(unique(x)) 보다 더 적은 수가 된다는 점을 주목하라. labels : 실제로 보여지는 값 exclude : levels를 설정할 때 제외되는 값들의 벡터 ordered : levels에 순서를 지정 nmax : levels 갯수의 상한 2.3.4 factor 생성 x &lt;- factor(&quot;문자벡터&quot;, levels = “벡터의 레벨(char)”, ordered = “ T/F” ) 2.3.4.1 factor 생성 factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;) ) # 디폴트로 레벨 : 오름차순 생성 ## [1] yes no yes ## Levels: no yes 2.3.4.2 factor에 levels 부여하기 factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;), levels = c(&quot;yes&quot;, &quot;no&quot;)) ## [1] yes no yes ## Levels: yes no 2.3.4.3 levels에 순위 부여하기 x &lt;- factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;), levels = c(&quot;yes&quot;, &quot;no&quot;) , ordered = T) # 가장 처음에 온 값이 기본 레벨(basic levels)이 됨 x ## [1] yes no yes ## Levels: yes &lt; no levels(x)[1:2] ## [1] &quot;yes&quot; &quot;no&quot; levels(x)[1:2] &lt;- &quot;yes&quot; levels(x) ## [1] &quot;yes&quot; x # levels에 접근하여 모든 값을 변경 가능 ## [1] yes yes yes ## Levels: yes 2.3.4.4 factor의 exclude인자 활용하기 x &lt;- factor(c(&quot;yes&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;yeah&quot;), levels = c(&quot;yes&quot;, &quot;no&quot;, &quot;yeah&quot;), ordered = T, exclude = &quot;yeah&quot;) x # exclude를 쓰면 NA 처리된다 ## [1] yes no yes &lt;NA&gt; ## Levels: yes &lt; no 2.3.4.5 addNA() 함수 활용하기 : addNA() 함수를 이용하여 NA를 levels에 추가하기 addNA(x, ifany = FALSE) # Levels에 N/A를 넣고싶다면 ## [1] yes no yes &lt;NA&gt; ## Levels: yes &lt; no &lt; &lt;NA&gt; 2.3.4.6 tapply() 함수를 통해 factor 이해하기 age &lt;- c(43,35,34,37,28,30,29,25,27,36,24,36,26,28,20) gender &lt;- factor(c(&#39;M&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;F&#39;,&#39;F&#39;,&#39;M&#39;,&#39;M&#39;,&#39;M&#39;,&#39;F&#39;,&#39;M&#39;)) sal &lt;- c(seq(100, 200, length.out=15)) emp &lt;- data.frame(age, gender, sal) emp$over30 &lt;- ifelse(emp$age &gt;= 35, 3, (ifelse(emp$age &gt;=30, 2, ifelse(emp$age &gt;=25, 1, 0)))) emp$over30 &lt;- as.factor(emp$over30) str(emp) ## &#39;data.frame&#39;: 15 obs. of 4 variables: ## $ age : num 43 35 34 37 28 30 29 25 27 36 ... ## $ gender: Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 1 1 2 2 1 1 2 1 1 ... ## $ sal : num 100 107 114 121 129 ... ## $ over30: Factor w/ 4 levels &quot;0&quot;,&quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 4 4 3 4 2 3 2 2 2 4 ... round(tapply(emp$sal, list(emp$gender, emp$over30), mean)) # gender, over30 별로 sal의 급여 평균 구하기 ## 0 1 2 3 ## F NA 164 125 136 ## M 186 155 NA 133 2.3.4.7 lm() 함수를 통해 factor 이해하기 hsb2 &lt;- read_csv(&quot;https://stats.idre.ucla.edu/stat/data/hsb2.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## id = col_double(), ## female = col_double(), ## race = col_double(), ## ses = col_double(), ## schtyp = col_double(), ## prog = col_double(), ## read = col_double(), ## write = col_double(), ## math = col_double(), ## science = col_double(), ## socst = col_double() ## ) str(hsb2) ## tibble [200 x 11] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ id : num [1:200] 70 121 86 141 172 113 50 11 84 48 ... ## $ female : num [1:200] 0 1 0 0 0 0 0 0 0 0 ... ## $ race : num [1:200] 4 4 4 4 4 4 3 1 4 3 ... ## $ ses : num [1:200] 1 2 3 3 2 2 2 2 2 2 ... ## $ schtyp : num [1:200] 1 1 1 1 1 1 1 1 1 1 ... ## $ prog : num [1:200] 1 3 1 3 2 2 1 2 1 2 ... ## $ read : num [1:200] 57 68 44 63 47 44 50 34 63 57 ... ## $ write : num [1:200] 52 59 33 44 52 52 59 46 57 55 ... ## $ math : num [1:200] 41 53 54 47 57 51 42 45 54 52 ... ## $ science: num [1:200] 47 63 58 53 53 63 53 39 58 50 ... ## $ socst : num [1:200] 57 61 31 56 61 61 61 36 51 51 ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. female = col_double(), ## .. race = col_double(), ## .. ses = col_double(), ## .. schtyp = col_double(), ## .. prog = col_double(), ## .. read = col_double(), ## .. write = col_double(), ## .. math = col_double(), ## .. science = col_double(), ## .. socst = col_double() ## .. ) ## race 컬럼에 factor 미적용시 summary(lm(write ~ race, data = hsb2)) ## ## Call: ## lm(formula = write ~ race, data = hsb2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -22.919 -5.912 1.091 8.082 17.100 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 45.8941 2.2652 20.260 &lt; 2e-16 *** ## race 2.0061 0.6322 3.173 0.00175 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.27 on 198 degrees of freedom ## Multiple R-squared: 0.0484, Adjusted R-squared: 0.04359 ## F-statistic: 10.07 on 1 and 198 DF, p-value: 0.001747 # 팩터 변수 생성 후 race 컬럼에 적용한 결과 hsb2$race.f &lt;- factor(hsb2$race) # race 컬럼의 팩터형 race.f 컬럼 is.factor(hsb2$race.f) # race.f 컬럼이 factor 형인지 확인 ## [1] TRUE hsb2$race.f[1:15] # race.f 컬럼의 앞 15개 요소 확인 ## [1] 4 4 4 4 4 4 3 1 4 3 4 4 4 4 3 ## Levels: 1 2 3 4 summary(lm(write ~ race.f, data = hsb2)) # write = a * race.f + b 선형 회귀식의 요약 통계 ## ## Call: ## lm(formula = write ~ race.f, data = hsb2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.0552 -5.4583 0.9724 7.0000 18.8000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 46.458 1.842 25.218 &lt; 2e-16 *** ## race.f2 11.542 3.286 3.512 0.000552 *** ## race.f3 1.742 2.732 0.637 0.524613 ## race.f4 7.597 1.989 3.820 0.000179 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.025 on 196 degrees of freedom ## Multiple R-squared: 0.1071, Adjusted R-squared: 0.0934 ## F-statistic: 7.833 on 3 and 196 DF, p-value: 5.785e-05 # ggplot(hsb2, aes(race.f, write)) + geom_point() + stat_smooth(method=lm, level = 0.95) 2.3.4.8 팩터변수를 외부에서 생성하기 싫은 경우 내부에 사용도 가능 hsb2 &lt;- read.csv(&quot;https://stats.idre.ucla.edu/stat/data/hsb2.csv&quot;) summary(lm(write ~ factor(race), data = hsb2)) ## ## Call: ## lm(formula = write ~ factor(race), data = hsb2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -23.0552 -5.4583 0.9724 7.0000 18.8000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 46.458 1.842 25.218 &lt; 2e-16 *** ## factor(race)2 11.542 3.286 3.512 0.000552 *** ## factor(race)3 1.742 2.732 0.637 0.524613 ## factor(race)4 7.597 1.989 3.820 0.000179 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 9.025 on 196 degrees of freedom ## Multiple R-squared: 0.1071, Adjusted R-squared: 0.0934 ## F-statistic: 7.833 on 3 and 196 DF, p-value: 5.785e-05 # ggplot(hsb2, aes(race, write)) + geom_point() + stat_smooth(aes(race, write), method=lm, level = 0.95) Reference R만의 명목변수 자료형 Factor 개념 이해하기 "],["data-cleansing.html", "Chapter 3 Data Cleansing 3.1 Data Cleansing 3.2 결측치(Missing Values) 처리 3.3 이상치(Outlier) 처리 {#outlier}", " Chapter 3 Data Cleansing 3.1 Data Cleansing 3.1.1 변수 요약 library(tidyverse) 각 변수들의 분포에 대한 간결한 요약정보에 익숙해야 한다. 그 이유는 다음과 같다: 표본의 특성 파악 의심이 가는 값들의 확인 base 패키지의 summary() 함수는 - 수치 변수에 대한 요약 통계량, factor 변수에 대한 빈도 등을 제공한다. - 문자 벡터들은 요약되지 않은채 남겨진다. 3.1.2 데이터 세트 d &lt;- read_csv(&quot;data3/patient_pt1_dm.csv&quot;); d ## ## -- Column specification -------------------------------------------------------- ## cols( ## .default = col_double(), ## hospital = col_character(), ## docid = col_character(), ## dis_date = col_character(), ## sex = col_character(), ## familyhx = col_character(), ## smokinghx = col_character(), ## cancerstage = col_character(), ## wbc = col_character() ## ) ## i Use `spec()` for the full column specifications. ## # A tibble: 120 x 24 ## hospital hospid docid dis_date sex age test1 test2 pain tumorsize co2 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 UCLA 1 1-1 6-Sep-09 male 65.0 3.70 8.09 4 68.0 1.53 ## 2 UCLA 1 1-1 7-Jan-11 fema~ 53.9 2.63 0.803 2 64.7 1.68 ## 3 UCLA 1 1-1 4-Sep-10 male 41.4 -99 2.13 3 86.4 1.45 ## # ... with 117 more rows, and 13 more variables: wound &lt;dbl&gt;, mobility &lt;dbl&gt;, ## # ntumors &lt;dbl&gt;, remission &lt;dbl&gt;, lungcapacity &lt;dbl&gt;, married &lt;dbl&gt;, ## # familyhx &lt;chr&gt;, smokinghx &lt;chr&gt;, cancerstage &lt;chr&gt;, lengthofstay &lt;dbl&gt;, ## # wbc &lt;chr&gt;, rbc &lt;dbl&gt;, bmi &lt;dbl&gt; 3.1.3 데이터 세트의 통계적 요약 정보 summary(d) ## hospital hospid docid dis_date ## Length:120 Min. :1.000 Length:120 Length:120 ## Class :character 1st Qu.:1.000 Class :character Class :character ## Mode :character Median :1.000 Mode :character Mode :character ## Mean :1.483 ## 3rd Qu.:2.000 ## Max. :2.000 ## sex age test1 test2 ## Length:120 Min. : 34.19 Min. :-99.000 Min. :-99.000 ## Class :character 1st Qu.: 47.75 1st Qu.: 1.560 1st Qu.: 2.249 ## Mode :character Median : 51.83 Median : 3.107 Median : 4.162 ## Mean : 53.59 Mean : -1.989 Mean : -1.226 ## 3rd Qu.: 55.01 3rd Qu.: 5.707 3rd Qu.: 6.166 ## Max. :357.89 Max. : 12.416 Max. : 17.228 ## pain tumorsize co2 wound ## Min. :1.000 Min. : 49.10 Min. :-98.0000 Min. :2.000 ## 1st Qu.:4.000 1st Qu.: 62.18 1st Qu.: 1.4954 1st Qu.:5.000 ## Median :5.000 Median : 68.23 Median : 1.5859 Median :6.000 ## Mean :5.325 Mean : 70.08 Mean : -0.8901 Mean :5.592 ## 3rd Qu.:6.000 3rd Qu.: 77.48 3rd Qu.: 1.6860 3rd Qu.:7.000 ## Max. :9.000 Max. :109.01 Max. : 1.9424 Max. :9.000 ## mobility ntumors remission lungcapacity ## Min. :2.000 Min. :0.00 Min. :0.00 Min. :-99.0000 ## 1st Qu.:5.000 1st Qu.:1.00 1st Qu.:0.00 1st Qu.: 0.5141 ## Median :6.000 Median :2.00 Median :0.00 Median : 0.7457 ## Mean :6.033 Mean :3.15 Mean :0.35 Mean :-18.3280 ## 3rd Qu.:7.000 3rd Qu.:5.00 3rd Qu.:1.00 3rd Qu.: 0.8721 ## Max. :9.000 Max. :9.00 Max. :1.00 Max. : 0.9982 ## married familyhx smokinghx cancerstage ## Min. :0.0000 Length:120 Length:120 Length:120 ## 1st Qu.:0.0000 Class :character Class :character Class :character ## Median :1.0000 Mode :character Mode :character Mode :character ## Mean :0.6333 ## 3rd Qu.:1.0000 ## Max. :1.0000 ## lengthofstay wbc rbc bmi ## Min. :3.000 Length:120 Min. :4.360 Min. :18.45 ## 1st Qu.:4.000 Class :character 1st Qu.:4.825 1st Qu.:24.51 ## Median :5.000 Mode :character Median :4.978 Median :27.82 ## Mean :5.308 Mean :4.970 Mean :29.38 ## 3rd Qu.:6.000 3rd Qu.:5.150 3rd Qu.:34.31 ## Max. :8.000 Max. :5.535 Max. :58.00 3.1.4 Hmisc 패키지의 describe() 함수 Hmisc 패키지의 describe() 함수는 데이터 프레임에 있는 모든 변수에 대한 다른 요약 통계량을 제공한다. 제공되는 정보는 변수의 데이터 형(data type)과 유일 값(distinct values)의 수에 따라 다르다. 중요 특징: 20개 보다 적은 수의 유일값을 갖는 변수들의 도수분포표 연속 변수에 대한 보다 자세한 백분위수(quantiles) 이진 변수에 대한 갯수와 비율 모든 변수의 결측치(NA) 갯수 describe()함수의 결과는 변수들이 타당한 값과 분포를 갖는지를 빠르게 결정하는데 사용될 수 있다. 3.1.4.1 Hmisc 패키지 설치 # install.packages(&quot;Hmisc&quot;) library(Hmisc) ## Loading required package: lattice ## Loading required package: survival ## Loading required package: Formula ## ## Attaching package: &#39;Hmisc&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## src, summarize ## The following objects are masked from &#39;package:base&#39;: ## ## format.pval, units 3.1.4.2 describe() 함수 데이터 세트에 대한 상세한 요약 정보를 보여 준다. describe(d) ## d ## ## 24 Variables 120 Observations ## -------------------------------------------------------------------------------- ## hospital ## n missing distinct ## 120 0 2 ## ## Value UCLA UCSF ## Frequency 62 58 ## Proportion 0.517 0.483 ## -------------------------------------------------------------------------------- ## hospid ## n missing distinct Info Mean Gmd ## 120 0 2 0.749 1.483 0.5036 ## ## Value 1 2 ## Frequency 62 58 ## Proportion 0.517 0.483 ## -------------------------------------------------------------------------------- ## docid ## n missing distinct ## 120 0 22 ## ## lowest : 1-1 1-100 1-11 1-21 1-22 , highest: 2-177 2-178 2-188 2-201 2-216 ## -------------------------------------------------------------------------------- ## dis_date ## n missing distinct ## 120 0 104 ## ## lowest : 1-Jul-09 10-Jun-09 10-Jun-10 11-Apr-10 11-Dec-09 ## highest: 9-Apr-10 9-Feb-09 9-Feb-10 9-Jun-10 9-May-10 ## -------------------------------------------------------------------------------- ## sex ## n missing distinct ## 120 0 3 ## ## Value 12.2 female male ## Frequency 1 74 45 ## Proportion 0.008 0.617 0.375 ## -------------------------------------------------------------------------------- ## age ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 117 1 53.59 11.92 40.86 41.52 ## .25 .50 .75 .90 .95 ## 47.75 51.83 55.01 58.61 59.65 ## ## lowest : 34.19229 35.31930 37.25225 39.61641 40.03724 ## highest: 63.93238 64.16432 64.96824 65.80417 357.89001 ## ## Value 35 40 45 50 55 60 65 360 ## Frequency 3 10 16 38 35 13 4 1 ## Proportion 0.025 0.083 0.133 0.317 0.292 0.108 0.033 0.008 ## ## For the frequency table, variable is rounded to the nearest 5 ## -------------------------------------------------------------------------------- ## test1 ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 111 1 -1.989 14.11 -99.0000 0.5809 ## .25 .50 .75 .90 .95 ## 1.5597 3.1065 5.7067 7.9931 9.5583 ## ## lowest : -99.0000000 0.1048958 0.1927608 0.4293420 0.5155185 ## highest: 9.7981329 10.2903990 10.4685400 11.0714440 12.4163920 ## ## Value -99 0 1 2 3 4 5 6 7 8 9 ## Frequency 7 3 20 17 21 12 8 11 6 7 1 ## Proportion 0.058 0.025 0.167 0.142 0.175 0.100 0.067 0.092 0.050 0.058 0.008 ## ## Value 10 11 12 ## Frequency 5 1 1 ## Proportion 0.042 0.008 0.008 ## ## For the frequency table, variable is rounded to the nearest 1 ## -------------------------------------------------------------------------------- ## test2 ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 111 1 -1.226 14.59 -99.0000 0.7881 ## .25 .50 .75 .90 .95 ## 2.2494 4.1620 6.1657 8.9973 10.9861 ## ## lowest : -99.0000000 0.5807591 0.6179262 0.6571499 0.7485080 ## highest: 11.4315750 12.4493730 14.2252270 14.5365420 17.2275810 ## ## Value -99 1 2 3 4 5 6 7 8 9 10 ## Frequency 7 15 12 19 16 15 9 6 6 6 1 ## Proportion 0.058 0.125 0.100 0.158 0.133 0.125 0.075 0.050 0.050 0.050 0.008 ## ## Value 11 12 14 15 17 ## Frequency 4 1 1 1 1 ## Proportion 0.033 0.008 0.008 0.008 0.008 ## ## For the frequency table, variable is rounded to the nearest 1 ## -------------------------------------------------------------------------------- ## pain ## n missing distinct Info Mean Gmd ## 120 0 9 0.961 5.325 1.742 ## ## lowest : 1 2 3 4 5, highest: 5 6 7 8 9 ## ## Value 1 2 3 4 5 6 7 8 9 ## Frequency 1 2 11 21 33 25 18 5 4 ## Proportion 0.008 0.017 0.092 0.175 0.275 0.208 0.150 0.042 0.033 ## -------------------------------------------------------------------------------- ## tumorsize ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 117 1 70.08 12.92 53.48 55.97 ## .25 .50 .75 .90 .95 ## 62.18 68.23 77.48 84.06 92.54 ## ## lowest : 49.09861 50.28009 50.50217 51.65727 53.19937 ## highest: 98.05510 98.32850 98.70570 102.69671 109.00956 ## -------------------------------------------------------------------------------- ## co2 ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 115 1 -0.8901 5.03 1.390 1.440 ## .25 .50 .75 .90 .95 ## 1.495 1.586 1.686 1.756 1.793 ## ## lowest : -98.000000 1.327440 1.362927 1.372113 1.391310 ## highest: 1.810847 1.820266 1.905606 1.920025 1.942401 ## ## Value -98 1 2 ## Frequency 3 29 88 ## Proportion 0.025 0.242 0.733 ## ## For the frequency table, variable is rounded to the nearest 1 ## -------------------------------------------------------------------------------- ## wound ## n missing distinct Info Mean Gmd ## 120 0 8 0.958 5.592 1.767 ## ## lowest : 2 3 4 5 6, highest: 5 6 7 8 9 ## ## Value 2 3 4 5 6 7 8 9 ## Frequency 5 10 12 23 36 22 10 2 ## Proportion 0.042 0.083 0.100 0.192 0.300 0.183 0.083 0.017 ## -------------------------------------------------------------------------------- ## mobility ## n missing distinct Info Mean Gmd ## 120 0 8 0.969 6.033 2.264 ## ## lowest : 2 3 4 5 6, highest: 5 6 7 8 9 ## ## Value 2 3 4 5 6 7 8 9 ## Frequency 6 4 19 19 28 15 5 24 ## Proportion 0.050 0.033 0.158 0.158 0.233 0.125 0.042 0.200 ## -------------------------------------------------------------------------------- ## ntumors ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 10 0.981 3.15 3.101 0 0 ## .25 .50 .75 .90 .95 ## 1 2 5 8 9 ## ## lowest : 0 1 2 3 4, highest: 5 6 7 8 9 ## ## Value 0 1 2 3 4 5 6 7 8 9 ## Frequency 23 21 19 9 12 11 7 5 5 8 ## Proportion 0.192 0.175 0.158 0.075 0.100 0.092 0.058 0.042 0.042 0.067 ## -------------------------------------------------------------------------------- ## remission ## n missing distinct Info Sum Mean Gmd ## 120 0 2 0.683 42 0.35 0.4588 ## ## -------------------------------------------------------------------------------- ## lungcapacity ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 96 0.995 -18.33 31.26 -99.0000 -99.0000 ## .25 .50 .75 .90 .95 ## 0.5142 0.7457 0.8721 0.9573 0.9790 ## ## lowest : -99.0000000 -98.0000000 0.2949074 0.3264440 0.3450253 ## highest: 0.9856416 0.9864109 0.9924814 0.9940955 0.9982018 ## ## Value -99.0 -98.0 0.2 0.4 0.6 0.8 1.0 ## Frequency 20 3 1 6 21 46 23 ## Proportion 0.167 0.025 0.008 0.050 0.175 0.383 0.192 ## ## For the frequency table, variable is rounded to the nearest 0.2 ## -------------------------------------------------------------------------------- ## married ## n missing distinct Info Sum Mean Gmd ## 120 0 2 0.697 76 0.6333 0.4683 ## ## -------------------------------------------------------------------------------- ## familyhx ## n missing distinct ## 120 0 3 ## ## Value -99 no yes ## Frequency 6 97 17 ## Proportion 0.050 0.808 0.142 ## -------------------------------------------------------------------------------- ## smokinghx ## n missing distinct ## 120 0 4 ## ## Value -99 current former never ## Frequency 6 26 22 66 ## Proportion 0.050 0.217 0.183 0.550 ## -------------------------------------------------------------------------------- ## cancerstage ## n missing distinct ## 120 0 4 ## ## Value I II III IV ## Frequency 40 54 17 9 ## Proportion 0.333 0.450 0.142 0.075 ## -------------------------------------------------------------------------------- ## lengthofstay ## n missing distinct Info Mean Gmd ## 120 0 6 0.933 5.308 1.271 ## ## lowest : 3 4 5 6 7, highest: 4 5 6 7 8 ## ## Value 3 4 5 6 7 8 ## Frequency 5 29 29 40 15 2 ## Proportion 0.042 0.242 0.242 0.333 0.125 0.017 ## -------------------------------------------------------------------------------- ## wbc ## n missing distinct ## 120 0 116 ## ## lowest : 3671.880371 4176.054199 4201.741211 4238.355957 4331.902344 ## highest: 7999.091309 8340.71582 8415.605469 8567.246094 not assessed ## -------------------------------------------------------------------------------- ## rbc ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 117 1 4.97 0.2885 4.526 4.606 ## .25 .50 .75 .90 .95 ## 4.825 4.978 5.150 5.285 5.353 ## ## lowest : 4.359662 4.436482 4.456108 4.465468 4.470100 ## highest: 5.441604 5.442614 5.459067 5.502604 5.535052 ## -------------------------------------------------------------------------------- ## bmi ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 117 1 29.38 7.278 20.71 22.07 ## .25 .50 .75 .90 .95 ## 24.51 27.82 34.31 37.75 40.71 ## ## lowest : 18.44992 18.68505 20.07485 20.17994 20.49195 ## highest: 42.84858 44.04223 46.50746 52.30723 58.00000 ## -------------------------------------------------------------------------------- 3.1.5 의심스러운 값 여기에 우리가 정확하다고 확신할 수 없는 몇 몇 변수의 값들이 있다: describe(d[,c(&quot;age&quot;, &quot;sex&quot;, &quot;test1&quot;)]) ## d[, c(&quot;age&quot;, &quot;sex&quot;, &quot;test1&quot;)] ## ## 3 Variables 120 Observations ## -------------------------------------------------------------------------------- ## age ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 117 1 53.59 11.92 40.86 41.52 ## .25 .50 .75 .90 .95 ## 47.75 51.83 55.01 58.61 59.65 ## ## lowest : 34.19229 35.31930 37.25225 39.61641 40.03724 ## highest: 63.93238 64.16432 64.96824 65.80417 357.89001 ## ## Value 35 40 45 50 55 60 65 360 ## Frequency 3 10 16 38 35 13 4 1 ## Proportion 0.025 0.083 0.133 0.317 0.292 0.108 0.033 0.008 ## ## For the frequency table, variable is rounded to the nearest 5 ## -------------------------------------------------------------------------------- ## sex ## n missing distinct ## 120 0 3 ## ## Value 12.2 female male ## Frequency 1 74 45 ## Proportion 0.008 0.617 0.375 ## -------------------------------------------------------------------------------- ## test1 ## n missing distinct Info Mean Gmd .05 .10 ## 120 0 111 1 -1.989 14.11 -99.0000 0.5809 ## .25 .50 .75 .90 .95 ## 1.5597 3.1065 5.7067 7.9931 9.5583 ## ## lowest : -99.0000000 0.1048958 0.1927608 0.4293420 0.5155185 ## highest: 9.7981329 10.2903990 10.4685400 11.0714440 12.4163920 ## ## Value -99 0 1 2 3 4 5 6 7 8 9 ## Frequency 7 3 20 17 21 12 8 11 6 7 1 ## Proportion 0.058 0.025 0.167 0.142 0.175 0.100 0.067 0.092 0.050 0.058 0.008 ## ## Value 10 11 12 ## Frequency 5 1 1 ## Proportion 0.042 0.008 0.008 ## ## For the frequency table, variable is rounded to the nearest 1 ## -------------------------------------------------------------------------------- age : 360 sex : 12.2 test1 : -99 3.1.6 describe()함수의 결과의 시각화 describe()함수의 결과들은 plot()함수로 다음과 같이 시각화할 수 있다: 명목 변수의 도수에 대한 점 그림(dot plot) 연속 변수의 분포에 대한 스파이크 히스토그램(spike histograms) 이러한 그림들은 변수의 분포에 대한 검토와 의심이 가는 데이터를 발견하는데 이용된다. 점 그림에서 명목 변수에 대한 의심이 가는 데이터의 라벨(아래의 그림에서 sex, familyhx 와 smokinghx 변수들)들을 찾아보자. 히스토그램에서는 각 히스토그램은 자체 척도를 가지고 있으며, 묶음 형태(bunched-up)의 히스토그램은 종종 극단치가 존재함을 알려준다(age, test1, test2, co2 와 lungcapacity 등의 변수들). win.graph(12,8) par(mfrow=c(2,1)) plot(describe(d)) ## $Categorical ## ## $Continuous 3.1.7 의심스러운 값을 결측치로 바꾸기 예제 데이터 세트의 요약정보의 결과와 describe() 함수 결과의 그래프는 여러 개의 의심스러운 값들이 있음을 알려주고 있다: age변수는 데이터 입력 에러로 보이는 357.89001 값이 있다. sex 변수는 데이터 입력 에러로 보이는 “12.2”값이 있다. test1, test2, lungcapacity, smokinghx, 그리고 familyhx 변수 등은 결측치 코드인 -99를 가지고 있다. co2 와 lungcapacity변수는 또 다른 결측치 코드인 -98 값을 가지고 있다. wbc 변수는 수치 변수인 것 같은데, R이 문자로 읽어들이게 하는 “not assessed” 값을 가지고 있다. 우리는 의심스러운 값들에 대하여 그 대체 값들을 알 수 없기때문에 R에서 결측치를 나타내는 NA로 변경할 것이다. 주의 : 자주 데이터 세트들은 결측치의 유형에 따라 결측치 값들을 구분하고 있다. 예를 들어, -99는 “결측치“, -98은 “답변 거부“” 등으로 처리하는 것을 들 수 있다. 분석의 목적을 위해서는 이 두 경우 모두 NA로 처리하면 된다. 그렇지만 결측치 값들을 구분하고자 하는 경우에는 memisc 패키지의 as.itemI) 함수를 참고하기 바란다. 데이터 입력 에러에 대하여 NA 값으로 대체하기 위해 논리적 서브세팅(logical subsetting)을 이용할 수 있다: # change all impossible age values to NA # assume all adults in this dataset d$age[d$age&lt;18 | d$age&gt;120] &lt;- NA # remember to use quotes for character variables d$sex[d$sex == &quot;12.2&quot;] &lt;- NA 이제 모든 -99, -98 그리고 not assessed 값들을 모두 NA로 바꿔보자. d[d==-99] &lt;- NA d[d==-98] &lt;- NA d[d==&quot;not assessed&quot;] &lt;- NA d ## # A tibble: 120 x 24 ## hospital hospid docid dis_date sex age test1 test2 pain tumorsize co2 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 UCLA 1 1-1 6-Sep-09 male 65.0 3.70 8.09 4 68.0 1.53 ## 2 UCLA 1 1-1 7-Jan-11 fema~ 53.9 2.63 0.803 2 64.7 1.68 ## 3 UCLA 1 1-1 4-Sep-10 male 41.4 NA 2.13 3 86.4 1.45 ## # ... with 117 more rows, and 13 more variables: wound &lt;dbl&gt;, mobility &lt;dbl&gt;, ## # ntumors &lt;dbl&gt;, remission &lt;dbl&gt;, lungcapacity &lt;dbl&gt;, married &lt;dbl&gt;, ## # familyhx &lt;chr&gt;, smokinghx &lt;chr&gt;, cancerstage &lt;chr&gt;, lengthofstay &lt;dbl&gt;, ## # wbc &lt;chr&gt;, rbc &lt;dbl&gt;, bmi &lt;dbl&gt; 예를 들어, 다음의 구문은 df 데이터 세트에 있는 모든a 값을 b값으로 바꾸는 것을 보여준다: df &lt;- data.frame(a=c(&quot;a&quot;, &quot;c&quot;, &quot;f&quot;), b=c(&quot;d&quot;, &quot;a&quot;, &quot;c&quot;)) df[df==&quot;a&quot;] &lt;- &quot;b&quot; df ## a b ## 1 b d ## 2 c b ## 3 f c 3.1.8 NA가 없는 완전한 데이터 complete.cases(x) 함수는 x의 행 각각에 누락된 데이터가 없는(NA가 존재하지 않는 데이터, complete cases)지를 확인해주는 논리값(TRUE/FALSE) 벡터를 반환한다. 해당 행 전체에 누락된 데이터가 없다면 TRUE값을 반환하고, 누락된 데이터가 존재한다면 FALSE를 반환해준다. 이 논리 벡터의 합은 complete cases의 갯수를 나타낸다. 3.1.8.1 결측치가 없는 데이터 complete.cases(d) ## [1] TRUE TRUE FALSE TRUE FALSE TRUE TRUE TRUE FALSE TRUE TRUE FALSE ## [13] TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE ## [25] TRUE TRUE FALSE TRUE FALSE TRUE TRUE FALSE FALSE TRUE TRUE FALSE ## [37] TRUE FALSE TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE FALSE TRUE ## [49] FALSE TRUE TRUE TRUE FALSE TRUE TRUE FALSE TRUE TRUE FALSE FALSE ## [61] TRUE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE FALSE TRUE FALSE ## [73] TRUE FALSE TRUE TRUE FALSE TRUE TRUE TRUE TRUE FALSE FALSE FALSE ## [85] TRUE FALSE TRUE TRUE TRUE TRUE TRUE FALSE TRUE TRUE FALSE TRUE ## [97] TRUE TRUE TRUE TRUE FALSE FALSE FALSE TRUE TRUE TRUE FALSE TRUE ## [109] FALSE TRUE TRUE FALSE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE 3.1.8.2 결측치가 아닌 데이터의 갯수 sum(complete.cases(d)) ## [1] 82 3.1.8.3 결측치가 없는 데이터 세트 생성 d_comp &lt;- d[complete.cases(d),] 3.1.9 데이터 정제 후의 describe()함수 결과 그림 describe() 함수 결과의 그림은 이제 더 나아 보인다. 점 그림에 의심이 가는 데이터 라벨이 없고 또 히스토그램은 아주 잘 분산되어 있다. 색은 그런 변수들의 결측치 수를 보여준다. 3.1.9.1 $Categorical 범주형 변수(factor)에 대한 시각화 plot(describe(d), which=&quot;categorical&quot;) 3.1.9.2 $Continuous 수치형 변수(numeric)에 대한 시각화 plot(describe(d_comp), which=&quot;continuous&quot;) 3.2 결측치(Missing Values) 처리 3.2.1 결측값이 포함되어 있는지 확인하는 방법: is.na() 3.2.1.1 데이터 세트 1 x &lt;- c(1, 2, 3, 4, NA, 6, 7, 8, 9, NA) 3.2.1.2 is.na() 함수 사용 is.na(x) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE 벡터 x의 각 요소에 대해 NA 여부를 확인. 논리형 벡터 반환. 3.2.1.3 데이터 세트 2 library(MASS) ## ## Attaching package: &#39;MASS&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select str(Cars93) ## &#39;data.frame&#39;: 93 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... MASS 패키지에 있는 Cars93 데이터 세트 27개의 컬럼과 93개의 행으로 구성되어 있다. is.na() 함수는 데이터 구조의 각 요소별로 NA 여부를 확인한다. 위의 벡터처럼 구성요소 갯수가 몇 개 안될 경우 is.na() 한 후에 TRUE, FALSE 논리형 값을 눈으로 보고 확인할 수 있다. 3.2.1.4 is.na() 함수 사용 하지만 Cars93 데이터 세트처럼 변수(열) 갯수도 많고, 관측치(행) 갯수도 많은 경우 (대부분의 실무에서 쓰는 데이터 세트는 이처럼 변수도 많고 관측치도 많다.) is.na() 함수만 가지고서는 아무래도 결측치 현황을 파악하는데 무리가 있다. head(is.na(Cars93)) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 2 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 3 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 4 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 5 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 6 FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## AirBags DriveTrain Cylinders EngineSize Horsepower RPM Rev.per.mile ## 1 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 2 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 3 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 4 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 5 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## 6 FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## Man.trans.avail Fuel.tank.capacity Passengers Length Wheelbase Width ## 1 FALSE FALSE FALSE FALSE FALSE FALSE ## 2 FALSE FALSE FALSE FALSE FALSE FALSE ## 3 FALSE FALSE FALSE FALSE FALSE FALSE ## 4 FALSE FALSE FALSE FALSE FALSE FALSE ## 5 FALSE FALSE FALSE FALSE FALSE FALSE ## 6 FALSE FALSE FALSE FALSE FALSE FALSE ## Turn.circle Rear.seat.room Luggage.room Weight Origin Make ## 1 FALSE FALSE FALSE FALSE FALSE FALSE ## 2 FALSE FALSE FALSE FALSE FALSE FALSE ## 3 FALSE FALSE FALSE FALSE FALSE FALSE ## 4 FALSE FALSE FALSE FALSE FALSE FALSE ## 5 FALSE FALSE FALSE FALSE FALSE FALSE ## 6 FALSE FALSE FALSE FALSE FALSE FALSE 3.2.2 결측치 갯수: sum(is.na()) 3.2.2.1 벡터의 경우 sum(is.na(x)) ## [1] 2 3.2.2.2 데이터 프레임의 경우 : Cars93 데이터 프레임. sum(is.na(Cars93)) ## [1] 13 3.2.2.3 Cars93 의 각 변수(컬럼)별로 결측값 개수 총 27개의 변수 중에서 Manufacturer, Price, Rear.seat.room, Luggage.room 등의 4개만 예시로 살펴본다. sum(is.na(Cars93$Manufacturer)) ## [1] 0 sum(is.na(Cars93$Price)) ## [1] 0 sum(is.na(Cars93$Rear.seat.room)) ## [1] 2 sum(is.na(Cars93$Luggage.room)) ## [1] 11 각 컬럼 별로 NA 요소 갯수가 반환된다. sum(is.na()) 함수를 이용하면 변수가 많거나 관측값이 많은 경우도 결측값 현황을 금방 파악할 수 있다. R은 TRUE 를 ‘1’로, FALSE 를’0‘으로 인식하기 때문에 sum(is.na())를 하게 되면 TRUE 값을’1’로 인식해서 합계를 구한다. 3.2.2.4 colSums() 함수 사용 colSums() 함수를 사용하면 데이터 프레임 내 다수 변수들에 대해서 한번에 각 개별 변수별 결측값의 개수 합계를 구할 수 있다. 바로 위에서 개별 함수별로 일일이 sum(is.na(Cars93$Manufacturer))…이런 식으로 변수의 개수만큼 쓰는 것을 colSums() 함수로는 한줄이면 해결할 수 있으니 훨씬 편하다. colSums(is.na(Cars93)) ## Manufacturer Model Type Min.Price ## 0 0 0 0 ## Price Max.Price MPG.city MPG.highway ## 0 0 0 0 ## AirBags DriveTrain Cylinders EngineSize ## 0 0 0 0 ## Horsepower RPM Rev.per.mile Man.trans.avail ## 0 0 0 0 ## Fuel.tank.capacity Passengers Length Wheelbase ## 0 0 0 0 ## Width Turn.circle Rear.seat.room Luggage.room ## 0 0 2 11 ## Weight Origin Make ## 0 0 0 colSums(is.na(Cars93)) : 함수로 간단하게 각 컬럼별 요소에 있는 NA의 갯수를 계산하였다. 3.2.3 결측치를 통계 분석시 제외시키기 : na.rm = TRUE 다음과 같은 함수는 데이터 세트에 NA가 포함되어 있으면 그 결과도 NA가 된다. sum(x) ## [1] NA mean(x) ## [1] NA 벡터 x에 결측치(NA)가 포함되어 있으면 그 결과는 NA로 반환됨. 이런 경우에 na.rm = TRUE를 함수의 인수로 사용한다. sum(x, na.rm = TRUE) ## [1] 40 mean(x, na.rm = TRUE) ## [1] 5 데이터 세트에서 NA를 제외하고 그 결과를 반환한다. 결측값이 들어있는 벡터에 대해서 sum(), mean(), sd(), min(), max(), range() 등의 통계 함수를 적용하면 NA만 나오게 된다. 결측값을 제외하고 통계 함수 계산을 하는 옵션은 na.rm = TRUE 가 된다. NA를 고려하지 않은 통계 처리의 경우 sum(Cars93$Luggage.room) ## [1] NA mean(Cars93$Luggage.room) ## [1] NA 모두 NA 결과 NA를 제외한 통계처리의 경우 sum(Cars93$Luggage.room, na.rm = TRUE) ## [1] 1139 mean(Cars93$Luggage.room, na.rm = TRUE) ## [1] 13.89024 NA를 제외한 통계 처리 결과 위 예제는 결측값이 포함된 데이터 프레임의 특정 변수에 대해 indexing을 해서 통계 함수를 적용해본 경우이다. 역시 na.rm = TRUE 옵션을 설정해 주어야 통계 계산이 제대로 됨을 알 수 있다. na.rm = FALSE 가 디폴트이므로 na.rm = TRUE를 설정하지 않는 경우 결측값이 포함되어 있으면 NA가 결과로 나타나게 된다. 3.2.4 결측치가 있는 행 제거: na.omit() na.rm = TRUE 옵션은 원래의 데이터 세트는 그대로 둔 채, 통계량 계산할 때만 NA를 포함하지 않게 된다. 따라서 다수의 통계 함수 혹은 다수의 변수에 통계 함수를 사용해야 하는 경우 매번 na.rm = TRUE 옵션을 설정해주는게 번거로울 수 있다. 따라서 차라리 원래 데이터 세트에서 결측값을 제거하면 된다. 결측값이 들어있는 행을 제거해 주는 함수가 na.omit() 함수이다. 좀 더 예리하게 특정 행과 열을 지정해서 그곳에 결측값이 있는 경우만 메스로 정밀 수술하는 함수가 complete.cases() 함수이다. 3.2.4.1 na.omit() 함수의 사용 예 Cars93_1 &lt;- na.omit(Cars93) str(Cars93_1) ## &#39;data.frame&#39;: 82 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... ## - attr(*, &quot;na.action&quot;)= &#39;omit&#39; Named int [1:11] 16 17 19 26 36 56 57 66 70 87 ... ## ..- attr(*, &quot;names&quot;)= chr [1:11] &quot;16&quot; &quot;17&quot; &quot;19&quot; &quot;26&quot; ... Cars93_1 &lt;- na.omit(Cars93) : NA를 가진 행을 제외한 새로운 데이터 세트 Cars93_1을 생성한다. str(Cars93_1) : 원래의 데이터 세트 Cars93에 있던 93개의 행이 82개로 줄어 들었다. 즉, 11개의 행을 삭제했다. 위의 예처럼 결측값이 들어있는 행을 통째로 삭제할 때는 만약의 사태를 대비해서 원본 Cars93은 그대로 유지하고, 행을 삭제한 데이터 셋을 별도의 이름 Cars93_1로 저장해서 분석을 진행하는 것을 추천한다. 3.2.4.2 특정 열에 결측값 존재 시 행 제거하기 : complete.cases() 함수 sum(is.na(Cars93)) ## [1] 13 Cars93 데이터 세트에 있는 NA 요소의 갯수를 출력한다. 3.2.4.2.1 Cars93 데이터 프레임의 Rear.seat.room 컬럼의 결측치 행을 데이터 세트에서 제거하기 Cars93[ , “Rear.seat.room”] 또는 Cars93$Rear.seat.room 변수를 이용할 수 있다. Cars93_2 &lt;- Cars93[ complete.cases(Cars93[ , c(&quot;Rear.seat.room&quot;)]), ] sum(is.na(Cars93_2)) ## [1] 9 위의 구문은 다음과 같은 논리로 문제를 해결한다. 1. x &lt;- Cars93$Rear.seat.room : 해당 컬럼을 변수 x로 대체 2. y &lt;- complete.cases(x) : x 벡터의 요소에 대해 NA 존재 여부 확인 -&gt; logical 벡터가 나온다. 3. Cars93_2 &lt;- Cars93[y, ] : y가 TRUE 행만을 Cars93_2로 추출한다. x &lt;- Cars93$Rear.seat.room; head(x) ## [1] 26.5 30.0 28.0 31.0 27.0 28.0 y &lt;- complete.cases(x); sum(!y) ## [1] 2 z &lt;- is.na(x); sum(z) ## [1] 2 Cars93_2 &lt;- Cars93[y, ]; str(Cars93_2); sum(is.na(Cars93_2)) ## &#39;data.frame&#39;: 91 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... ## [1] 9 compleste.cases(x) : 요소가 NA가 아니면 TRUE, NA면 FALSE 반환. - 따라서, NA인 요소의 갯수를 구하기 위해 sum(!y)를 사용. : x 컬럼의 NA 갯수는 2개. is.na(x) : complete.cases() 함수와 비교하기 위함. is.na() 함수는 요소가 NA이면 TRUE, NA가 아니면 FALSE 반환. 따라서 sum(z)로 NA인 요소의 갯수를 구한다. : x 컬럼의 NA 갯수는 2개. Cars93[y, ] : Cars93 데이터 세트 중에서 벡터 y가 TRUE인 행인 모든 열([y, ])을 추출한다. sum(is.na(Cars93_2)) : Cars93_2 데이터 세트에 NA 요소가 아직도 9개 남아 있음을 확인할 수 있다. 3.2.4.2.2 Cars93 데이터 프레임의 23~24번째 칼럼 내 결측값이 있는 행 전체 삭제 이의 해결은 다음과 같은 논리 절차과정을 거치게 된다. Cars93의 23, 24번쨰 컬럼은 다음과 같이 표현된다. : Cars93[ , 23:24] 이를 x 변수에 대입한다. : x &lt;- Cars93[, 23:24] 이 x 변수에 대해 결측치가 없는 행을 확인하고 이를 y 변수에 대입한다. : y &lt;- complete_cases(x) Cars93에서 결측치가 없는 행들을 Cars93_3에 대입한다. : Cars93_3 &lt;- Cars93[y, ] Cars93_3의 결측치 요소 갯수를 확인한다. : sum(is.na(Cars93_3)) 이 절차를 스크립트로 작성하면 다음과 같다. x &lt;- Cars93[, 23:24] y &lt;- complete.cases(x) Cars93_3 &lt;- Cars93[y, ] sum(is.na(Cars93_3)) ## [1] 0 Cars93_3 데이터 세트에는 NA 요소가 하나도 없다. 이러한 논리를 한 줄에 표현한 것이 다음의 스크립트이다. Cars93_3 &lt;- Cars93[ complete.cases(Cars93[ , c(23:24)]), ] sum(is.na(Cars93_3)) ## [1] 0 행의 갯수 즉, 관측치의 갯수를 확인해 보자. dim(Cars93_3) ## [1] 82 27 str(Cars93_3) ## &#39;data.frame&#39;: 82 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... 관측값이 82개로서 전체 93개 중에서 11개가 줄어들었음을 알 수 있다. 3.2.5 결측치를 다른 값으로 대체 3.2.5.1 기본 형식 결측치를 다른 값으로 대체하는 기본적인 형식은 다음과 같다. dataset$var[is.na(dataset$var)] &lt;- new_value 이 구문의 논리적 흐름은 다음과 같다. 1. dataset$var : dataset 데이터 세트의 var 컬럼 (x) 2. is.na(x) : x에 NA가 있는가 (y) 3. dataset$var[y] &lt;- new_value : dataset의 var 컬럼 중 y가 TRUE인 경우 new_value를 대입. 3.2.5.2 결측치 대체 예 Cars93 데이터 세트에서 Luggage.room 컬럼에 있는 결측치를 모두 0으로 변경해 본다. 3.2.5.2.1 결측치 요소 확인 Cars93$Luggage.room 변수에 대해 결측치 요소 확인 Cars93$Luggage.room ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 NA NA 20 NA 15 14 17 11 13 14 ## [26] NA 16 11 11 15 12 12 13 12 18 NA 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 NA NA 12 15 6 15 11 14 12 14 NA 14 14 16 NA 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 NA 10 NA 14 15 14 15 sum(is.na(Cars93$Luggage.room)) ## [1] 11 3.2.5.2.2 결측치를 0으로 대체하기 원래의 데이터 세트 Cars93을 Cars93_4로 복사한 다음, Cars93_4$Luggage.room의 결측치를 0으로 대체한다. 이 구문의 논리적 흐름은 다음과 같다. 1. Cars93_4 &lt;- Cars93 : Cars93을 Cars93_4에 복사한다. 2. Cars93_4$Luggage.room : Cars93_4 데이터 세트의 var 컬럼 (x) 3. is.na(x) : x에 NA가 있는가 (y) 4. Cars93_4$var[y] &lt;- 0 : Cars93_4의 Luggage.room 컬럼 중 y가 TRUE인 경우 new_value0`를 대입. 이를 스크립트로 표현하면 다음과 같다. Cars93_4 &lt;- Cars93 x &lt;- Cars93_4$Luggage.room; x # 수정 전 Luggage.room 컬럼 ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 NA NA 20 NA 15 14 17 11 13 14 ## [26] NA 16 11 11 15 12 12 13 12 18 NA 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 NA NA 12 15 6 15 11 14 12 14 NA 14 14 16 NA 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 NA 10 NA 14 15 14 15 y &lt;- is.na(Cars93_4$Luggage.room) Cars93_4$Luggage.room[y] &lt;- 0 Cars93_4$Luggage.room # 수정 후 Luggage.room 컬럼 ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 0 0 20 0 15 14 17 11 13 14 ## [26] 0 16 11 11 15 12 12 13 12 18 0 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 0 0 12 15 6 15 11 14 12 14 0 14 14 16 0 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 0 10 0 14 15 14 15 NA값들이 모두 0으로 대체되었음을 알 수 있다. 위의 스크립트를 간단하게 표현하면 다음과 같다. 여기서는 Cars93을 Cars93_5로 복사하여 처리한다. # Luggage.room 변수 내 결측값을 &#39;0&#39;으로 대체 Cars93_5 &lt;- Cars93 Cars93_5$Luggage.room # 수정 전 Luggage.room 컬럼 ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 NA NA 20 NA 15 14 17 11 13 14 ## [26] NA 16 11 11 15 12 12 13 12 18 NA 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 NA NA 12 15 6 15 11 14 12 14 NA 14 14 16 NA 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 NA 10 NA 14 15 14 15 Cars93_5$Luggage.room[is.na(Cars93_5$Luggage.room)] &lt;- 0 Cars93_5$Luggage.room # 수정 후 Luggage.room 컬럼 ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 0 0 20 0 15 14 17 11 13 14 ## [26] 0 16 11 11 15 12 12 13 12 18 0 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 0 0 12 15 6 15 11 14 12 14 0 14 14 16 0 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 0 10 0 14 15 14 15 Cars93_5$Luggage.room[is.na(Cars93_5$Luggage.room)] &lt;- 0 과 같은 스크립트에 익숙해질 필요가 있는 것이다. 3.2.5.2.3 결측치를 컬럼의 평균값으로 대체하기 sum(is.na(Cars93$Luggage.room)) 함수를 사용해 Cars93의 Luggage.room 변수에 보면 11개의 결측값이 있음을 알 수 있다. Luggage.room 변수 내 결측값을 indexing 기법을 활용해서 ’0’로 대체하는 방법을 살펴보았다. 물론 ’0’이 아니라 다른 값으로도 대체가 가능하다. 아래의 예제에서는 결측값을 미포함(`na.rm = TRUE)했을 때의 Luggage.room의 평균값으로 결측값을 대체하여 보자, Cars93_6 &lt;- Cars93 Cars93_6$Luggage.room # 수정 전 Luggage.room ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 NA NA 20 NA 15 14 17 11 13 14 ## [26] NA 16 11 11 15 12 12 13 12 18 NA 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 NA NA 12 15 6 15 11 14 12 14 NA 14 14 16 NA 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 NA 10 NA 14 15 14 15 Cars93_6$Luggage.room[is.na(Cars93_6$Luggage.room)] &lt;- mean(Cars93_6$Luggage.room, na.rm = TRUE) sum(is.na(Cars93_6$Luggage.room)) ## [1] 0 round(Cars93_6$Luggage.room) # 수정 후 Luggage.room ## [1] 11 15 14 17 13 16 17 21 14 18 14 13 14 13 16 14 14 20 14 15 14 17 11 13 14 ## [26] 14 16 11 11 15 12 12 13 12 18 14 18 21 10 11 8 12 14 11 12 9 14 15 14 9 ## [51] 19 22 16 13 14 14 14 12 15 6 15 11 14 12 14 14 14 14 16 14 17 8 17 13 13 ## [76] 16 18 14 12 10 15 14 10 11 13 15 14 10 14 14 15 14 15 0 값 대신에 Luggage.room 컬럼의 평균인 mean(Cars93_6$Luggage.room, na.rm = TRUE)로 대체하고 있음을 알 수 있다. 3.2.5.2.4 일괄 대체 데이터프레임의 모든 행의 결측값을 특정 값(가령, ‘0’)으로 일괄 대체 : dataset[is.na(dataset)] &lt;- 0 Cars93_7 &lt;- Cars93 # counting the number of missing values in Cars93 dataset sum(is.na(Cars93_7)) # 13 ## [1] 13 # converting the missing value in Cars93 dataframe to &#39;0&#39; Cars93_7[is.na(Cars93_7)] &lt;- 0 # counting the number of missing values in Cars93 dataset sum(is.na(Cars93_7)) # 0 ## [1] 0 3.2.5.2.5 데이터프레임의 각 변수의 결측값을 각 변수 별 평균값으로 일괄 대체 위의 3)번에서 결측값을 그 열의 평균으로 대체하는 방법을 알아보았다. 만약 결측값을 포함한 열이 매우 많다면 일일이 변수이름을 지정해가면서 나열해서 입력하는 것은 번거로운 일이다. 이럴 때 sapply() 함수를 사용하면 일괄로 결측값을 포함한 변수에 대해서는 해당 변수의 평균으로 대체하라고 프로그래밍할 수 있다. sapply()를 적용하면 matrix를 반환하므로 dataframe으로 만들기 위해서 앞에 data.frame() 을 추가로 붙여주었다. sapply(dataset, function(x) ifelse(is.na(x), mean(x, na.rm=TRUE), x)) 이러한 문제의 해결을 위한 스크립트는 다음과 같다. # converting the missing value in Cars93 dataframe to each column&#39;s mean value Cars93_8 &lt;- Cars93[1:20,c(&quot;Rear.seat.room&quot;, &quot;Luggage.room&quot;)] colSums(is.na(Cars93_8)) ## Rear.seat.room Luggage.room ## 1 3 head(Cars93_8) ## Rear.seat.room Luggage.room ## 1 26.5 11 ## 2 30.0 15 ## 3 28.0 14 ## 4 31.0 17 ## 5 27.0 13 ## 6 28.0 16 sapply(Cars93_8, function(x) mean(x, na.rm=T)) ## Rear.seat.room Luggage.room ## 29.10526 15.35294 Cars93_8 &lt;- data.frame(sapply(Cars93_8, function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x) ) ) head(Cars93_8) ## Rear.seat.room Luggage.room ## 1 26.5 11 ## 2 30.0 15 ## 3 28.0 14 ## 4 31.0 17 ## 5 27.0 13 ## 6 28.0 16 3.2.5.2.6 그룹별 평균값으로 결측값 대체하기 base 패키지를 사용할 수도 있다. 그런데 여기서는 dplyr 패키지의 group_by() 와 ifelse() 조건문을 사용한 mutate() 함수로 그룹 별 평균값으로 결측값 채우는 방법에 대하여 알아보자. 3.2.5.2.6.1 데이터 세트 생성 # make a sample DataFrame grp &lt;- c(rep(&#39;a&#39;, 5), rep(&#39;b&#39;, 5)) val &lt;- c(1, 2, 3, NaN, 6, 2, 4, NaN, 10, 8) df &lt;- data.frame(grp, val) df ## grp val ## 1 a 1 ## 2 a 2 ## 3 a 3 ## 4 a NaN ## 5 a 6 ## 6 b 2 ## 7 b 4 ## 8 b NaN ## 9 b 10 ## 10 b 8 3.2.5.2.6.2 그룹별 평균 구하기 결측값을 제외하고, 그룹 ‘a’와 그룹 ’b’ 별 평균을 계산해보자. # mean value by group &#39;a&#39; and &#39;b&#39; library(dplyr) df %&gt;% group_by(grp) %&gt;% summarise(grp_mean = mean(val, na.rm = TRUE)) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 2 x 2 ## grp grp_mean ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 3 ## 2 b 6 그룹 ‘a’의 평균은 3, 그룹’b’의 평균은 6이다. 3.2.5.2.6.3 결측치를 그룹별 평균으로 대체하기 그러면 4번째 행에 있는 그룹 ‘a’의’val’ 칼럼 결측값을 그룹 ‘a’의 평균 3으로 대체(replace) 또는 채워넣기(fill in)를 하면 다음과 같다. 그리고 8번째 행에 있는 그룹’b‘의’val’ 칼럼 결측값을 그룹 ’b’의 평균 6으로 대체하면 다음과 같다. df %&gt;% group_by(grp) %&gt;% mutate(val = ifelse(is.na(val), mean(val, na.rm=TRUE), val)) ## # A tibble: 10 x 2 ## # Groups: grp [2] ## grp val ## &lt;chr&gt; &lt;dbl&gt; ## 1 a 1 ## 2 a 2 ## 3 a 3 ## # ... with 7 more rows 위에서 NA(Not Available)에 대해서 소개를 했는데요, 참고로 벡터에서 NaN (Not a Number), 무한값 Inf (Infinity), 유한값 finite 확인하는 방법도 마저 소개하겠습니다. 유의할 것은, is.na()에서 NA 뿐만 아니라 NaN 도 TRUE 를 반환합니다. my_data &lt;- c(-1, 0, 10, NA, NaN, Inf) my_data ## [1] -1 0 10 NA NaN Inf is.finite(my_data) ## [1] TRUE TRUE TRUE FALSE FALSE FALSE is.na(my_data) ## [1] FALSE FALSE FALSE TRUE TRUE FALSE is.nan(my_data) ## [1] FALSE FALSE FALSE FALSE TRUE FALSE is.infinite(my_data) ## [1] FALSE FALSE FALSE FALSE FALSE TRUE Reference https://rfriend.tistory.com/34 [R, Python 분석과 프로그래밍의 친구 (by R Friend)] 3.3 이상치(Outlier) 처리 {#outlier} 3.3.1 표준값 Z를 이용한 이상치 확인 및 처리 outliers 패키지를 이용해서 Z값(Z-score) 이상값을 결측치로 대체하는 방법이 있다. Z-값은 통계학에서 매우 기본이 되는 값으로,z = (x-μ)/σ로 구해지는 값이다. 이를 통해 서로 단위나 크기가 다른 값을 모두 표준화시킬 수 있다. 따라서 표준점수, 표준값이라고도 합니다. - 표준점수 0.0(=편차치 50) 이상은 전체의 50％이다. - **표준점수의 절대값**이 1.0(=편차치 60) 이상은 전체의 31.74％이다. - **표준점수의 절대값**이 2.0(=편차치 70) 이상은 전체의 4.56％이다. - **표준점수의 절대값**이 3.0(=편차치 80) 이상은 전체의 0.28％이다. - **표준점수의 절대값**이 4.0(=편차치 90) 이상은 전체의 0.006％이다. - **표준점수의 절대값**이 5.0(=편차치 100) 이상은 전체의 0.00004％이다. Z의 절대값이 3.0 이상의 값을 갖는 것은 전체 관측치의 0.28% 정도로 매우 드물기 때문에 이 정도 범위에서 벗어나는 값은 이상치라는 의심을 지닐 수 있다. 물론 더 엄격한 기준을 제시할 수 있는데, 미 국립표준 기술 연구소 (NIST, National Institute of Standards and Technology)의 경우 4.0을 제시하고 있으며 연구자에 따라서는 3.5를 사용할 수 있다. 3.3.1.1 outliers 패키지 설치 # install.packages(&quot;outliers&quot;) library(outliers) 3.3.1.2 정규분포 데이터 세트 생성 평균 100, 표준편차 3의 정규분포를 하는 샘플 300개를 rnorm() 함수를 이용하여 데이터 세트 x1을 생성한다. set.seed(1234) x1 &lt;- rnorm(300, 100, 3) # 평균 100, 표준편차 3인, 표본 300개 생성 이렇게 생성된 샘플의 분포도를 그려본다. plot(x1) 3.3.1.3 이상치의 존재유무 확인 정규분포를 따르더라도 확률적으로 Z의 절대값이 3을 넘을 수 있다. 즉, Z값이 3보다 크거나 Z값이 -3보다 작을 수 있다. 다만 이 코드에서는 쉽게 확인할 수 없으므로 outliers 패키지의 scores() 함수를 이용해서 찾아본다. (도움말은 ? scores() 참조) Z값을 나타내는 Z라는 새로운 데이터를 생성하고, 이 Z 값의 분포도를 plot() 함수를 이용하여 그리고, Z의 절대값이 3이 되는 수평선을 그려본다. Z &lt;- scores(x1, type=&quot;z&quot;) plot(Z, col = ifelse(abs(Z)&gt;3, &quot;red&quot;, &quot;blue&quot;)) abline(h = 3, col=&quot;blue&quot;) abline(h =-3, col=&quot;blue&quot;) - scores(x1, type=\"z\") : 데이타 x1에 대한 표준값(z)을 반환 - plot(Z, col = ifelse(abs(Z)&gt;3, \"red\", \"blue\")) : Z의 절대값이 3보다 크면 점의 색깔을 빨간색으로, 그렇지 않으면 파란색으로 표시한다. - abline(h = 3, col=\"blue\") : Z 값이 3인 수평선을 그린다. - 이 분포도에서 2개의 outlier가 존재함을 확인할 수 있다. 이 Z의 절대값 중 3을 넘는 값의 존재함을 확인하였으나 이상치의 정확한 색인 번호는 which() 함수를 이용하여 확인할 수 있다. which(Z %in% Z[abs(Z) &gt; 3]) ## [1] 178 237 %in% : 벡터 내 특정 값 포함 여부 확인 연산자. 색인 번호 반환. 178번과 237본 두 개의 데이터가 이상치. 3.3.1.4 이상치를 결측치로 대체 두 개의 이상치가 존재함을 확인하였으므로, 이제 이 이상치를 결측치 NA로 변경한다. x1[which(Z %in% Z[abs(Z) &gt; 3])] &lt;- NA x1[c(178, 237)] ## [1] NA NA 178번째 값과 237번째 값이 NA로 변경되어 있음. 또 다른 방법은 replace() 함수를 이용하여 이상치(Z&gt;3) 조건을 만족하는 x1의 값을 결측치 NA로 변경할 수 있다. x1 &lt;- replace(x1, abs(Z) &gt; 3, NA) x1[178] ## [1] NA 이렇게 표준에서 크게 벗어난 값을 보다 논리적으로 해결할 수 있게 되었다. 3.3.1.5 이상치 제거 시의 주의점 원래 데이터에 너무 많은 이상치가 존재하는 경우에는 이상치 제거에 신중해야 한다. 3.3.2 수정된 표준값을 이용한 이상치 확인 및 처리 표준값을 이용하는 방법은 가장 일반적이고 간단한 접근이다 그러나, 관측값(즉 표본)의 숫자가 적은 경우 정상적인 데이터가 이상치로 처리되는 경우가 있을 수 있다. 극단적인 예를 든다면, 20명의 소득을 조사했는데, 그 가운데 특별히 빌 게이츠가 끼어 있는 경우이다. 이 경우 소득의 평균값이 수백만 달러로 올라가게 되고, 그러면 5만 달러, 10만 달러의 연봉을 받는 사람까지 이상치로 처리될 수 있는 것이다. 이렇게 평균을 내면 본래 이상치가 아닌 것도 이상치로 만들 수 있다. 이를 회피하는 가장 좋은 방법은 평균 대신 중앙값(median)을 이용하는 것이다. 집단에서 중간 위치에 있는 값(중앙값)을 기준으로 잡으면, 평균의 함정에서 벗어날 수 있다. 3.3.2.1 데이터 세트의 생성 이번에는 평균이 100이고 표준편차가 3으로 정규분포하는 샘플을 3,000개 생성한다. set.seed(1234) x2 &lt;- rnorm(3000,100,3) 3.3.2.2 수정된 표준값 계산 표준값의 계산에 있어서 평균값이 아닌 중앙값을 사용하는 방법에 대하여 알아본다. outliers 패키지의 score() 함수에서 type= 인수로 mad를 지정하고 변수명은 Zm으로 한다. 여기서 mad는 median absolute deviation(MAD)로 중앙값의 절대 편차값을 의미한다. 이렇게 구해진 값은 수정된 표준값(modified Z score)라고 한다. Zm &lt;- scores(x2, type=&quot;mad&quot;) scores(x2, type=\"mad\") : 데이터 x2에 대한 수정된 표준값 반환 plot() 함수를 이용하여 수정된 표준값의 분포도를 그려본다. plot(Zm, col = ifelse(abs(Zm)&gt;3, &quot;red&quot;, &quot;blue&quot;)) abline(h = 3, col=&quot;blue&quot;) abline(h =-3, col=&quot;blue&quot;) 8개의 이상치가 있음을 확인할 수 있다. 3.3.2.3 이상치의 위치 확인 이제 수정된 표준값의 절대값이 3보다 큰 값들의 색인번호를 which() 함수를 이용하여 이상치의 위치를 확인한다. which(abs(Zm) &gt;3) ## [1] 178 237 392 486 1660 1815 2111 2414 총 8개의 이상치가 있다. 3.3.2.4 이상치를 결측치로 대체하기 샘플 데이터 x2의 이상치를 which() 함수를 이용하여 결측치로 대체한다 x2[which(abs(Zm) &gt;3)] &lt;- NA x2[which(abs(Zm) &gt;3)] ## [1] NA NA NA NA NA NA NA NA 3.3.2.5 데이터 프레임으로 데이터 확인하기 샘플 데이터 x2와 수정된 표준값 Zm을 데이터 프레임 df로 만들어 본다. df &lt;- data.frame(x2, Zm) head(df) ## x2 Zm ## 1 96.37880 -1.2328145 ## 2 100.83229 0.2683791 ## 3 103.25332 1.0844689 ## 4 92.96291 -2.3842547 ## 5 101.28737 0.4217810 ## 6 101.51817 0.4995776 subset() 함수를 이용해 수정된 표준값 Zm의 절대값이 3이상인 값들을 구해 이상치 값들의 집합인 데이터 프레임 df1을 만들어 보자. df1 &lt;- subset(df, abs(Zm) &gt; 3) df1 ## x2 Zm ## 178 NA 3.065834 ## 237 NA -3.281692 ## 392 NA -3.446436 ## 486 NA 3.219680 ## 1660 NA -3.168874 ## 1815 NA 3.191402 ## 2111 NA -3.141637 ## 2414 NA 3.044304 8개의 이상치 데이터와 수정된 표준값을 확인할 수 있다. 3.3.3 사분위수를 이용한 이상치 확인 및 처리 사분 범위(IQR: Interquartile range)에서 크게 벗어난 값을 이상치로 설정하는 방법에 대해서 살펴본다. 3.3.3.1 사분 범위를 이용한 이상치 계산식 사분 범위에서의 이상치는 다음과 같이 계산된다. `Q3 + 1.5 * IQR`과 `Q1 - 1.5 * IQR` 여기서, Q1 : 1 사분위수 Q3 : 3 사분위수 IQR : 사분 범위 3.3.3.2 사분범위 방법과 표준값 방법의 비교 사실 정규 분포를 따르더라도 표본 수가 많아지면, (Q3 + 1.5 * IQR)와 (Q1 - 1.5 * IQR)를 벗어나는 값도 같이 많아지기 때문에 그만큼 이상치로 보는 숫자가 점점 많아진다는 점도 고려해야 한다. 사분범위를 이용한 방법과 앞서 Z값 3을 기준으로 삼는 방법 간의 차이점을 우선 비교해 보면 다음의 그림과 같다. (출처 : 위키피디어) IQR은 4사 분위수(Q3, 75번째 백분위수)에서 2사분위수(Q1, 25번째 백분위수)을 뺀 값이다. 즉, IQR = Q3 - Q1이다. Q1은 표준값 -.6745 그리고 Q3는 표준값 .6745에 해당된다. Q1 - 1.5 * IQR은 표준값 -2.698, 그리고 Q3 + 1.5 * IQR은 표준값 2.698에 해당된다. 3.3.3.3 데이터 세트의 생성 여기서도 편의상 평균 100, 표준편차 3을 갖는 샘플 3천개인 데이터 세트 x3를 생성한다. set.seed(1234) x3 &lt;- rnorm(3000, 100, 3) 이 샘플 데이터의 분포도를 그려보자. plot(x3) 3.3.3.4 사분범위를 이용한 이상치의 상한과 하한 계산 데이터 세트 x3에 대한 사분범위를 이용한 이상치의 계산은 다음과 같은 outlier() 함수를 생성하여 계산한다. outlier &lt;- function(x) { low_Outlier &lt;- quantile(x)[2] - 1.5 * IQR(x) up_Outlier &lt;- quantile(x)[4] + 1.5 * IQR(x) return(c(low_Outlier, up_Outlier)) } outlier(x3) ## 25% 75% ## 91.9957 108.0194 3.3.3.5 이상치 존재 유무 확인하기 데이터 세트의 사분범위 이상치의 하한과 상한을 outlier() 함수로 계산하였으므로, 이제 이 범위를 벗어나는 데이터를 찾아본다. lim &lt;- outlier(x3) which(x3 &gt; lim[2] | x3 &lt; lim[1]) ## [1] 178 181 192 227 237 392 486 487 517 558 771 788 901 949 967 ## [16] 1121 1317 1359 1517 1660 1815 2024 2111 2264 2355 2414 2844 lim &lt;- outlier(x3) : x3의 사분범위 이상치의 범위값을 lim 변수에 대입한다. lim[1]이 하한, lim[2]가 상한 which(x3 &gt; lim[2] | x3 &lt; lim[1] ) : 하한보다 작거나, 상한보다 큰 값의 위치를 확인 총 27개의 이상치가 확인됨 3.3.3.6 이상치를 결측치로 대체하기 이상치에 대해 which() 함수를 이용하여 결측치로 대체한다. x3[which(x3 &gt; lim[2] | x3 &lt; lim[1])] &lt;- NA sum(is.na(x3)) ## [1] 27 sum(is.na(x3)) : 전체 데이터 중 NA 값의 갯수. 27개의 결측값은 앞서 예제에서보다 훨씬 많다. 대략적으로 전체의 1%가 조금 안되는 값이 이상치로 분류되어 제거된 것이다. 사실 모든 값들이 정규 분포를 따르고 제거할 필요가 없는 값이라는 점을 생각하면 좀 과도하게 제거된 것일 수도 있다. 하지만 표본의 100개 이하로 좀 작다면 무리 없이 적용할 수 있을 것이다. "],["preprocessing.html", "Chapter 4 Data Preprocessing 4.1 들어가는 말 4.2 dplyr 패키지에 있는 함수들 4.3 데이터 프레임의 컬럼 선택: select() 4.4 filter() 함수를 이용한 행의 선택 4.5 arrange() 함수를 이용한 행의 정렬 4.6 rename() 함수를 이용한 데이터 프레임의 컬럼 이름 변경 4.7 distinct() 함수를 이용한 유일한 값 추출 4.8 무작위 표본 추출 4.9 mutate() 함수를 이용한 새로운 컬럼 생성 4.10 summarise()함수를 이용한 요약 통계량 계산", " Chapter 4 Data Preprocessing 4.1 들어가는 말 데이터 프레임(dataframe)을 위한 데이터 전처리, 조작(data pre-processing, data manipulation)을 쉽고! 빠르게! 할 수 있도록 해주는 dplyr 패키지에 대해서 알아보겠습니다. R help에 검색해보면 dplyr 패키지를 아래와 같이 소개하고 있다. dplyr은 유연한 데이터 조작의 문법을 제공합니다. 이것은 plyr의 차기작으로서, 데이터 프레임을 집중적으로 다루는 툴이다 dplyr provides a flexible grammar of data manipulation. It’s the next iteration of plyr, focused on tools for working with data frames (hence the d in the name) 데이터 조작을 위한 문법으로 체계화를 해서 한번 배워놓으면 쉽다는 점과 더불어, C언어로 만들어서 매우 빠르다는 점도 dplyr 패키지의 크나큰 장점 중의 하나이다. 그래프/시각화를 문법으로 승화시켜서 체계를 잡아놓은 “ggplot2” 패키지 ( “ggplot is an implementation of the grammer of Graphics in R”)가 있다. 이 ggplot2를 만든 그 유명한 Hadley Wickham 이 dplyr 패키지도 만들었다. 아래에 소개한 것처럼, https://www.r-bloggers.com/ 에 소개되어 있는 Hadley 의 인터뷰를 보면, 기존 통계학에서는 데이터 전처리(Data munging and manipulation)를 “내 일이 아니야”라고 무시했었다고 한다. 그런데 Hadley Wickham이 보기에는 ’모델링’과 ’시각화’로 부터 통찰을 끄집에 내는데 있어서 데이터 조작, 전처리가 매우 중요하고 또 어려운 영역이라고 보았고, Hadley가 직접 나서서 이를 도와줄 수 있는 R packages를 만들었다는 것이다. “Hadley Wickham on why he created all those R packages” July 27, 2015 By David Smith “There are definitely some academic statisticians who just don’t understand why what I do is statistics, but basically I think they are all wrong . What I do is fundamentally statistics. The fact that data science exists as a field is a colossal failure of statistics. To me, that is what statistics is all about. It is gaining insight from data using modelling and visualization. Data munging and manipulation is hard and statistics has just said that’s not our domain.” * source : https://www.r-bloggers.com/hadley-wickham-on-why-he-created-all-those-r-packages/ Hadley Wickham의 Github repository 주소는 https://github.com/hadley?tab=repositories 이다. 여기 가보면 엄청나게 많은 R 패키지들에 입이 쩍 벌어진다. 만약에 노벨상에 R community에 기여한 공로를 치하하는 상으로 ’노벨 R 상’이 있다면 Hadley Wickham이 그 첫번째 수상자가 된다고 해도 전혀 이상할게 없을 정도로 정말 R의 확산에 지대한 공헌을 한 것이다. ggplot2가 시각화/그래프에 관한한 우리를 실망시키지 않았듯이, dplyr 또한 데이터 전처리에 관한한 coverage의 방대함과 문법의 명료함이 우리를 매료시킬 것이라고 생각하며, 하나씩 예를 들어 설명 알아보기로 한다. 아래의 설명은 browseVignettes(package = \"dplyr\") 치면 팝업으로 나오는 “Introduction to dplyr” HTML 페이지를 참조하였습니다. 4.1.1 데이터 전처리란? 데이터 전처리란 작업할 raw data를 구성하는 관측치와 변수들을 제거, 수정 혹은 추가하여 최종적으로 분석에 사용할 Data Set을 만드는 과정을 말한다. 예를 몇 가지 들자면 다음과 같다. 성별(sex)을 0, 1로 기입해 놓은 경우 보기 좋게 male, female 로 변경. 가구 회사에서 의자와 책상을 만들기 위해서 신장과 체중만 있으면 되는 경우, 그 외에 불필요한 변수들(주거지, 최종 학력 등)을 제거하는 것. 학생들의 교육 성취도 조사를 하려는데 1년치 자료만 있는 경우 과거 기록도 추가하는 경우 4.1.2 왜 dplyr 패키지 인가? dplyr 패키지의 가장 큰 장점은 %&gt;%(파이프, Pipe) 연산자라고 할 수 있다. 전처리 외에도 파이프 연산자는 가독성을 높여 준다. 수학적으로 말하자면 합성함수 o(circle)와 유사한 기능을 한다. 다만 둘의 차이점은 합성함수는 (f o g)(x) == f(g(x)) 처럼 뒤에서부터 앞의 순서로 계산하지만, dplyr 의 파이프 연산자는 왼쪽에서 오른쪽 순서로 진행된다. DataFrame %&gt;% function1() %&gt;% function2() 4.2 dplyr 패키지에 있는 함수들 예제로 사용할 데이터는 MASS 패키지에 들어있는 Cars93 데이터프레임입니다. 원래는 93개의 자동차 관측치에 27개의 변수를 가지고 있는데, 예시들기 편하도록 앞에서부터 변수 8개만 선택해서 사용하겠다. (Cars93_1 dataframe) 4.2.1 패키지 설치 library(dplyr) library(MASS) 4.2.2 예제 데이터 확인 head(MASS::Cars93) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Acura Integra Small 12.9 15.9 18.8 25 31 ## 2 Acura Legend Midsize 29.2 33.9 38.7 18 25 ## 3 Audi 90 Compact 25.9 29.1 32.3 20 26 ## 4 Audi 100 Midsize 30.8 37.7 44.6 19 26 ## 5 BMW 535i Midsize 23.7 30.0 36.2 22 30 ## 6 Buick Century Midsize 14.2 15.7 17.3 22 31 ## AirBags DriveTrain Cylinders EngineSize Horsepower RPM ## 1 None Front 4 1.8 140 6300 ## 2 Driver &amp; Passenger Front 6 3.2 200 5500 ## 3 Driver only Front 6 2.8 172 5500 ## 4 Driver &amp; Passenger Front 6 2.8 172 5500 ## 5 Driver only Rear 4 3.5 208 5700 ## 6 Driver only Front 4 2.2 110 5200 ## Rev.per.mile Man.trans.avail Fuel.tank.capacity Passengers Length Wheelbase ## 1 2890 Yes 13.2 5 177 102 ## 2 2335 Yes 18.0 5 195 115 ## 3 2280 Yes 16.9 5 180 102 ## 4 2535 Yes 21.1 6 193 106 ## 5 2545 Yes 21.1 4 186 109 ## 6 2565 No 16.4 6 189 105 ## Width Turn.circle Rear.seat.room Luggage.room Weight Origin Make ## 1 68 37 26.5 11 2705 non-USA Acura Integra ## 2 71 38 30.0 15 3560 non-USA Acura Legend ## 3 67 37 28.0 14 3375 non-USA Audi 90 ## 4 70 37 31.0 17 3405 non-USA Audi 100 ## 5 69 39 27.0 13 3640 non-USA BMW 535i ## 6 69 41 28.0 16 2880 USA Buick Century 관측치 53,940개, 변수 10개로 이루어진 데이터임을 알 수 있다. 이 외에도 데이터를 확인하는 다양한 함수들은 다음과 같은 것들이 있다. # Cars93 요약정보 확인 summary(Cars93) ## Manufacturer Model Type Min.Price Price ## Chevrolet: 8 100 : 1 Compact:16 Min. : 6.70 Min. : 7.40 ## Ford : 8 190E : 1 Large :11 1st Qu.:10.80 1st Qu.:12.20 ## Dodge : 6 240 : 1 Midsize:22 Median :14.70 Median :17.70 ## Mazda : 5 300E : 1 Small :21 Mean :17.13 Mean :19.51 ## Pontiac : 5 323 : 1 Sporty :14 3rd Qu.:20.30 3rd Qu.:23.30 ## Buick : 4 535i : 1 Van : 9 Max. :45.40 Max. :61.90 ## (Other) :57 (Other):87 ## Max.Price MPG.city MPG.highway AirBags ## Min. : 7.9 Min. :15.00 Min. :20.00 Driver &amp; Passenger:16 ## 1st Qu.:14.7 1st Qu.:18.00 1st Qu.:26.00 Driver only :43 ## Median :19.6 Median :21.00 Median :28.00 None :34 ## Mean :21.9 Mean :22.37 Mean :29.09 ## 3rd Qu.:25.3 3rd Qu.:25.00 3rd Qu.:31.00 ## Max. :80.0 Max. :46.00 Max. :50.00 ## ## DriveTrain Cylinders EngineSize Horsepower RPM ## 4WD :10 3 : 3 Min. :1.000 Min. : 55.0 Min. :3800 ## Front:67 4 :49 1st Qu.:1.800 1st Qu.:103.0 1st Qu.:4800 ## Rear :16 5 : 2 Median :2.400 Median :140.0 Median :5200 ## 6 :31 Mean :2.668 Mean :143.8 Mean :5281 ## 8 : 7 3rd Qu.:3.300 3rd Qu.:170.0 3rd Qu.:5750 ## rotary: 1 Max. :5.700 Max. :300.0 Max. :6500 ## ## Rev.per.mile Man.trans.avail Fuel.tank.capacity Passengers ## Min. :1320 No :32 Min. : 9.20 Min. :2.000 ## 1st Qu.:1985 Yes:61 1st Qu.:14.50 1st Qu.:4.000 ## Median :2340 Median :16.40 Median :5.000 ## Mean :2332 Mean :16.66 Mean :5.086 ## 3rd Qu.:2565 3rd Qu.:18.80 3rd Qu.:6.000 ## Max. :3755 Max. :27.00 Max. :8.000 ## ## Length Wheelbase Width Turn.circle ## Min. :141.0 Min. : 90.0 Min. :60.00 Min. :32.00 ## 1st Qu.:174.0 1st Qu.: 98.0 1st Qu.:67.00 1st Qu.:37.00 ## Median :183.0 Median :103.0 Median :69.00 Median :39.00 ## Mean :183.2 Mean :103.9 Mean :69.38 Mean :38.96 ## 3rd Qu.:192.0 3rd Qu.:110.0 3rd Qu.:72.00 3rd Qu.:41.00 ## Max. :219.0 Max. :119.0 Max. :78.00 Max. :45.00 ## ## Rear.seat.room Luggage.room Weight Origin Make ## Min. :19.00 Min. : 6.00 Min. :1695 USA :48 Acura Integra: 1 ## 1st Qu.:26.00 1st Qu.:12.00 1st Qu.:2620 non-USA:45 Acura Legend : 1 ## Median :27.50 Median :14.00 Median :3040 Audi 100 : 1 ## Mean :27.83 Mean :13.89 Mean :3073 Audi 90 : 1 ## 3rd Qu.:30.00 3rd Qu.:15.00 3rd Qu.:3525 BMW 535i : 1 ## Max. :36.00 Max. :22.00 Max. :4105 Buick Century: 1 ## NA&#39;s :2 NA&#39;s :11 (Other) :87 DT::datatable(Cars93) str(Cars93) ## &#39;data.frame&#39;: 93 obs. of 27 variables: ## $ Manufacturer : Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... ## $ AirBags : Factor w/ 3 levels &quot;Driver &amp; Passenger&quot;,..: 3 1 2 1 2 2 2 2 2 2 ... ## $ DriveTrain : Factor w/ 3 levels &quot;4WD&quot;,&quot;Front&quot;,..: 2 2 2 2 3 2 2 3 2 2 ... ## $ Cylinders : Factor w/ 6 levels &quot;3&quot;,&quot;4&quot;,&quot;5&quot;,&quot;6&quot;,..: 2 4 4 4 2 2 4 4 4 5 ... ## $ EngineSize : num 1.8 3.2 2.8 2.8 3.5 2.2 3.8 5.7 3.8 4.9 ... ## $ Horsepower : int 140 200 172 172 208 110 170 180 170 200 ... ## $ RPM : int 6300 5500 5500 5500 5700 5200 4800 4000 4800 4100 ... ## $ Rev.per.mile : int 2890 2335 2280 2535 2545 2565 1570 1320 1690 1510 ... ## $ Man.trans.avail : Factor w/ 2 levels &quot;No&quot;,&quot;Yes&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Fuel.tank.capacity: num 13.2 18 16.9 21.1 21.1 16.4 18 23 18.8 18 ... ## $ Passengers : int 5 5 5 6 4 6 6 6 5 6 ... ## $ Length : int 177 195 180 193 186 189 200 216 198 206 ... ## $ Wheelbase : int 102 115 102 106 109 105 111 116 108 114 ... ## $ Width : int 68 71 67 70 69 69 74 78 73 73 ... ## $ Turn.circle : int 37 38 37 37 39 41 42 45 41 43 ... ## $ Rear.seat.room : num 26.5 30 28 31 27 28 30.5 30.5 26.5 35 ... ## $ Luggage.room : int 11 15 14 17 13 16 17 21 14 18 ... ## $ Weight : int 2705 3560 3375 3405 3640 2880 3470 4105 3495 3620 ... ## $ Origin : Factor w/ 2 levels &quot;USA&quot;,&quot;non-USA&quot;: 2 2 2 2 2 1 1 1 1 1 ... ## $ Make : Factor w/ 93 levels &quot;Acura Integra&quot;,..: 1 2 4 3 5 6 7 9 8 10 ... dplyr::glimpse(Cars93) ## Rows: 93 ## Columns: 27 ## $ Manufacturer &lt;fct&gt; Acura, Acura, Audi, Audi, BMW, Buick, Buick, Bui... ## $ Model &lt;fct&gt; Integra, Legend, 90, 100, 535i, Century, LeSabre... ## $ Type &lt;fct&gt; Small, Midsize, Compact, Midsize, Midsize, Midsi... ## $ Min.Price &lt;dbl&gt; 12.9, 29.2, 25.9, 30.8, 23.7, 14.2, 19.9, 22.6, ... ## $ Price &lt;dbl&gt; 15.9, 33.9, 29.1, 37.7, 30.0, 15.7, 20.8, 23.7, ... ## $ Max.Price &lt;dbl&gt; 18.8, 38.7, 32.3, 44.6, 36.2, 17.3, 21.7, 24.9, ... ## $ MPG.city &lt;int&gt; 25, 18, 20, 19, 22, 22, 19, 16, 19, 16, 16, 25, ... ## $ MPG.highway &lt;int&gt; 31, 25, 26, 26, 30, 31, 28, 25, 27, 25, 25, 36, ... ## $ AirBags &lt;fct&gt; None, Driver &amp; Passenger, Driver only, Driver &amp; ... ## $ DriveTrain &lt;fct&gt; Front, Front, Front, Front, Rear, Front, Front, ... ## $ Cylinders &lt;fct&gt; 4, 6, 6, 6, 4, 4, 6, 6, 6, 8, 8, 4, 4, 6, 4, 6, ... ## $ EngineSize &lt;dbl&gt; 1.8, 3.2, 2.8, 2.8, 3.5, 2.2, 3.8, 5.7, 3.8, 4.9... ## $ Horsepower &lt;int&gt; 140, 200, 172, 172, 208, 110, 170, 180, 170, 200... ## $ RPM &lt;int&gt; 6300, 5500, 5500, 5500, 5700, 5200, 4800, 4000, ... ## $ Rev.per.mile &lt;int&gt; 2890, 2335, 2280, 2535, 2545, 2565, 1570, 1320, ... ## $ Man.trans.avail &lt;fct&gt; Yes, Yes, Yes, Yes, Yes, No, No, No, No, No, No,... ## $ Fuel.tank.capacity &lt;dbl&gt; 13.2, 18.0, 16.9, 21.1, 21.1, 16.4, 18.0, 23.0, ... ## $ Passengers &lt;int&gt; 5, 5, 5, 6, 4, 6, 6, 6, 5, 6, 5, 5, 5, 4, 6, 7, ... ## $ Length &lt;int&gt; 177, 195, 180, 193, 186, 189, 200, 216, 198, 206... ## $ Wheelbase &lt;int&gt; 102, 115, 102, 106, 109, 105, 111, 116, 108, 114... ## $ Width &lt;int&gt; 68, 71, 67, 70, 69, 69, 74, 78, 73, 73, 74, 66, ... ## $ Turn.circle &lt;int&gt; 37, 38, 37, 37, 39, 41, 42, 45, 41, 43, 44, 38, ... ## $ Rear.seat.room &lt;dbl&gt; 26.5, 30.0, 28.0, 31.0, 27.0, 28.0, 30.5, 30.5, ... ## $ Luggage.room &lt;int&gt; 11, 15, 14, 17, 13, 16, 17, 21, 14, 18, 14, 13, ... ## $ Weight &lt;int&gt; 2705, 3560, 3375, 3405, 3640, 2880, 3470, 4105, ... ## $ Origin &lt;fct&gt; non-USA, non-USA, non-USA, non-USA, non-USA, USA... ## $ Make &lt;fct&gt; Acura Integra, Acura Legend, Audi 90, Audi 100, ... # subset Cars93 Cars93_1 &lt;- Cars93[, 1:8] str(Cars93_1) ## &#39;data.frame&#39;: 93 obs. of 8 variables: ## $ Manufacturer: Factor w/ 32 levels &quot;Acura&quot;,&quot;Audi&quot;,..: 1 1 2 2 3 4 4 4 4 5 ... ## $ Model : Factor w/ 93 levels &quot;100&quot;,&quot;190E&quot;,&quot;240&quot;,..: 49 56 9 1 6 24 54 74 73 35 ... ## $ Type : Factor w/ 6 levels &quot;Compact&quot;,&quot;Large&quot;,..: 4 3 1 3 3 3 2 2 3 2 ... ## $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... ## $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... ## $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... ## $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... ## $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... Cars93_1 데이터 프레임에 대하여 str(Cars93_1)으로 데이터 구조를 확인해 본다. 컬럼(변수) 갯수, 컬럼(변수) 명, 관찰치 개수, 관찰치 미리보기 등을 확인해 보면 다음과 같다. 데이터 구조 : 'data.frame' : 컬럼(변수) 갯수 : 8 variables 컬럼(변수) 명 : $ Manufacturer, $ Model, $ Type, $ Min.Price, Price, Max.Price, MPG.City,MPG.highway 등 8개 컬럼(변수)의 이름 관찰치 개수 : 93 obs. 관찰치 미리보기 : 각 컬럼별 관찰치의 데이터 타입과 실제 데이터를 보여준다. $ Manufacturer: Factor w/ 32 levels \"Acura\",\"Audi\",..: 1 1 2 2 3 4 4 4 4 5 ... $ Model : Factor w/ 93 levels \"100\",\"190E\",\"240\",..: 49 56 9 1 6 24 54 74 73 35 ... $ Type : Factor w/ 6 levels \"Compact\",\"Large\",..: 4 3 1 3 3 3 2 2 3 2 ... $ Min.Price : num 12.9 29.2 25.9 30.8 23.7 14.2 19.9 22.6 26.3 33 ... $ Price : num 15.9 33.9 29.1 37.7 30 15.7 20.8 23.7 26.3 34.7 ... $ Max.Price : num 18.8 38.7 32.3 44.6 36.2 17.3 21.7 24.9 26.3 36.3 ... $ MPG.city : int 25 18 20 19 22 22 19 16 19 16 ... $ MPG.highway : int 31 25 26 26 30 31 28 25 27 25 ... 실제 데이터(관찰치)의 내용은 View(Cars93_1)로 확인할 수 있다. View(Cars93_1) 8개의 컬럼(변수) 93개의 행(관찰치) 4.2.3 dplyr 패키지의 주요 함수 목록 단일 테이블을 대상으로 하는 dplyr 패키지의 함수들(Single table verbs)을 표로 정리해보면 아래와 같습니다. dplyr verbs description similar {package} function filter() Filter rows with condition {base} subset slice() Filter rows with position {base} subset arrange() Re-order or arrange rows {base} order select() Select columns {base} subset select(df, starts_with()) Select columns that start with a prefix select(df, ends_with()) Select columns that end with a prefix select(df, contains()) Select columns that contain a character string select(df, matchs()) Select columns that match a regular expression select(df, one_of()) Select columns that are from a group of names select(df, num_range()) Select columns from num_range a to n with a prefix rename() Rename column name {reshape} rename distinct() Extract distinct(unique) rows {base} unique sample_n() Random sample rows for a fixed number {base} sample sample_frac() Random sample rows for a fixed fraction {base} sample mutate() Create(add) new columns. mutate() allows you to refer to columns that you’ve just created. {base} transform transmute() Create(add) new columns. transmute() only keeps the new columns. {base} transform summarise() Summarise values {base} summary 4.3 데이터 프레임의 컬럼 선택: select() 4.3.1 select() 함수의 기본 형식 select(dataframe, VAR1, VAR2, ...) dataframe : 데이터 세트 VAR1, VAR2 : 선택하고자 하는 컬럼 이름 기입 Cars93_1 데이터 세트로부터 제조사명(Manufacturer), 최대가격(Max.Price), 고속도로연비(MPG.highway) 3개 변수(칼럼)를 선택해 보자. # select() : Select columns by name # select(Cars93_1, Manufacturer, Max.Price, MPG.highway) # 또는 # Cars93_1 %&gt;% # select(Manufacturer, Max.Price, MPG.highway) 위의 스크립트를 실행하면 다음과 같은 에러메시지가 나온다. Error in select(Cars93_1, Manufacturer, Max.Price, MPG.highway) : 사용되지 않은 인자 (Manufacturer, Max.Price, MPG.highway) 이는 dplyr 패키지의 select() 함수와 MASS 패키지의 select() 함수가 충돌하기 때문이다. 이러한 패키지 간의 충돌을 방지하기 위한 해결 방법은 다음과 같다. (방법 1) dplyr::select() : select() 함수에 명시적으로 dplyr패키지 명을 지정하는 방법 a1 &lt;- dplyr::select(Cars93_1, Manufacturer, Max.Price, MPG.highway) head(a1) ## Manufacturer Max.Price MPG.highway ## 1 Acura 18.8 31 ## 2 Acura 38.7 25 ## 3 Audi 32.3 26 ## 4 Audi 44.6 26 ## 5 BMW 36.2 30 ## 6 Buick 17.3 31 (방법 2) select &lt;- dplyr::select : select() 함수가 dplyr 패키지의 select() 함수임을 명시적으로 지정 select &lt;- dplyr::select a2 &lt;- select(Cars93_1, Manufacturer, Max.Price, MPG.highway) head(a2) ## Manufacturer Max.Price MPG.highway ## 1 Acura 18.8 31 ## 2 Acura 38.7 25 ## 3 Audi 32.3 26 ## 4 Audi 44.6 26 ## 5 BMW 36.2 30 ## 6 Buick 17.3 31 # 또는 a3 &lt;- Cars93_1 %&gt;% select(Manufacturer, Max.Price, MPG.highway) head(a3) ## Manufacturer Max.Price MPG.highway ## 1 Acura 18.8 31 ## 2 Acura 38.7 25 ## 3 Audi 32.3 26 ## 4 Audi 44.6 26 ## 5 BMW 36.2 30 ## 6 Buick 17.3 31 (방법 3) MASS 패키지를 먼저 로딩하고, 나중에 dplyr 패키지를 로딩하기 library(MASS) library(dplyr) # dplyr loading after MASS a4 &lt;- select(Cars93, Manufacturer, Max.Price, MPG.highway) head(a4) ## Manufacturer Max.Price MPG.highway ## 1 Acura 18.8 31 ## 2 Acura 38.7 25 ## 3 Audi 32.3 26 ## 4 Audi 44.6 26 ## 5 BMW 36.2 30 ## 6 Buick 17.3 31 이제 정상적으로 3개의 컬럼이 선택되어 출력이 된다. 4.3.2 a번째 부터 n번째의 연속적 컬럼 선택 select(dataframe, VAR_a:VAR_n, ...) dataframe : 데이터 세트 VAR_a:VAR_n : a번째부터 n번째 변수 서로 인접한 연속된 변수들을 선택하고자 할 때는 예시처럼 ‘:’를 사용한다. Cars93_1 데이터 세트에서 1번째에 위치한 제조사(Manufacturer) ~ 5번째에 위치한 가격(Price)까지 연속적으로 5개의 변수들을 선택해 보자. (컬럼의 이름으로) a5 &lt;- select(Cars93_1, Manufacturer:Price) head(a5) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 # 또는 a6 &lt;- Cars93_1 %&gt;% select(Manufacturer:Price) head(a6) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 위의 결과로 Manufacturer, Model, Type, Min.Price, 그리고 Price 등의 5개의 컬럼이 선택된다. 아래와 같이 연속적인 컬럼의 위치를 알고 있으면 (가령 a부터 n번째 위치) ‘a:n’처럼 숫자를 직접 입력해주면 바로 위의 결과와 동일한 결과를 얻을 수 있다. a7 &lt;- select(Cars93_1, 1:5) head(a7) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 # 또는 a8 &lt;- Cars93_1 %&gt;% select(1:5) head(a8) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 참고로, dplyr 패키지의 select() 함수는 base패키지에 내장되어 있는 subset(dataframe, select=...) 함수와 기능이 같다. 아래의 subset() 함수의 결과와 비교해 보면, 그 결과가 위와 같다. a9 &lt;- subset(Cars93_1, select = c(Manufacturer:Price)) head(a9) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 # 또는 a10 &lt;- Cars93_1 %&gt;% subset(select = c(Manufacturer:Price)) head(a10) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 a11 &lt;- subset(Cars93_1, select = c(1:5)) head(a11) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 # 또는 a12 &lt;- Cars93_1 %&gt;% subset(select = c(1:5)) head(a12) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Acura Legend Midsize 29.2 33.9 ## 3 Audi 90 Compact 25.9 29.1 ## 4 Audi 100 Midsize 30.8 37.7 ## 5 BMW 535i Midsize 23.7 30.0 ## 6 Buick Century Midsize 14.2 15.7 4.3.3 a번째 부터 n번째의 연속적 컬럼을 제외한 선택 select(dataframe, -(VAR_a:VAR_n, …)) dataframe : 데이터 세트 VAR_a:VAR_n : a번째부터 n번째 변수 컬럼 이름 앞에 ‘-’(minus) 부호를 사용하면, 그 컬럼은 제외하고 선택하게 된다. # select(dataframe, -var1, -var2, ...) : to drop variables a13 &lt;- select(Cars93_1, -(Manufacturer:Price)); head(a13) ## Max.Price MPG.city MPG.highway ## 1 18.8 25 31 ## 2 38.7 18 25 ## 3 32.3 20 26 ## 4 44.6 19 26 ## 5 36.2 22 30 ## 6 17.3 22 31 # 또는 a14 &lt;- select(Cars93_1, -(1:5)); head(a14) ## Max.Price MPG.city MPG.highway ## 1 18.8 25 31 ## 2 38.7 18 25 ## 3 32.3 20 26 ## 4 44.6 19 26 ## 5 36.2 22 30 ## 6 17.3 22 31 # 또는 a15 &lt;- Cars93_1 %&gt;% select(-(Manufacturer:Price)) head(a15) ## Max.Price MPG.city MPG.highway ## 1 18.8 25 31 ## 2 38.7 18 25 ## 3 32.3 20 26 ## 4 44.6 19 26 ## 5 36.2 22 30 ## 6 17.3 22 31 # 또는 a16 &lt;- Cars93_1 %&gt;% select(-(1:5)) head(a16) ## Max.Price MPG.city MPG.highway ## 1 18.8 25 31 ## 2 38.7 18 25 ## 3 32.3 20 26 ## 4 44.6 19 26 ## 5 36.2 22 30 ## 6 17.3 22 31 4.3.4 컬럼 이름의 ’앞 부분’을 지정하여 선택 select(dataframe, starts_with(“xx_name”)) dataframe : 데이터 세트 starts_with(“xx_name”) :컬럼 이름이 “xx_name”으로 시작하는 모든 컬럼 선택 select() 함수의 인수로 starts_with() 를 사용하여 “xx_name”으로 시작하는 모든 컬럼을 선택할 수 있다. Cars93_1 데이터 프레임에서 “MPG”로 시작하는 모든 변수를 선택해 보자. # select(dataframe, starts_with(&quot;xx_name&quot;)) # : select all variables, starting with a &quot;xx_name&quot; prefix a17 &lt;- select(Cars93_1, starts_with(&quot;MPG&quot;)) head(a17) ## MPG.city MPG.highway ## 1 25 31 ## 2 18 25 ## 3 20 26 ## 4 19 26 ## 5 22 30 ## 6 22 31 # 또는 a18 &lt;- Cars93_1 %&gt;% select(starts_with(&quot;MPG&quot;)) head(a18) ## MPG.city MPG.highway ## 1 25 31 ## 2 18 25 ## 3 20 26 ## 4 19 26 ## 5 22 30 ## 6 22 31 “MPG”로 시작하는 컬럼으로 “MPG.city”(도시 연비), “MPG.highway”(고속도로 연비) 두 개의 컬럼이 출력된다. 4.3.5 컬럼 이름의 ’끝 부분’을 지정하여 선택 select(dataframe, ends_with(“xx_name”)) dataframe : 데이터 세트 ends_with(“xx_name”) :컬럼 이름이 “xx_name”으로 끝나는 모든 컬럼 선택 starts_with가() 있으면 ends_with()도 있다. “xx_name”으로 끝나는 모든 컬럼을 선택하고 싶다면 select() 함수 안에 인수로 ends_with() 를 추가해주면 된다. Cars93_1 데이터 프레임에서 “Price”로 끝나는 모든 변수를 선택해 보자 # select(dataframe, ends_with(&quot;xx_name&quot;)) # : select all variables, ending with a &quot;xx_name&quot; prefix a19 &lt;- select(Cars93_1, ends_with(&quot;Price&quot;)) head(a19) ## Min.Price Price Max.Price ## 1 12.9 15.9 18.8 ## 2 29.2 33.9 38.7 ## 3 25.9 29.1 32.3 ## 4 30.8 37.7 44.6 ## 5 23.7 30.0 36.2 ## 6 14.2 15.7 17.3 # 또는 a20 &lt;- Cars93_1 %&gt;% select(ends_with(&quot;Price&quot;)) head(a20) ## Min.Price Price Max.Price ## 1 12.9 15.9 18.8 ## 2 29.2 33.9 38.7 ## 3 25.9 29.1 32.3 ## 4 30.8 37.7 44.6 ## 5 23.7 30.0 36.2 ## 6 14.2 15.7 17.3 “Price”로 끝나는 컬럼이 “Min.Price,” “Price,” “Max.Price” 등 3개가 있음을 알 수 있다. 4.3.6 컬럼 이름의 일부를 포함하는 컬럼 선택 select(dataframe, contains(“xx_name”)) dataframe : 데이터 세트 contains(“xx_name”) : 컬럼 이름이 “xx_name”을 포함하는 모든 컬럼 선택 select() 함수에 contains() 인수를 사용하면 특정 문자열을 포함하는 모든 컬럼을 선택할 수 있다. 이때 “xx_name”은 대소문자를 구분하지 않는다. Cars93_1 데이터 프레임에 있는 컬럼들 중에서 “P”를 포함하는 모든 컬럼을 선택해 보자. # select(dataframe, contains(&quot;xx_string&quot;)) # : select all variables which contains a &quot;xx_string&quot; literal string a21 &lt;- select(Cars93_1, contains(&quot;P&quot;)) head(a21) ## Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 15.9 18.8 25 31 ## 2 Midsize 29.2 33.9 38.7 18 25 ## 3 Compact 25.9 29.1 32.3 20 26 ## 4 Midsize 30.8 37.7 44.6 19 26 ## 5 Midsize 23.7 30.0 36.2 22 30 ## 6 Midsize 14.2 15.7 17.3 22 31 # 또는 a22 &lt;- Cars93_1 %&gt;% select(contains(&quot;P&quot;)) head(a22) ## Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 15.9 18.8 25 31 ## 2 Midsize 29.2 33.9 38.7 18 25 ## 3 Compact 25.9 29.1 32.3 20 26 ## 4 Midsize 30.8 37.7 44.6 19 26 ## 5 Midsize 23.7 30.0 36.2 22 30 ## 6 Midsize 14.2 15.7 17.3 22 31 “P”를 포함하는 컬럼으로 “Type”(소문자 ‘p’ 포함, 대소문자 구분 안함), “Min.Price,” “Price,” “Max.Price,” “MPG.city,” “MPG.highway” 등 총 6개의 컬럼이 있다. 4.3.7 정규 표현식과 일치하는 문자열을 포함하는 컬럼 선택 select(dataframe, matches(“.xx_string.”)) dataframe : 데이터 세트 matches(“.xx_string.”) : 정규 표현식과 일치하는 문자열이 포함된 모든 컬럼 선택 여기서도 대소문자는 구분하지 않는다. 정규 표현식(regular expressions)에 대해서는 추후에 학습하기로 한다. Cars93_1의 데이터 프레임에 있는 컬럼 중 그 이름의 중간에 “P”를 포함하는(정규표현식 - “.P.”) 모든 컬럼을 선택해 보자. # select(dataframe, matches(&quot;.xx_string.&quot;)) # : Select columns that match a regular expression a23 &lt;- select(Cars93_1, matches(&quot;.P.&quot;)); head(a23) ## Type Min.Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 18.8 25 31 ## 2 Midsize 29.2 38.7 18 25 ## 3 Compact 25.9 32.3 20 26 ## 4 Midsize 30.8 44.6 19 26 ## 5 Midsize 23.7 36.2 22 30 ## 6 Midsize 14.2 17.3 22 31 a24 &lt;- select(Cars93_1, matches(&quot;P&quot;)); head(a24) # exactly the same with contains(&quot;P&quot;) ## Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 15.9 18.8 25 31 ## 2 Midsize 29.2 33.9 38.7 18 25 ## 3 Compact 25.9 29.1 32.3 20 26 ## 4 Midsize 30.8 37.7 44.6 19 26 ## 5 Midsize 23.7 30.0 36.2 22 30 ## 6 Midsize 14.2 15.7 17.3 22 31 # 또는 a25 &lt;- Cars93_1 %&gt;% select(matches(&quot;.P.&quot;)) head(a25) ## Type Min.Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 18.8 25 31 ## 2 Midsize 29.2 38.7 18 25 ## 3 Compact 25.9 32.3 20 26 ## 4 Midsize 30.8 44.6 19 26 ## 5 Midsize 23.7 36.2 22 30 ## 6 Midsize 14.2 17.3 22 31 a26 &lt;- Cars93_1 %&gt;% select(matches(&quot;P&quot;)) head(a26) ## Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Small 12.9 15.9 18.8 25 31 ## 2 Midsize 29.2 33.9 38.7 18 25 ## 3 Compact 25.9 29.1 32.3 20 26 ## 4 Midsize 30.8 37.7 44.6 19 26 ## 5 Midsize 23.7 30.0 36.2 22 30 ## 6 Midsize 14.2 15.7 17.3 22 31 위에 match() 옵션 안에 첫 예제는 (“.P.”)를, 두번 째 예제는 점이 없이 (“P”)를 사용했다. 앞 뒤로 ‘.’(dot) 을 붙이면 시작과 끝 말고 컬럼명의 중간에 특정 문자열이 포함된 컬럼을 선택하라는 뜻이다. matches(\".P.\") 로 한 경우에는 “P”로 시작하는 “Price” 컬럼이 선택되지 않지만, 그냥 matches(\"P\")로 한 경우는 “P”로 시작하는 “Price” 컬럼도 포함되어 있음을 알 수 있다. 참고로, ‘.’(dot) 이 없이 matches()를 쓰면 contains() 와 동일한 결과를 반환합니다. 4.3.8 원하는 컬럼 명의 그룹에 포함된 컬럼 선택 select(dataframe, one_of(vars)) dataframe : 데이터 세트 one_of(vars) : 컬럼 이름의 그룹(vars)에 포함된 모든 컬럼 선택 Cars93_1의 데이터 프레임 중에서 “Manufacturer,” “MAX.Price,” “MPG.highway” 등 3개의 컬럼 이름을 포함하는 컬럼 그룹이 있다고 할 때, Cars93_1 데이터 프레임에서 이 컬럼 그룹에 있는 컬럼이 있다면(&lt;- 즉, 있을 수도 있지만 없을 수도 있다는 뜻임!) 모두 선택해 보자. # select(dataframe, one_of(vars)) # : Select columns that are from a group of names vars &lt;- c(&quot;Manufacturer&quot;, &quot;MAX.Price&quot;, &quot;MPG.highway&quot;) a27 &lt;- select(Cars93_1, one_of(vars)) ## Warning: Unknown columns: `MAX.Price` head(a27) ## Manufacturer MPG.highway ## 1 Acura 31 ## 2 Acura 25 ## 3 Audi 26 ## 4 Audi 26 ## 5 BMW 30 ## 6 Buick 31 # 또는 vars &lt;- c(&quot;Manufacturer&quot;, &quot;MAX.Price&quot;, &quot;MPG.highway&quot;) a28 &lt;- Cars93_1 %&gt;% select(one_of(vars)) ## Warning: Unknown columns: `MAX.Price` head(a28) ## Manufacturer MPG.highway ## 1 Acura 31 ## 2 Acura 25 ## 3 Audi 26 ## 4 Audi 26 ## 5 BMW 30 ## 6 Buick 31 위의 결과로 “MAX.Price”라는 컬럼에 대해서는 “Unknown variables”라고 해서 Warning mesage가 뜬다. Cars93_1에 보면 “Max.Price”라는 컬럼은 있어도 “MAX.Price”라는 컬럼이 없다.이처럼 변수 그룹 vars 에 나열된 이름 중에서 데이터 프레임에 포함된 컬럼에 대해서는 선택되지만. 해당 컬럼이 없다면 Warning message를 보여준다. 반면에 그냥 select() 함수로 위의 컬럼 그룹을 선택해보면, 아래처럼 “Error: Can’t subset columns that don’t exist. x Column MAX.Price doesn’t exist.” error 메시지만 표시가 된다. # select(Cars93_1, Manufacturer, MAX.Price, MPG.highway) 4.3.9 컬럼 이름의 접두사와 숫자 범위를 조합하여 컬럼 선택 select(dataframe, num_range(\"V\", a:n)) dataframe : 데이터 세트 num_range(\"V\", a:n): 접두사(“V”)와 숫자 범위(“a:n”)를 조합하여 Va 컬럼 부터 Vn 컬럼까지 선택 변수 이름이 동일하게 특정 접두사로 시작하는 데이터 프레임의 경우 이 기능을 유용하게 사용할 수 있다. “V1,” “V2,” “V3,” “V4” 등의 4개 변수를 가진 df 데이터 프레임에서 “V2,” “V3” 변수를 선택해 보자. 단, 이때 접두사 “V”와 숫자 범위 2:3 을 조합해서 쓰는 num_range() 옵션을 사용하면 다음과 같다. # select(df, num_range(&quot;V&quot;, a:n)) # : Select columns from num_range a to n with a prefix V1 &lt;- c(rep(1, 10)) V2 &lt;- c(rep(1:2, 5)) V3 &lt;- c(rep(1:5, 2)) V4 &lt;- c(rep(1:10)) df &lt;- data.frame(V1, V2, V3, V4) df ## V1 V2 V3 V4 ## 1 1 1 1 1 ## 2 1 2 2 2 ## 3 1 1 3 3 ## 4 1 2 4 4 ## 5 1 1 5 5 ## 6 1 2 1 6 ## 7 1 1 2 7 ## 8 1 2 3 8 ## 9 1 1 4 9 ## 10 1 2 5 10 a29 &lt;- select(df, num_range(&quot;V&quot;, 2:3)) head(a29) ## V2 V3 ## 1 1 1 ## 2 2 2 ## 3 1 3 ## 4 2 4 ## 5 1 5 ## 6 2 1 # 또는 a30 &lt;- df %&gt;% select(num_range(&quot;V&quot;, 2:3)) head(a30) ## V2 V3 ## 1 1 1 ## 2 2 2 ## 3 1 3 ## 4 2 4 ## 5 1 5 ## 6 2 1 4.4 filter() 함수를 이용한 행의 선택 4.4.1 filter() 함수의 기본 형식 filter(dataframe, filter condition 1, filter condition 2, …) dataframe : 데이터 세트 filter condition : &amp;(AND) 조건으로 행의 부분집합 선택. 조건을 컴마(‘,’)로 구분 4.4.2 단일 조건에 의한 행의 선택 Cars93_1 데이터 프레임에 차종(Type)별로 보면 Compact 차종이 총 16개 있음을 알 수 있습니다. # number of cars by `Type` table(Cars93_1$Type) ## ## Compact Large Midsize Small Sporty Van ## 16 11 22 21 14 9 # filter() : select a subset of rows in a data frame filter(Cars93_1, Type == c(&quot;Compact&quot;)) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city ## 1 Audi 90 Compact 25.9 29.1 32.3 20 ## 2 Chevrolet Cavalier Compact 8.5 13.4 18.3 25 ## 3 Chevrolet Corsica Compact 11.4 11.4 11.4 25 ## 4 Chrysler LeBaron Compact 14.5 15.8 17.1 23 ## 5 Dodge Spirit Compact 11.9 13.3 14.7 22 ## 6 Ford Tempo Compact 10.4 11.3 12.2 22 ## 7 Honda Accord Compact 13.8 17.5 21.2 24 ## 8 Mazda 626 Compact 14.3 16.5 18.7 26 ## 9 Mercedes-Benz 190E Compact 29.0 31.9 34.9 20 ## 10 Nissan Altima Compact 13.0 15.7 18.3 24 ## 11 Oldsmobile Achieva Compact 13.0 13.5 14.0 24 ## 12 Pontiac Sunbird Compact 9.4 11.1 12.8 23 ## 13 Saab 900 Compact 20.3 28.7 37.1 20 ## 14 Subaru Legacy Compact 16.3 19.5 22.7 23 ## 15 Volkswagen Passat Compact 17.6 20.0 22.4 21 ## 16 Volvo 240 Compact 21.8 22.7 23.5 21 ## MPG.highway ## 1 26 ## 2 36 ## 3 34 ## 4 28 ## 5 27 ## 6 27 ## 7 31 ## 8 34 ## 9 29 ## 10 30 ## 11 31 ## 12 31 ## 13 26 ## 14 30 ## 15 30 ## 16 28 4.4.3 복수 조건을 AND(,)로 결합한 행의 선택 행을 선택하는 조건이 여러 개이면 동시에 만족해야 하는 경우는 AND 연산에 의한 조건 결합으로 행을 선택한다. 예를 들어, 차종(Type)이 “Compact”이면서(Type == c(“Compact”)) , 최대가격(Max.Price)이 20 백$ 이하이고 (Max.Price &lt;-20), 고속도로 연비(MPG.highway) 가 30 이상 (MPG.highway &gt; 30)인 관측치를 선택해 보자. 이 경우는 3개의 행 선택 조건이 모두 AND로 결합되는 것이다. 이때에는 이들 세 개의 조건식을 컴마(,)로 구분해 주면 된다. 따라서 위의 문제를 dplyr의 filter() 함수를 사용하여 나타내면 다음과 같다. 참고로, subset() 함수의 subset()과 동일한 기능을 한다. # filter() : select a subset of rows in a data frame filter(Cars93_1, Type == c(&quot;Compact&quot;), Max.Price &lt;= 20, MPG.highway &gt;= 30) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Chevrolet Cavalier Compact 8.5 13.4 18.3 25 36 ## 2 Chevrolet Corsica Compact 11.4 11.4 11.4 25 34 ## 3 Mazda 626 Compact 14.3 16.5 18.7 26 34 ## 4 Nissan Altima Compact 13.0 15.7 18.3 24 30 ## 5 Oldsmobile Achieva Compact 13.0 13.5 14.0 24 31 ## 6 Pontiac Sunbird Compact 9.4 11.1 12.8 23 31 # 또는 Cars93_1 %&gt;% filter(Type == c(&quot;Compact&quot;), Max.Price &lt;= 20, MPG.highway &gt;= 30) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Chevrolet Cavalier Compact 8.5 13.4 18.3 25 36 ## 2 Chevrolet Corsica Compact 11.4 11.4 11.4 25 34 ## 3 Mazda 626 Compact 14.3 16.5 18.7 26 34 ## 4 Nissan Altima Compact 13.0 15.7 18.3 24 30 ## 5 Oldsmobile Achieva Compact 13.0 13.5 14.0 24 31 ## 6 Pontiac Sunbird Compact 9.4 11.1 12.8 23 31 세 개의 조건을 동시에 만족하는 관측치의 갯수는 6개임을 알 수 있다. 4.4.4 복수 조건을 OR(|)로 결합한 행의 선택 filter(dataframe, filter condition 1 | filter condition 2 | …) dataframe : 데이터 세트 filter condition 1 : 선택 조건 1 |: OR 조건 연산자 OR(또는) 조건으로 부분집합을 선별하려면 |를 사용한다. (subset() 함수와 동일) Cars93_1 데이터 세트의 차종(Type)이 “Compact”이거나(|: OR), 최대가격(Max.Price)이 20 백$ 이하이거나(|, OR) 고속도로 연비(MPG.highway) 가 30 이상인 관측치 (행)을 선택해 보자. 즉, 3개의 검색 조건 중 하나라도 만족하면 그 행은 선택이 된다. 이때 이들 조건들을 OR 연산자인 |를 사용하여 결합하다. 위의 문제는 dplyr의 filter() 함수를 사용하면 다음과 같이 된다. # filter(dataframe, condition1 | condition2) : or filter(Cars93_1, Type == c(&quot;Compact&quot;) | Max.Price &lt;= 20 | MPG.highway &gt;= 30) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city ## 1 Acura Integra Small 12.9 15.9 18.8 25 ## 2 Audi 90 Compact 25.9 29.1 32.3 20 ## 3 BMW 535i Midsize 23.7 30.0 36.2 22 ## 4 Buick Century Midsize 14.2 15.7 17.3 22 ## 5 Chevrolet Cavalier Compact 8.5 13.4 18.3 25 ## 6 Chevrolet Corsica Compact 11.4 11.4 11.4 25 ## 7 Chevrolet Camaro Sporty 13.4 15.1 16.8 19 ## 8 Chevrolet Lumina Midsize 13.4 15.9 18.4 21 ## 9 Chevrolet Lumina_APV Van 14.7 16.3 18.0 18 ## 10 Chevrolet Astro Van 14.7 16.6 18.6 15 ## 11 Chevrolet Caprice Large 18.0 18.8 19.6 17 ## 12 Chrylser Concorde Large 18.4 18.4 18.4 20 ## 13 Chrysler LeBaron Compact 14.5 15.8 17.1 23 ## 14 Dodge Colt Small 7.9 9.2 10.6 29 ## 15 Dodge Shadow Small 8.4 11.3 14.2 23 ## 16 Dodge Spirit Compact 11.9 13.3 14.7 22 ## 17 Dodge Dynasty Midsize 14.8 15.6 16.4 21 ## 18 Eagle Summit Small 7.9 12.2 16.5 29 ## 19 Ford Festiva Small 6.9 7.4 7.9 31 ## 20 Ford Escort Small 8.4 10.1 11.9 23 ## 21 Ford Tempo Compact 10.4 11.3 12.2 22 ## 22 Ford Probe Sporty 12.8 14.0 15.2 24 ## 23 Ford Taurus Midsize 15.6 20.2 24.8 21 ## 24 Geo Metro Small 6.7 8.4 10.0 46 ## 25 Geo Storm Sporty 11.5 12.5 13.5 30 ## 26 Honda Prelude Sporty 17.0 19.8 22.7 24 ## 27 Honda Civic Small 8.4 12.1 15.8 42 ## 28 Honda Accord Compact 13.8 17.5 21.2 24 ## 29 Hyundai Excel Small 6.8 8.0 9.2 29 ## 30 Hyundai Elantra Small 9.0 10.0 11.0 22 ## 31 Hyundai Scoupe Sporty 9.1 10.0 11.0 26 ## 32 Hyundai Sonata Midsize 12.4 13.9 15.3 20 ## 33 Mazda 323 Small 7.4 8.3 9.1 29 ## 34 Mazda Protege Small 10.9 11.6 12.3 28 ## 35 Mazda 626 Compact 14.3 16.5 18.7 26 ## 36 Mercedes-Benz 190E Compact 29.0 31.9 34.9 20 ## 37 Mercury Capri Sporty 13.3 14.1 15.0 23 ## 38 Mercury Cougar Midsize 14.9 14.9 14.9 19 ## 39 Mitsubishi Mirage Small 7.7 10.3 12.9 29 ## 40 Nissan Sentra Small 8.7 11.8 14.9 29 ## 41 Nissan Altima Compact 13.0 15.7 18.3 24 ## 42 Oldsmobile Achieva Compact 13.0 13.5 14.0 24 ## 43 Oldsmobile Cutlass_Ciera Midsize 14.2 16.3 18.4 23 ## 44 Oldsmobile Silhouette Van 19.5 19.5 19.5 18 ## 45 Plymouth Laser Sporty 11.4 14.4 17.4 23 ## 46 Pontiac LeMans Small 8.2 9.0 9.9 31 ## 47 Pontiac Sunbird Compact 9.4 11.1 12.8 23 ## 48 Saab 900 Compact 20.3 28.7 37.1 20 ## 49 Saturn SL Small 9.2 11.1 12.9 28 ## 50 Subaru Justy Small 7.3 8.4 9.5 33 ## 51 Subaru Loyale Small 10.5 10.9 11.3 25 ## 52 Subaru Legacy Compact 16.3 19.5 22.7 23 ## 53 Suzuki Swift Small 7.3 8.6 10.0 39 ## 54 Toyota Tercel Small 7.8 9.8 11.8 32 ## 55 Toyota Celica Sporty 14.2 18.4 22.6 25 ## 56 Volkswagen Fox Small 8.7 9.1 9.5 25 ## 57 Volkswagen Passat Compact 17.6 20.0 22.4 21 ## 58 Volvo 240 Compact 21.8 22.7 23.5 21 ## MPG.highway ## 1 31 ## 2 26 ## 3 30 ## 4 31 ## 5 36 ## 6 34 ## 7 28 ## 8 29 ## 9 23 ## 10 20 ## 11 26 ## 12 28 ## 13 28 ## 14 33 ## 15 29 ## 16 27 ## 17 27 ## 18 33 ## 19 33 ## 20 30 ## 21 27 ## 22 30 ## 23 30 ## 24 50 ## 25 36 ## 26 31 ## 27 46 ## 28 31 ## 29 33 ## 30 29 ## 31 34 ## 32 27 ## 33 37 ## 34 36 ## 35 34 ## 36 29 ## 37 26 ## 38 26 ## 39 33 ## 40 33 ## 41 30 ## 42 31 ## 43 31 ## 44 23 ## 45 30 ## 46 41 ## 47 31 ## 48 26 ## 49 38 ## 50 37 ## 51 30 ## 52 30 ## 53 43 ## 54 37 ## 55 32 ## 56 33 ## 57 30 ## 58 28 # 또는 Cars93_1 %&gt;% filter(Type == c(&quot;Compact&quot;) | Max.Price &lt;= 20 | MPG.highway &gt;= 30) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city ## 1 Acura Integra Small 12.9 15.9 18.8 25 ## 2 Audi 90 Compact 25.9 29.1 32.3 20 ## 3 BMW 535i Midsize 23.7 30.0 36.2 22 ## 4 Buick Century Midsize 14.2 15.7 17.3 22 ## 5 Chevrolet Cavalier Compact 8.5 13.4 18.3 25 ## 6 Chevrolet Corsica Compact 11.4 11.4 11.4 25 ## 7 Chevrolet Camaro Sporty 13.4 15.1 16.8 19 ## 8 Chevrolet Lumina Midsize 13.4 15.9 18.4 21 ## 9 Chevrolet Lumina_APV Van 14.7 16.3 18.0 18 ## 10 Chevrolet Astro Van 14.7 16.6 18.6 15 ## 11 Chevrolet Caprice Large 18.0 18.8 19.6 17 ## 12 Chrylser Concorde Large 18.4 18.4 18.4 20 ## 13 Chrysler LeBaron Compact 14.5 15.8 17.1 23 ## 14 Dodge Colt Small 7.9 9.2 10.6 29 ## 15 Dodge Shadow Small 8.4 11.3 14.2 23 ## 16 Dodge Spirit Compact 11.9 13.3 14.7 22 ## 17 Dodge Dynasty Midsize 14.8 15.6 16.4 21 ## 18 Eagle Summit Small 7.9 12.2 16.5 29 ## 19 Ford Festiva Small 6.9 7.4 7.9 31 ## 20 Ford Escort Small 8.4 10.1 11.9 23 ## 21 Ford Tempo Compact 10.4 11.3 12.2 22 ## 22 Ford Probe Sporty 12.8 14.0 15.2 24 ## 23 Ford Taurus Midsize 15.6 20.2 24.8 21 ## 24 Geo Metro Small 6.7 8.4 10.0 46 ## 25 Geo Storm Sporty 11.5 12.5 13.5 30 ## 26 Honda Prelude Sporty 17.0 19.8 22.7 24 ## 27 Honda Civic Small 8.4 12.1 15.8 42 ## 28 Honda Accord Compact 13.8 17.5 21.2 24 ## 29 Hyundai Excel Small 6.8 8.0 9.2 29 ## 30 Hyundai Elantra Small 9.0 10.0 11.0 22 ## 31 Hyundai Scoupe Sporty 9.1 10.0 11.0 26 ## 32 Hyundai Sonata Midsize 12.4 13.9 15.3 20 ## 33 Mazda 323 Small 7.4 8.3 9.1 29 ## 34 Mazda Protege Small 10.9 11.6 12.3 28 ## 35 Mazda 626 Compact 14.3 16.5 18.7 26 ## 36 Mercedes-Benz 190E Compact 29.0 31.9 34.9 20 ## 37 Mercury Capri Sporty 13.3 14.1 15.0 23 ## 38 Mercury Cougar Midsize 14.9 14.9 14.9 19 ## 39 Mitsubishi Mirage Small 7.7 10.3 12.9 29 ## 40 Nissan Sentra Small 8.7 11.8 14.9 29 ## 41 Nissan Altima Compact 13.0 15.7 18.3 24 ## 42 Oldsmobile Achieva Compact 13.0 13.5 14.0 24 ## 43 Oldsmobile Cutlass_Ciera Midsize 14.2 16.3 18.4 23 ## 44 Oldsmobile Silhouette Van 19.5 19.5 19.5 18 ## 45 Plymouth Laser Sporty 11.4 14.4 17.4 23 ## 46 Pontiac LeMans Small 8.2 9.0 9.9 31 ## 47 Pontiac Sunbird Compact 9.4 11.1 12.8 23 ## 48 Saab 900 Compact 20.3 28.7 37.1 20 ## 49 Saturn SL Small 9.2 11.1 12.9 28 ## 50 Subaru Justy Small 7.3 8.4 9.5 33 ## 51 Subaru Loyale Small 10.5 10.9 11.3 25 ## 52 Subaru Legacy Compact 16.3 19.5 22.7 23 ## 53 Suzuki Swift Small 7.3 8.6 10.0 39 ## 54 Toyota Tercel Small 7.8 9.8 11.8 32 ## 55 Toyota Celica Sporty 14.2 18.4 22.6 25 ## 56 Volkswagen Fox Small 8.7 9.1 9.5 25 ## 57 Volkswagen Passat Compact 17.6 20.0 22.4 21 ## 58 Volvo 240 Compact 21.8 22.7 23.5 21 ## MPG.highway ## 1 31 ## 2 26 ## 3 30 ## 4 31 ## 5 36 ## 6 34 ## 7 28 ## 8 29 ## 9 23 ## 10 20 ## 11 26 ## 12 28 ## 13 28 ## 14 33 ## 15 29 ## 16 27 ## 17 27 ## 18 33 ## 19 33 ## 20 30 ## 21 27 ## 22 30 ## 23 30 ## 24 50 ## 25 36 ## 26 31 ## 27 46 ## 28 31 ## 29 33 ## 30 29 ## 31 34 ## 32 27 ## 33 37 ## 34 36 ## 35 34 ## 36 29 ## 37 26 ## 38 26 ## 39 33 ## 40 33 ## 41 30 ## 42 31 ## 43 31 ## 44 23 ## 45 30 ## 46 41 ## 47 31 ## 48 26 ## 49 38 ## 50 37 ## 51 30 ## 52 30 ## 53 43 ## 54 37 ## 55 32 ## 56 33 ## 57 30 ## 58 28 위의 3가지 조건을 OR로 만족시키는 관측치의 갯수는 58개 임을 알 수 있다. 4.4.5 행의 위치를 지정해서 행의 데이터 부분집합 선택 slice(dataframe, from, to) dataframe: 데이터 세트 from : 시작 위치 to : 마지막 위치 filter()가 조건에 의한 행의 선택이었다면, 위치(position)를 사용한 행의 선택을 위해서는 slice() 함수를 사용한다. Cars93_1 데이터 세트의 6번째에서 10번째 행(row)의 데이터를 선택해 보자. # slice() : select rows by position slice(Cars93_1, 6:10) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city ## 1 Buick Century Midsize 14.2 15.7 17.3 22 ## 2 Buick LeSabre Large 19.9 20.8 21.7 19 ## 3 Buick Roadmaster Large 22.6 23.7 24.9 16 ## 4 Buick Riviera Midsize 26.3 26.3 26.3 19 ## 5 Cadillac DeVille Large 33.0 34.7 36.3 16 ## MPG.highway ## 1 31 ## 2 28 ## 3 25 ## 4 27 ## 5 25 # 또는 Cars93_1 %&gt;% slice(6:10) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city ## 1 Buick Century Midsize 14.2 15.7 17.3 22 ## 2 Buick LeSabre Large 19.9 20.8 21.7 19 ## 3 Buick Roadmaster Large 22.6 23.7 24.9 16 ## 4 Buick Riviera Midsize 26.3 26.3 26.3 19 ## 5 Cadillac DeVille Large 33.0 34.7 36.3 16 ## MPG.highway ## 1 31 ## 2 28 ## 3 25 ## 4 27 ## 5 25 6번쨰 행부터 10번쨰 행까지를 선택하게 된다. 4.5 arrange() 함수를 이용한 행의 정렬 4.5.1 arrange() 함수의 기본 형식 arrange(dataframe, order criterion 1, order criterion 2, ...) dataframe : 데이터 세트 order criterion : 정렬 기준이 되는 컬럼 명(디폴트로 오름차순). 내림차순의 경우 desc(컬럼명) 데이터 프레임을 정렬할 때 arrange() 함수를 쓰면 매우 편리하다. Cars93_1 데이터 프레임의 행들을 최고가격(Max.Price) 컬럼 기준으로 오름 차순으로 정렬해 보자. # arrange() : reorder rows of data frame in ascending order b1 &lt;- arrange(Cars93_1, Max.Price) head(b1) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Ford Festiva Small 6.9 7.4 7.9 31 33 ## 2 Mazda 323 Small 7.4 8.3 9.1 29 37 ## 3 Hyundai Excel Small 6.8 8.0 9.2 29 33 ## 4 Subaru Justy Small 7.3 8.4 9.5 33 37 ## 5 Volkswagen Fox Small 8.7 9.1 9.5 25 33 ## 6 Pontiac LeMans Small 8.2 9.0 9.9 31 41 # 또는 b2 &lt;- Cars93_1 %&gt;% arrange(Max.Price) head(b2) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Ford Festiva Small 6.9 7.4 7.9 31 33 ## 2 Mazda 323 Small 7.4 8.3 9.1 29 37 ## 3 Hyundai Excel Small 6.8 8.0 9.2 29 33 ## 4 Subaru Justy Small 7.3 8.4 9.5 33 37 ## 5 Volkswagen Fox Small 8.7 9.1 9.5 25 33 ## 6 Pontiac LeMans Small 8.2 9.0 9.9 31 41 이제는 Cars93_1 데이터 프레임의 행들을 최고가격(Max.Price) 컬럼 기준으로 내림 차순으로 정렬해 보자. # arrange() : reorder rows of data frame in descending order b3 &lt;- arrange(Cars93_1, desc(Max.Price)) head(b3) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Mercedes-Benz 300E Midsize 43.8 61.9 80.0 19 25 ## 2 Infiniti Q45 Midsize 45.4 47.9 50.4 17 22 ## 3 Audi 100 Midsize 30.8 37.7 44.6 19 26 ## 4 Cadillac Seville Midsize 37.5 40.1 42.7 16 25 ## 5 Chevrolet Corvette Sporty 34.6 38.0 41.5 17 25 ## 6 Acura Legend Midsize 29.2 33.9 38.7 18 25 # 또는 b4 &lt;- Cars93_1 %&gt;% arrange(desc(Max.Price)) head(b4) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Mercedes-Benz 300E Midsize 43.8 61.9 80.0 19 25 ## 2 Infiniti Q45 Midsize 45.4 47.9 50.4 17 22 ## 3 Audi 100 Midsize 30.8 37.7 44.6 19 26 ## 4 Cadillac Seville Midsize 37.5 40.1 42.7 16 25 ## 5 Chevrolet Corvette Sporty 34.6 38.0 41.5 17 25 ## 6 Acura Legend Midsize 29.2 33.9 38.7 18 25 4.5.2 복수 개의 정렬 기준으로 행을 정렬하기 여러개의 기준에 의해서 정렬을 하고 싶으면 기준이 되는 컬럼을 정렬하고자 하는 순서대로 나열하면 됩니다. 기본 정렬 옵셥은 오름차순(ascending)이며, 만약 내림차순(descending) 으로 정렬을 하고 싶다면 desc()를 입력해주면 됩니다. Cars93_1 데이터 프레임의 고속도로 연비(MPG.highway) 가 높은 순서(오름차순)대로 정렬을 하되, 만약 고속도로 연비가 동일하다면 최고가격(Max.Price)가 낮은 순서대로(내림차순) 정렬을 해보자. # arrange() : reorder rows of data frame b5 &lt;- arrange(Cars93_1, desc(MPG.highway), Max.Price) head(b5) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Geo Metro Small 6.7 8.4 10.0 46 50 ## 2 Honda Civic Small 8.4 12.1 15.8 42 46 ## 3 Suzuki Swift Small 7.3 8.6 10.0 39 43 ## 4 Pontiac LeMans Small 8.2 9.0 9.9 31 41 ## 5 Saturn SL Small 9.2 11.1 12.9 28 38 ## 6 Mazda 323 Small 7.4 8.3 9.1 29 37 # 또는 b6 &lt;- Cars93_1 %&gt;% arrange(desc(MPG.highway), Max.Price) head(b6) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 1 Geo Metro Small 6.7 8.4 10.0 46 50 ## 2 Honda Civic Small 8.4 12.1 15.8 42 46 ## 3 Suzuki Swift Small 7.3 8.6 10.0 39 43 ## 4 Pontiac LeMans Small 8.2 9.0 9.9 31 41 ## 5 Saturn SL Small 9.2 11.1 12.9 28 38 ## 6 Mazda 323 Small 7.4 8.3 9.1 29 37 위의 스크립트에 대한 결과(의 일부)는 다음과 같다. 첫 번째 정렬 조건인 MPG.Highway의 내림차순으로 행들이 정렬되어 있음을 알 수 있다. 그런데 MPG.highway의 값이 같은 경우네는 두 번쨰 정렬 조건인 Max.Price의 오름차순으로 행들이 정렬되어 있다. 참고로, arrange() 함수 말고도 아래처럼 order() 함수를 사용해서 indexing 하는 방법도 있지만, 아무래도 arrange() 함수가 더 깔끔하고 해석하기에 좋다. # order() 함수의 이용 b7 &lt;- Cars93[order(-Cars93_1$MPG.highway, Cars93_1$Max.Price), ] head(b7) ## Manufacturer Model Type Min.Price Price Max.Price MPG.city MPG.highway ## 39 Geo Metro Small 6.7 8.4 10.0 46 50 ## 42 Honda Civic Small 8.4 12.1 15.8 42 46 ## 83 Suzuki Swift Small 7.3 8.6 10.0 39 43 ## 73 Pontiac LeMans Small 8.2 9.0 9.9 31 41 ## 79 Saturn SL Small 9.2 11.1 12.9 28 38 ## 53 Mazda 323 Small 7.4 8.3 9.1 29 37 ## AirBags DriveTrain Cylinders EngineSize Horsepower RPM Rev.per.mile ## 39 None Front 3 1.0 55 5700 3755 ## 42 Driver only Front 4 1.5 102 5900 2650 ## 83 None Front 3 1.3 70 6000 3360 ## 73 None Front 4 1.6 74 5600 3130 ## 79 Driver only Front 4 1.9 85 5000 2145 ## 53 None Front 4 1.6 82 5000 2370 ## Man.trans.avail Fuel.tank.capacity Passengers Length Wheelbase Width ## 39 Yes 10.6 4 151 93 63 ## 42 Yes 11.9 4 173 103 67 ## 83 Yes 10.6 4 161 93 63 ## 73 Yes 13.2 4 177 99 66 ## 79 Yes 12.8 5 176 102 68 ## 53 Yes 13.2 4 164 97 66 ## Turn.circle Rear.seat.room Luggage.room Weight Origin Make ## 39 34 27.5 10 1695 non-USA Geo Metro ## 42 36 28.0 12 2350 non-USA Honda Civic ## 83 34 27.5 10 1965 non-USA Suzuki Swift ## 73 35 25.5 17 2350 USA Pontiac LeMans ## 79 40 26.5 12 2495 USA Saturn SL ## 53 34 27.0 16 2325 non-USA Mazda 323 4.6 rename() 함수를 이용한 데이터 프레임의 컬럼 이름 변경 4.6.1 rename() 함수의 기본 형식 rename(dataframe, new_var1 = old_var1, new_var2 = old_var2, ...) dataframe : 데이터 세트 new_var1 = old_var1, : 새로운 컬럼 명(new_var1) = 이전의 컬럼명(old_var1) 새로운 변수 이름을 앞에, 이전 변수이름을 뒤에 위치시킨다. 큰 따옴표를 안 쓰며, 그냥 컬럼 이름만 써 준다. 이름을 변경하고자 하는 변수가 여러 개 일 경우 ‘,’ (comma)로 구분한다. Cars93_1 데이터 프레임의 8개의 컬럼명 앞에 ’New_' 라는 접두사(prefix)를 붙여 바꿔보자. # rename() : rename column name names(Cars93_1) ## [1] &quot;Manufacturer&quot; &quot;Model&quot; &quot;Type&quot; &quot;Min.Price&quot; &quot;Price&quot; ## [6] &quot;Max.Price&quot; &quot;MPG.city&quot; &quot;MPG.highway&quot; # rename(dataframe, new_var1 = old_var1, new_var2 = old_var2, ...) Cars93_2 &lt;- rename(Cars93_1, New_Model = Model, New_Type = Type, New_MPG.city = MPG.city, New_MPG.highway = MPG.highway) names(Cars93_2) ## [1] &quot;Manufacturer&quot; &quot;New_Model&quot; &quot;New_Type&quot; &quot;Min.Price&quot; ## [5] &quot;Price&quot; &quot;Max.Price&quot; &quot;New_MPG.city&quot; &quot;New_MPG.highway&quot; # 또는 Cars93_2 &lt;- Cars93_1 %&gt;% rename(New_Model = Model, New_Type = Type, New_MPG.city = MPG.city, New_MPG.highway = MPG.highway) names(Cars93_2) ## [1] &quot;Manufacturer&quot; &quot;New_Model&quot; &quot;New_Type&quot; &quot;Min.Price&quot; ## [5] &quot;Price&quot; &quot;Max.Price&quot; &quot;New_MPG.city&quot; &quot;New_MPG.highway&quot; 위의 결과로 Cars93_2 데이터 프레임이 생성되고, New_Model, New_Type, New_MPG.city, New_MPG.hightway 등의 4개의 컬럼만 이름이 변경되고, 나머지는 이전의 컬럼 명 그대로 사용하다. 이전에 plyr 패키지의 rename() 함수나 reshaple 패키지의 rename() 함수를 사용해 보았다면 약간 혼란이 생길 수 있다. 큰 따옴표(“var_name”)를 써야 하는건지 말아야 하는건지, 새로운 변수 이름(new_var)과 이전 변수 이름(old_var)의 위치가 앞인지 뒤인지, 변수가 여러개인 경우 c() 로 묶어주어야 하는지 아닌지가 패키지별로 조금씩 다르기 때문이다. (참고 링크=&gt; http://rfriend.tistory.com/41 ) 데이터 전처리는 dplyr 패키지로 단일화해 나가는 것이 혼동을 줄일 수 있는 좋은 전략일 것이다. 4.7 distinct() 함수를 이용한 유일한 값 추출 4.7.1 distinct() 함수의 기본 형식 distinct(dataframe, var1, var2, ...) dataframe : 데이터 세트 var1, var2, ... : 중복이 없는 유일한 값(unique, distinct value)을 추출하고자 하는 기준이 되는 컬럼(변수) base 패키지의 unique() 함수와 같은 기능을 수행하지만, dplyr 패키지의 distinct() 가 C 언어로 작성이 되어 있기 때문에 속도는 훨씬 빠르다. 4.7.2 단일 기준에 의한 유일 값 추출 Cars93_1 데이터 프레임에서 ‘차종(Type)’과 ’생산국-미국여부(Origin)’ 변수를 기준으로 중복없는 유일한 값을 추출해 보자. # to use Cars93 dataframe names(Cars93) ## [1] &quot;Manufacturer&quot; &quot;Model&quot; &quot;Type&quot; ## [4] &quot;Min.Price&quot; &quot;Price&quot; &quot;Max.Price&quot; ## [7] &quot;MPG.city&quot; &quot;MPG.highway&quot; &quot;AirBags&quot; ## [10] &quot;DriveTrain&quot; &quot;Cylinders&quot; &quot;EngineSize&quot; ## [13] &quot;Horsepower&quot; &quot;RPM&quot; &quot;Rev.per.mile&quot; ## [16] &quot;Man.trans.avail&quot; &quot;Fuel.tank.capacity&quot; &quot;Passengers&quot; ## [19] &quot;Length&quot; &quot;Wheelbase&quot; &quot;Width&quot; ## [22] &quot;Turn.circle&quot; &quot;Rear.seat.room&quot; &quot;Luggage.room&quot; ## [25] &quot;Weight&quot; &quot;Origin&quot; &quot;Make&quot; # distinct(dataframe, var1) : find unique values of var1 in a table distinct(Cars93, Type) ## Type ## 1 Small ## 2 Midsize ## 3 Compact ## 4 Large ## 5 Sporty ## 6 Van distinct(Cars93, Origin) ## Origin ## 1 non-USA ## 2 USA # 또는 Cars93 %&gt;% distinct(Type) ## Type ## 1 Small ## 2 Midsize ## 3 Compact ## 4 Large ## 5 Sporty ## 6 Van Cars93 %&gt;% distinct(Origin) ## Origin ## 1 non-USA ## 2 USA distinct() 함수의 결과는 데이터 프레임으로 출력이 된다. 4.7.3 복수 기준에 의한 유일 값 추출 Cars93_1 데이터 프레임에서 ‘차종(Type)’과 ’생산국-미국여부(Origin)’ 변수를 동시에 고려하여 중복없는 유일한 값을 추출해 보자. # distinct(dataframe, var1, var2) : find unique values in a table distinct(Cars93, Type, Origin) ## Type Origin ## 1 Small non-USA ## 2 Midsize non-USA ## 3 Compact non-USA ## 4 Midsize USA ## 5 Large USA ## 6 Compact USA ## 7 Sporty USA ## 8 Van USA ## 9 Small USA ## 10 Sporty non-USA ## 11 Van non-USA distinct(Cars93, Origin, Type) ## Type Origin ## 1 Small non-USA ## 2 Midsize non-USA ## 3 Compact non-USA ## 4 Midsize USA ## 5 Large USA ## 6 Compact USA ## 7 Sporty USA ## 8 Van USA ## 9 Small USA ## 10 Sporty non-USA ## 11 Van non-USA # 또는 Cars93 %&gt;% distinct(Type, Origin) ## Type Origin ## 1 Small non-USA ## 2 Midsize non-USA ## 3 Compact non-USA ## 4 Midsize USA ## 5 Large USA ## 6 Compact USA ## 7 Sporty USA ## 8 Van USA ## 9 Small USA ## 10 Sporty non-USA ## 11 Van non-USA Cars93 %&gt;% distinct(Origin, Type) ## Type Origin ## 1 Small non-USA ## 2 Midsize non-USA ## 3 Compact non-USA ## 4 Midsize USA ## 5 Large USA ## 6 Compact USA ## 7 Sporty USA ## 8 Van USA ## 9 Small USA ## 10 Sporty non-USA ## 11 Van non-USA 참고로, base 패키지의 unique() 함수로는 unique(Cars93[, c(\"Origin\", \"Type\")]) 이렇게 입력하면 된다. # unique() 함수의 사용 unique(Cars93[, c(&quot;Origin&quot;)]) ## [1] non-USA USA ## Levels: USA non-USA unique(Cars93[, c(&quot;Type&quot;)]) ## [1] Small Midsize Compact Large Sporty Van ## Levels: Compact Large Midsize Small Sporty Van unique(Cars93[, c(&quot;Origin&quot;, &quot;Type&quot;)]) ## Origin Type ## 1 non-USA Small ## 2 non-USA Midsize ## 3 non-USA Compact ## 6 USA Midsize ## 7 USA Large ## 12 USA Compact ## 14 USA Sporty ## 16 USA Van ## 23 USA Small ## 40 non-USA Sporty ## 56 non-USA Van unique(Cars93[, c(&quot;Type&quot;, &quot;Origin&quot;)]) ## Type Origin ## 1 Small non-USA ## 2 Midsize non-USA ## 3 Compact non-USA ## 6 Midsize USA ## 7 Large USA ## 12 Compact USA ## 14 Sporty USA ## 16 Van USA ## 23 Small USA ## 40 Sporty non-USA ## 56 Van non-USA unique() 함수의 결과는 기준 컬럼이 하나일 때는 factor 형으로, 기준 컬럼이 여러 개일 때는 데이터 프레임 형태로 출력이 된다.  unique(), duplicate(), distinct()의 비교 4.8 무작위 표본 추출 4.8.1 정해진 갯수 만큼의 표본 무작위 추출 sample_n(dataframe, n) dataframe : 데이터 세트 n : 무작위 추출할 표본의 갯수 Cars93 데이터 프레임애소 1~5번째 변수에 대해 10개의 관측치를 무작위로 추출해 보자. # sample_n() : randomly sample rows for a fixed number sample_n(Cars93[, 1:5], 10) ## Manufacturer Model Type Min.Price Price ## 1 Ford Escort Small 8.4 10.1 ## 2 Lincoln Town_Car Large 34.4 36.1 ## 3 Oldsmobile Eighty-Eight Large 19.5 20.7 ## 4 Acura Legend Midsize 29.2 33.9 ## 5 Pontiac Firebird Sporty 14.0 17.7 ## 6 Chevrolet Astro Van 14.7 16.6 ## 7 Ford Mustang Sporty 10.8 15.9 ## 8 Pontiac LeMans Small 8.2 9.0 ## 9 Toyota Tercel Small 7.8 9.8 ## 10 Infiniti Q45 Midsize 45.4 47.9 # random sampling one more time sample_n(Cars93[, 1:5], 10) ## Manufacturer Model Type Min.Price Price ## 1 Pontiac LeMans Small 8.2 9.0 ## 2 BMW 535i Midsize 23.7 30.0 ## 3 Chevrolet Caprice Large 18.0 18.8 ## 4 Ford Crown_Victoria Large 20.1 20.9 ## 5 Dodge Stealth Sporty 18.5 25.8 ## 6 Honda Accord Compact 13.8 17.5 ## 7 Eagle Summit Small 7.9 12.2 ## 8 Acura Legend Midsize 29.2 33.9 ## 9 Lincoln Continental Midsize 33.3 34.3 ## 10 Mercury Cougar Midsize 14.9 14.9 # 또는 Cars93[, 1:5] %&gt;% sample_n(10) ## Manufacturer Model Type Min.Price Price ## 1 Volvo 240 Compact 21.8 22.7 ## 2 Honda Accord Compact 13.8 17.5 ## 3 Mitsubishi Mirage Small 7.7 10.3 ## 4 Acura Legend Midsize 29.2 33.9 ## 5 Ford Festiva Small 6.9 7.4 ## 6 Mercedes-Benz 300E Midsize 43.8 61.9 ## 7 Chevrolet Cavalier Compact 8.5 13.4 ## 8 Nissan Altima Compact 13.0 15.7 ## 9 Mazda MPV Van 16.6 19.1 ## 10 Chevrolet Lumina Midsize 13.4 15.9 Cars93[, 1:5] %&gt;% sample_n(10) ## Manufacturer Model Type Min.Price Price ## 1 Dodge Caravan Van 13.6 19.0 ## 2 Ford Festiva Small 6.9 7.4 ## 3 Toyota Celica Sporty 14.2 18.4 ## 4 Chevrolet Lumina_APV Van 14.7 16.3 ## 5 Saab 900 Compact 20.3 28.7 ## 6 Chevrolet Corvette Sporty 34.6 38.0 ## 7 Volvo 240 Compact 21.8 22.7 ## 8 Hyundai Excel Small 6.8 8.0 ## 9 Ford Escort Small 8.4 10.1 ## 10 Buick LeSabre Large 19.9 20.8 전체 관측치 중에 10개의 관측치를 무작위로 표본을 추출해 준다. sample_n() 함수를 실행할 때 마다 추출된 표본은 달라짐을 알 수 있다. 4.8.2 정해진 비율로 표본 무작위 추출 sample_frac(dataframe, p) dataframe : 데이터 세트 p : 무작위 추출하고자하는 비율 (예, 0.1 -&gt; 10%) Cars93 데이터 프레임에서 1~5번째 변수에 대해 10%의 관측치를 무작위로 추출해 보자. # sample_frac() : randomly sample rows for a fixed fraction nrow(Cars93) ## [1] 93 nrow(Cars93)*0.1 ## [1] 9.3 sample_frac(Cars93[ , 1:5], 0.1) ## Manufacturer Model Type Min.Price Price ## 1 Mitsubishi Diamante Midsize 22.4 26.1 ## 2 Volvo 850 Midsize 24.8 26.7 ## 3 Dodge Stealth Sporty 18.5 25.8 ## 4 Saturn SL Small 9.2 11.1 ## 5 Dodge Dynasty Midsize 14.8 15.6 ## 6 Mazda RX-7 Sporty 32.5 32.5 ## 7 Pontiac Sunbird Compact 9.4 11.1 ## 8 Oldsmobile Cutlass_Ciera Midsize 14.2 16.3 ## 9 Pontiac Bonneville Large 19.4 24.4 # 또는 Cars93[, 1:5] %&gt;% sample_frac(0.1) ## Manufacturer Model Type Min.Price Price ## 1 Eagle Summit Small 7.9 12.2 ## 2 Suzuki Swift Small 7.3 8.6 ## 3 Hyundai Elantra Small 9.0 10.0 ## 4 Buick LeSabre Large 19.9 20.8 ## 5 Chrylser Concorde Large 18.4 18.4 ## 6 Audi 90 Compact 25.9 29.1 ## 7 Dodge Stealth Sporty 18.5 25.8 ## 8 Subaru Justy Small 7.3 8.4 ## 9 Nissan Quest Van 16.7 19.1 Cars93 데이터 프레임은 관측치가 93개 이며, 10%는 9.3개에 해당 sample_frac(Cars93, 0.1)은 총 9개의 무작위 샘플을 추출 4.8.3 정해진 갯수 만큼의 표본 복원 추출 smaple_n(dataframe, n, replace = TRUE) dataframe : 데이터 세트 n : 추출하고자 하는 표본 갯수 replace = TRUE : 복원 추출 앞의 두 경우는 한번 추출한 표본은 다시 추출하지 않는 ’비복원 추출(sampling with replacement)’이었다(눈을 감고 주머니에서 한번 뽑았으면, 뽑힌 공은 다시 주머니에 넣지 않고 옆에 따로 빼어놓고, 다시 눈을 감고 주머니에서 공을 뽑음). dplyr 패키지의 sample_n(), sample_frac() 함수의 디폴트는 비복원추출이며, 만약 ’복원추출(sampling with replacement, bootstrap sampling)’을 하고 싶다면 ‘replace = TRUE’ 옵션을 설정해주면 된다(눈을 감고 주머니에서 공을 뽑고, 뽑힌 공을 다시 주머니에 넣은 후에, 눈을 감고 다시 주머니에서 공을 뽑음). Cars93 데이터 프레임에서 1~5번까지 변수에 대해 20개의 관측치를 무작위로 복원 추출해보자. # sample_n(dataframe, n, replace = TRUE) : random sampling with replacement # a bootstrap sample of 20 records sample_n(Cars93[, 1:5], 20, replace = TRUE) ## Manufacturer Model Type Min.Price Price ## 1 Acura Integra Small 12.9 15.9 ## 2 Geo Metro Small 6.7 8.4 ## 3 Toyota Tercel Small 7.8 9.8 ## 4 Lincoln Town_Car Large 34.4 36.1 ## 5 Pontiac Grand_Prix Midsize 15.4 18.5 ## 6 Mazda 323 Small 7.4 8.3 ## 7 Saab 900 Compact 20.3 28.7 ## 8 Honda Civic Small 8.4 12.1 ## 9 Cadillac DeVille Large 33.0 34.7 ## 10 Subaru Justy Small 7.3 8.4 ## 11 Cadillac DeVille Large 33.0 34.7 ## 12 Chevrolet Corsica Compact 11.4 11.4 ## 13 Hyundai Excel Small 6.8 8.0 ## 14 Mazda 323 Small 7.4 8.3 ## 15 Ford Crown_Victoria Large 20.1 20.9 ## 16 Chevrolet Corsica Compact 11.4 11.4 ## 17 Nissan Quest Van 16.7 19.1 ## 18 Dodge Shadow Small 8.4 11.3 ## 19 Nissan Sentra Small 8.7 11.8 ## 20 BMW 535i Midsize 23.7 30.0 무작위 복원 추출을 하면 동일한 표본이 중복으로 추출될 수 있다. 4.8.4 집단별 층화 표본 추출 dataframe %&gt;% group_by(factor_var) %&gt;% sample_n(size) dataframe : 데이터 세트 factor_var : 그룹으로 지정할 변수 size : 표본의 갯수 분석을 하다 보면 집단, 그룹별로 동일한 수의 표본을 무작위 추출해서 분석해야 하는 경우가 있다. 특히 분석 주제 혹은 분석에 큰 영향을 미치는 요인 변수에 대한 집단 분포(distribution)가 한쪽 그룹으로 심하게 편향된 모집단(biased, unbalanced population)의 경우 층화 무작위 표본 추출(stratified random sampling)이 필요합니다. *[예제] Cars93 데이터 프레임에서 ‘제조국가_미국여부(Origin)’의 ’USA,’ ‘non-USA’ 요인 속성별로 각 10개씩의 표본을 무작위 비복원 추출하시오.* # dataframe %&gt;% # group_by(factor_var) %&gt;% # sample_n(size) : random sampling by group Cars93[ , c(&quot;Manufacturer&quot;, &quot;Model&quot;, &quot;Origin&quot;)] %&gt;% group_by(Origin) %&gt;% sample_n(10) ## # A tibble: 20 x 3 ## # Groups: Origin [2] ## Manufacturer Model Origin ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Saturn SL USA ## 2 Ford Crown_Victoria USA ## 3 Dodge Stealth USA ## # ... with 17 more rows 위의 ‘%&gt;%’ (단축키 : shift + ctrl + M)의 chaining 에 대해서는 다음번 포스팅에서 별도로 소개하겠으니 지금 궁금하시더라도 조금만 참아주세요. ^^; 4.9 mutate() 함수를 이용한 새로운 컬럼 생성 4.9.1 mutate() 함수의 기본 형식 함수 mutate()는 컬럼을 추가할 때 사용한다. 비슷한 기능을 하는 함수로 base 패키지의 transform()이 있지만, 함수 mutate()는 함수에서 새로 만든 열을 같은 함수 안에서 바로 사용할 수 있는 장점이 있다. 단, 새로 생성된 칼럼은 별도의 변수로 지정하거나 기존의 데이터에 덮어씌우지 않는 한 저장되지 않는다. mutate(dataframe, new_var = expression_of_old_var, ..., .keep, .before, .after) dataframe : 데이터 세트 new_var = expression_of_old_var : 새로운 컬럼(new_var)을 생성하는 식 … : 여러 개 반복 가능 .keep : (“all,” “used,” “unused,” “none”) .before .after : 기존 변수 + 신규 변수 모두 keep** 4.9.2 새로운 컬럼 생성 예 x, y의 2개의 컬럼에 각각의 값을1과 2로 하는 데이터 df 에 대해 x+y를 값으로 하는 새로운 컬럼 z를 생성해 보자. # z = x + y 컬럼 생성 df &lt;- tibble(x = 1, y = 2) df ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 mutate(df, z=x+y) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 # 또는 df %&gt;% mutate(z = x + y) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 Cars93 데이터프레임에서 최소가격(Min.Price)과 최대가격(Max.Price)의 범위(Price_range)를 구해보자. # mutate(dataframe, new_var = operation of old vars, ...) : Create(add) new columns Cars93_1 &lt;- Cars93[c(1:10), # subset for better printing : (10 X 3) c(&quot;Model&quot;, &quot;Min.Price&quot;, &quot;Max.Price&quot;)] Cars93_1 &lt;- mutate(Cars93_1, Price_range = Max.Price - Min.Price) Cars93_1 ## Model Min.Price Max.Price Price_range ## 1 Integra 12.9 18.8 5.9 ## 2 Legend 29.2 38.7 9.5 ## 3 90 25.9 32.3 6.4 ## 4 100 30.8 44.6 13.8 ## 5 535i 23.7 36.2 12.5 ## 6 Century 14.2 17.3 3.1 ## 7 LeSabre 19.9 21.7 1.8 ## 8 Roadmaster 22.6 24.9 2.3 ## 9 Riviera 26.3 26.3 0.0 ## 10 DeVille 33.0 36.3 3.3 # 또는 Cars93_1 %&gt;% mutate(Price_range = Max.Price - Min.Price) ## Model Min.Price Max.Price Price_range ## 1 Integra 12.9 18.8 5.9 ## 2 Legend 29.2 38.7 9.5 ## 3 90 25.9 32.3 6.4 ## 4 100 30.8 44.6 13.8 ## 5 535i 23.7 36.2 12.5 ## 6 Century 14.2 17.3 3.1 ## 7 LeSabre 19.9 21.7 1.8 ## 8 Roadmaster 22.6 24.9 2.3 ## 9 Riviera 26.3 26.3 0.0 ## 10 DeVille 33.0 36.3 3.3 Cars93_1 ## Model Min.Price Max.Price Price_range ## 1 Integra 12.9 18.8 5.9 ## 2 Legend 29.2 38.7 9.5 ## 3 90 25.9 32.3 6.4 ## 4 100 30.8 44.6 13.8 ## 5 535i 23.7 36.2 12.5 ## 6 Century 14.2 17.3 3.1 ## 7 LeSabre 19.9 21.7 1.8 ## 8 Roadmaster 22.6 24.9 2.3 ## 9 Riviera 26.3 26.3 0.0 ## 10 DeVille 33.0 36.3 3.3 Cars93 데이터프레임에서 최소가격(Min.Price)과 최대가격(Max.Price)의 범위(Price_range)와 최소가격 대비 최대가격의 비율(Price_ration = Max.Price/Min.Price) 을 나타내는 새로운 컬럼을 생성해 보자. # mutate(dataframe, new_var = operation of old vars, ...) : Create(add) new columns Cars93_1 &lt;- mutate(Cars93_1, Price_range = Max.Price - Min.Price, Price_ratio = Max.Price / Min.Price) Cars93_1 ## Model Min.Price Max.Price Price_range Price_ratio ## 1 Integra 12.9 18.8 5.9 1.457364 ## 2 Legend 29.2 38.7 9.5 1.325342 ## 3 90 25.9 32.3 6.4 1.247104 ## 4 100 30.8 44.6 13.8 1.448052 ## 5 535i 23.7 36.2 12.5 1.527426 ## 6 Century 14.2 17.3 3.1 1.218310 ## 7 LeSabre 19.9 21.7 1.8 1.090452 ## 8 Roadmaster 22.6 24.9 2.3 1.101770 ## 9 Riviera 26.3 26.3 0.0 1.000000 ## 10 DeVille 33.0 36.3 3.3 1.100000 4.9.3 새로운 만든 컬럼(변수)를 이용하여 또 다른 컬럼 생성하기 mutate() 함수는 하나의 함수 명령문 안에서 새로 만든 변수를 바로 이용하여, 또 다른 변수의 input 변수로 사용할 수 있다. 예를 들어, 앞의 예에서 생성한 Price_range 변수의 값이 5이상이면 1, 아니면 0을 값으로 하는 Price_range_cd 컬럼을 생성고 그 결과를 Cars93_2 테이블에 저장해 보자. ( Price_range_cd = ifelse(Price_range &gt;= 5, 1, 0)) # comparison with {dplyr} mutate() and {base} transform() Cars93_2 &lt;- mutate(Cars93_1, Price_range = Max.Price - Min.Price, Price_range_cd = ifelse(Price_range &gt;= 5, 1, 0)) Cars93_2 ## Model Min.Price Max.Price Price_range Price_ratio Price_range_cd ## 1 Integra 12.9 18.8 5.9 1.457364 1 ## 2 Legend 29.2 38.7 9.5 1.325342 1 ## 3 90 25.9 32.3 6.4 1.247104 1 ## 4 100 30.8 44.6 13.8 1.448052 1 ## 5 535i 23.7 36.2 12.5 1.527426 1 ## 6 Century 14.2 17.3 3.1 1.218310 0 ## 7 LeSabre 19.9 21.7 1.8 1.090452 0 ## 8 Roadmaster 22.6 24.9 2.3 1.101770 0 ## 9 Riviera 26.3 26.3 0.0 1.000000 0 ## 10 DeVille 33.0 36.3 3.3 1.100000 0 # 또는 Cars93_2 &lt;- Cars93_1 %&gt;% mutate( Price_range = Max.Price - Min.Price, Price_range_cd = ifelse(Price_range &gt;= 5, 1, 0)) Cars93_2 ## Model Min.Price Max.Price Price_range Price_ratio Price_range_cd ## 1 Integra 12.9 18.8 5.9 1.457364 1 ## 2 Legend 29.2 38.7 9.5 1.325342 1 ## 3 90 25.9 32.3 6.4 1.247104 1 ## 4 100 30.8 44.6 13.8 1.448052 1 ## 5 535i 23.7 36.2 12.5 1.527426 1 ## 6 Century 14.2 17.3 3.1 1.218310 0 ## 7 LeSabre 19.9 21.7 1.8 1.090452 0 ## 8 Roadmaster 22.6 24.9 2.3 1.101770 0 ## 9 Riviera 26.3 26.3 0.0 1.000000 0 ## 10 DeVille 33.0 36.3 3.3 1.100000 0 base 패키지의 transform() 함수도 하나의 명령문 안에 새로 만든 변수를 다른 신규 변수의 input 변수로 사용할 수 있다. # {base} transform() Cars93_3 &lt;- transform(Cars93_1, Price_range = Max.Price - Min.Price, Price_range_cd = ifelse(Price_range &gt;= 5, 1, 0)) Cars93_3 ## Model Min.Price Max.Price Price_range Price_ratio Price_range_cd ## 1 Integra 12.9 18.8 5.9 1.457364 1 ## 2 Legend 29.2 38.7 9.5 1.325342 1 ## 3 90 25.9 32.3 6.4 1.247104 1 ## 4 100 30.8 44.6 13.8 1.448052 1 ## 5 535i 23.7 36.2 12.5 1.527426 1 ## 6 Century 14.2 17.3 3.1 1.218310 0 ## 7 LeSabre 19.9 21.7 1.8 1.090452 0 ## 8 Roadmaster 22.6 24.9 2.3 1.101770 0 ## 9 Riviera 26.3 26.3 0.0 1.000000 0 ## 10 DeVille 33.0 36.3 3.3 1.100000 0 4.9.4 컬럼의 값을 새로운 값으로 변경하기 Cars93_1에 있는 Min.Price의 값을 1.2배를 하고, Max.Price값들은 1.3배로 변경해 보자. 그리고, 최소가격(Min.Price)과 최대가격(Max.Price)의 범위(Price_range)와 최소가격 대비 최대가격의 비율(Price_ration = Max.Price/Min.Price) 도 변경해 보자. 그 결과는 Cars93_4에 저장한다.) Cars93_4 &lt;- mutate(Cars93_1, Min.Price = Min.Price * 1.2, Max.Price = Max.Price * 1.3, Price_range = Max.Price - Min.Price, Price_ratio = Max.Price / Min.Price) Cars93_4 ## Model Min.Price Max.Price Price_range Price_ratio ## 1 Integra 15.48 24.44 8.96 1.578811 ## 2 Legend 35.04 50.31 15.27 1.435788 ## 3 90 31.08 41.99 10.91 1.351030 ## 4 100 36.96 57.98 21.02 1.568723 ## 5 535i 28.44 47.06 18.62 1.654712 ## 6 Century 17.04 22.49 5.45 1.319836 ## 7 LeSabre 23.88 28.21 4.33 1.181323 ## 8 Roadmaster 27.12 32.37 5.25 1.193584 ## 9 Riviera 31.56 34.19 2.63 1.083333 ## 10 DeVille 39.60 47.19 7.59 1.191667 현재의 컬럼의 값을 새로운 값으로도 쉽게 변경할 수 있음을 알 수 있다. 4.9.5 .keep 인수의 사용 예 mutate() 함수의 인수로 .keep= 인수를 사용할 수 있다. 디폴트 값은 “all”이다. 다음의 예를 실행해 보면 쉽게 이해할 수 있다. .keep 이 가질 수 있는 옵션은 all(default), used, unused, none 등이 있다. # Experimental: You can override with `.keep` df &lt;- tibble(x = 1, y = 2, a = &quot;a&quot;, b = &quot;b&quot;) df %&gt;% mutate(z = x + y, .keep = &quot;all&quot;) # the default ## # A tibble: 1 x 5 ## x y a b z ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2 a b 3 df %&gt;% mutate(z = x + y, .keep = &quot;used&quot;) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 df %&gt;% mutate(z = x + y, .keep = &quot;unused&quot;) ## # A tibble: 1 x 3 ## a b z ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 a b 3 df %&gt;% mutate(z = x + y, .keep = &quot;none&quot;) # same as transmute() ## # A tibble: 1 x 1 ## z ## &lt;dbl&gt; ## 1 3 .keep = all : df의 컬럼 변수 전체(x, y, a, b)와 새로 생성된 변수(z) 모두를 보여준다. (default) .keep = used : df의 컬럼 변수 중 새 변수를 만드는데 사용된 변수(x와 y)와 새 변수(z)를 보여준다. .keep = unused : df의 컬럼 변수 중 새 변수를 만드는데 사용되지 않은 변수(a와 b)와 새 변수(z)를 보여준다. .keep = none : 새 변수(z) 만을 보여준다. 4.9.6 .after와 .before 인수의 사용 예 mutate() 함수의 .after와 .before 인수를 이용하여 새로 생성된 변수의 위치를 지정할 수 있다. # Experimental: you can override with `.before` or `.after` df &lt;- tibble(x = 1, y = 2) df %&gt;% mutate(z = x + y) ## # A tibble: 1 x 3 ## x y z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 df %&gt;% mutate(z = x + y, .before = 1) # z를 1번째 컬럼의 왼 쪽에 표시 ## # A tibble: 1 x 3 ## z x y ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 1 2 df %&gt;% mutate(z = x + y, .after = x) # z를 x 컬럼 오른 쪽에 표지 ## # A tibble: 1 x 3 ## x z y ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3 2 4.9.7 transmute() 함수를 이용한 새로운 컬럼 생성 mutate() 함수가 기존 변수와 신규 변수를 모두 관리하는 것과 달리, transmute() 함수는 신규 변수만 저장을 하고 기존 변수들은 모두 없앤다. 4.9.7.1 transmute() 함수의 기본 형식 transmute(dataframe, 새로운 변수 = 기존 변수 조합한 수식, ...) dataframe : 데이터 세트 transmute()의 인수와 같음… Cars93_1의 데이터 세트에서 최소가격(Min.Price)과 최대가격(`Max.Price)의 차이를 나타내는 범위(Price_range) 변수와 최소가격 대비 최대가격의 비율(Price_ration = Max.Price/Min.Price) 의 새로운 변수를 생성한 후에, 이들 2개의 신규변수만 Cars93_5에 저장해 보자. # transmute() : Create(add) new columns Cars93_1 &lt;- Cars93[c(1:10), c(&quot;Model&quot;, &quot;Min.Price&quot;, &quot;Max.Price&quot;)] # subset for better printing Cars93_1 ## Model Min.Price Max.Price ## 1 Integra 12.9 18.8 ## 2 Legend 29.2 38.7 ## 3 90 25.9 32.3 ## 4 100 30.8 44.6 ## 5 535i 23.7 36.2 ## 6 Century 14.2 17.3 ## 7 LeSabre 19.9 21.7 ## 8 Roadmaster 22.6 24.9 ## 9 Riviera 26.3 26.3 ## 10 DeVille 33.0 36.3 Cars93_5 &lt;- transmute(Cars93_1, Price_range = Max.Price - Min.Price, Price_Min_Max_ratio = Max.Price / Min.Price) Cars93_5 ## Price_range Price_Min_Max_ratio ## 1 5.9 1.457364 ## 2 9.5 1.325342 ## 3 6.4 1.247104 ## 4 13.8 1.448052 ## 5 12.5 1.527426 ## 6 3.1 1.218310 ## 7 1.8 1.090452 ## 8 2.3 1.101770 ## 9 0.0 1.000000 ## 10 3.3 1.100000 이는 mutate() 함수에서 .keep 인수의 값을 “none”으로 한 결과와 같음을 알 수 있다. # mutate( , .keep = &quot;none&quot;) == transmute() : Create(add) new columns Cars93_1 &lt;- Cars93[c(1:10), c(&quot;Model&quot;, &quot;Min.Price&quot;, &quot;Max.Price&quot;)] # subset for better printing Cars93_1 ## Model Min.Price Max.Price ## 1 Integra 12.9 18.8 ## 2 Legend 29.2 38.7 ## 3 90 25.9 32.3 ## 4 100 30.8 44.6 ## 5 535i 23.7 36.2 ## 6 Century 14.2 17.3 ## 7 LeSabre 19.9 21.7 ## 8 Roadmaster 22.6 24.9 ## 9 Riviera 26.3 26.3 ## 10 DeVille 33.0 36.3 Cars93_6 &lt;- mutate(Cars93_1, Price_range = Max.Price - Min.Price, Price_Min_Max_ratio = Max.Price / Min.Price, .keep = &quot;none&quot;) Cars93_6 ## Price_range Price_Min_Max_ratio ## 1 5.9 1.457364 ## 2 9.5 1.325342 ## 3 6.4 1.247104 ## 4 13.8 1.448052 ## 5 12.5 1.527426 ## 6 3.1 1.218310 ## 7 1.8 1.090452 ## 8 2.3 1.101770 ## 9 0.0 1.000000 ## 10 3.3 1.100000 4.10 summarise()함수를 이용한 요약 통계량 계산 4.10.1 summarise() 함수의 기본 형식 summarise(dataframe, …, .groups = NULL) summarize(dataframe, …, .groups = NULL) datafreame : 데이터 세트 … : 한 개의 값만을 출력하는 함수(sum, mean, sd, var, …), n개의 값을 출력하는 함수(IQR, …), 하나의 식을 이용해 복수 개의 컬럼을 더하는 데이터 프레임 등 .groups : “drop_last,” “drop,” “keep,” “rowwise” 등의 옵션 summarise() 함수이 제공하는 수치형 데이터에 대한 요약 통계량 옵션의 예를 들면 다음과 같다. mean(x, na.rm = TRUE) : 평균. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 median(x, na.rm = TRUE) : 중앙값. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 sd(x, na.rm = TRUE) : 표준편차. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 min(x, na.rm = TRUE) : 최소값. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 max(x, na.rm = TRUE) : 최대값. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 IQR(x, na.rm = TRUE) : 3사분위수 - 1사분위수 (Inter Quartile Range = Q3 - Q1). 결측값(NA)을 제외하려면 na.rm = TRUE 추가 sum(x, na.rm = TRUE) : 합. 결측값(NA)을 제외하려면 na.rm = TRUE 추가 4.10.2 summarise() 함수를 이용한 요약 통계 계산 Cars93 데이터 프레임에서 가격(Price)의 a) 평균, b) 중앙값, c) 표준편차, d) 최소값, e) 최대값, f) 사분위 범위(IQR), g) 합계를 구해보자. (단, 결측값은 포함하지 않고 계산함 = na.rm = TRUE) # summarise() : Summarise numeric values # mean(), median(), sd(), min(), max(), IQR(), sum() # IQR : IQR(Inter quartile Range) = Upper Quartile(Q3) - Lower Quartile(Q1) summarise(Cars93, Price_mean = mean(Price, na.rm = T), # mean of Price Price_median = median(Price, na.rm = T), # median of Price Price_sd = sd(Price, na.rm = T), # standard deviation of Price Price_min = min(Price, na.rm = T), # min of Price Price_max = max(Price, na.rm = T), # max of Price Price_IQR = IQR(Price), na.rm = T, # IQR of Price Price_sum = sum(Price, na.rm = T)) # sum of Price ## Price_mean Price_median Price_sd Price_min Price_max Price_IQR na.rm ## 1 19.50968 17.7 9.65943 7.4 61.9 11.1 TRUE ## Price_sum ## 1 1814.4 4.10.3 summarise()를 이용한 관측치의 갯수 및 색인 찾기 summarise()를 이용한 관측치의 갯수 및 색인을 찾기 위한 함수의 예는 다음과 같다. n() : 관측치 겟수 계산, x 변수 입력하지 않음 n_distinct(x) : 중복없는 유일한 관측치 갯수 계산, 기준이 되는 x변수 입력함 first(x) : 기준이 되는 x변수의 첫번째 관측치 last(x) : 기준이 되는 x변수의 마지막 관측치 nth(x, n) : 기준이 되는 x변수의 n번째 관측치 Cars93_1 데이터 프레임에서 a) 총 관측치의 갯수, b) 제조사(Manufacturer)의 갯수(유일한 값), c) 첫번째 관측치의 제조사 이름, d) 마지막 관측치의 제조사 이름, e) 5번째 관측치의 제조사 이름을 확인해 보자. # summarise() : n(), n_distinct(), first(), last(), nth() Cars93_1 &lt;- Cars93[c(1:10), c(&quot;Manufacturer&quot;, &quot;Model&quot;, &quot;Type&quot;)] # subset for better print Cars93_1 ## Manufacturer Model Type ## 1 Acura Integra Small ## 2 Acura Legend Midsize ## 3 Audi 90 Compact ## 4 Audi 100 Midsize ## 5 BMW 535i Midsize ## 6 Buick Century Midsize ## 7 Buick LeSabre Large ## 8 Buick Roadmaster Large ## 9 Buick Riviera Midsize ## 10 Cadillac DeVille Large summarise(Cars93_1, tot_cnt = n(), # counting the number of all observations Manufacturer_dist_cnt = n_distinct(Manufacturer), # distinct number of var First_obs = first(Manufacturer), # first observation Last_obs = last(Manufacturer), # last observation Nth_5th_obs = nth(Manufacturer, 5)) # n&#39;th observation ## tot_cnt Manufacturer_dist_cnt First_obs Last_obs Nth_5th_obs ## 1 10 5 Acura Cadillac BMW 4.10.4 summarise() 함수를 이용한 그룹별 요약 통계량 계산 summarise() 함수를 이용하여 그룹별로 통계량을 계산(Grouped operations)하려면 group_by() 함수를 이용한다. Cars93 데이터 프레임에서 ‘차종(Type)’ 별로 a) 전체 관측치 갯수, b) (중복 없는) 제조사 업체 수, c) 가격(Price)의 평균과 d) 가격의 표준편차를 구해 보자 (단, 결측값은 포함하지 않고 계산함). # summarise by group grouped &lt;- group_by(Cars93, Type) summarise(grouped, n_conut = n(), # counting the number of cars Manufacturer_cnt = n_distinct(Manufacturer), # distinct number of Manufacturer Price_mean = mean(Price, na.rm = TRUE), # mean of Price Price_sd = sd(Price, na.rm = TRUE) # standard deviation of Price ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 6 x 5 ## Type n_conut Manufacturer_cnt Price_mean Price_sd ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Compact 16 15 18.2 6.69 ## 2 Large 11 10 24.3 6.34 ## 3 Midsize 22 20 27.2 12.3 ## # ... with 3 more rows # 또는 Cars93 %&gt;% group_by(Type) %&gt;% summarise(n_conut = n(), # counting the number of cars Manufacturer_cnt = n_distinct(Manufacturer), # distinct number of Manufacturer Price_mean = mean(Price, na.rm = TRUE), # mean of Price Price_sd = sd(Price, na.rm = TRUE) # standard deviation of Price ) ## `summarise()` ungrouping output (override with `.groups` argument) ## # A tibble: 6 x 5 ## Type n_conut Manufacturer_cnt Price_mean Price_sd ## &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Compact 16 15 18.2 6.69 ## 2 Large 11 10 24.3 6.34 ## 3 Midsize 22 20 27.2 12.3 ## # ... with 3 more rows 4.10.5 복수 개의 변수에 동일한 summarise() 함수 적용하기 summarise_each() 함수를 이용하면 복수 개의 변수에 동일한 summarise() 함수를 적용할 수 있다. Cars93 데이터 프레임의 가격(Price) 변수와 고속도로연비(MPG.highway) 등의 두개의 변수에 대해 a) 평균(mean), b) 중앙값(median), c) 표준편차(standard deviation) 등의 3개의 함수를 동시에 적용하여 계산해 보자. # summarize_each() : applies the same summary function(s) to multiple variables summarise_each(Cars93, funs(mean, median, sd), Price, MPG.highway) ## Warning: `summarise_each_()` is deprecated as of dplyr 0.7.0. ## Please use `across()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## Warning: `funs()` is deprecated as of dplyr 0.8.0. ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. ## Price_mean MPG.highway_mean Price_median MPG.highway_median Price_sd ## 1 19.50968 29.08602 17.7 28 9.65943 ## MPG.highway_sd ## 1 5.331726 summarise_each() 함수는 dplyr 0.7.0이후로 사용하지 않고 있으며, 그 대신 across() 함수를 이용하고 있다. summarise_each() 함수 대신에 summarise() 함수 안에 across() 함수를 이용하면 다음과 같다. # across() 함수의 이용 summarise(Cars93, across(c(Price, MPG.highway), list(mean=mean, median=median, sd=sd), na.rm= TRUE)) ## Price_mean Price_median Price_sd MPG.highway_mean MPG.highway_median ## 1 19.50968 17.7 9.65943 29.08602 28 ## MPG.highway_sd ## 1 5.331726 Cars93 %&gt;% summarise(across(c(Price, MPG.highway), list(mean=mean, median=median, sd=sd), na.rm= TRUE)) ## Price_mean Price_median Price_sd MPG.highway_mean MPG.highway_median ## 1 19.50968 17.7 9.65943 29.08602 28 ## MPG.highway_sd ## 1 5.331726 Reference Introduction to dplyr (http://127.0.0.1:21980/library/dplyr/doc/introduction.html) dplyr functions for single dataset (http://stat545.com/block010_dplyr-end-single-table.html) dplyr tutorial (http://genomicsclass.github.io/book/pages/dplyr_tutorial.html) R, Python 분석과 프로그래밍의 친구 [https://rfriend.tistory.com/234?category=601862] "],["piping-operator.html", "Chapter 5 Pipe Operator 5.1 파이프 연산자 : %&gt;% 5.2 파이프된 명령어에 ‘.’ 사용하기", " Chapter 5 Pipe Operator 5.1 파이프 연산자 : %&gt;% library(tidyverse) 데이터 관리 업무는 최종적으로 바람직한 데이터 세트를 만들기 위한 여러 단계를 포함한다. 중간 단계에서 종종 신경을 쓰거나 계속 유지하기 위한 계획없이 데이터 세트들이 생성된다. 이러한 다단계 업무를 위해서 파이프 연산자가 유용하고, 시간을 절약해주고, 효율적인 단축 기록을 제공한다. 데이터 세트의 이름을 붙이는 것은 생각하기에도 시간이 소요되고, 코딩도 난잡하게 만든다. 이때 파이프 연산자는 데이터 세트의 이름보다 사용되는 함수에 집중하게 함으로써 코드를 더 쉽게 이해할 수 있게 해준다. 파이프 연산자 %&gt;%는 CTRL-SHIFT-M (CMD-SHIFT-M on a Mac)으로 작성될 수 있다. 파이프 연산자는 코드를 읽을 때 “그런 다음(then)”으로 표현될 수 있다. 이 연산자는 (`library(tidyverse)를 로드할 때 자동으로 로드되는) magrittr 패키지로 로드된다. 파이프 연산자는 이 연산자의 왼쪽에 있는 데이터 세트를 이 연산자의 오른쪽에 있는 함수로 전달(pipe)해 준다. x %&gt;% f(y)코드는 f(x,y)로 변환될 수 있는데, 이는 x가 디폴트로 f() 함수의 첫 번째 인수가 된다는 것이다. 이 함수가 데이터 프레임을 반환하면, 이 데이터 프레임을 다른 함수로 전달할 수 있다. 따라서, x %&gt;% f(y) %&gt;% g(z)는 g(f(x,y), z)로 변환될 수 있다. 5.1.1 파이프 연산자의 사용 예 첫 번째 예로, 40세 이하의 여성으로 구성된 데이터 세트를 생성하는데 age변수와 pain 변수 만을 선택하고 싶다고 하자. 이 작업을 다음과 같이 두 단계로 수행할 수 있다: d &lt;- read_csv(&quot;data5/patient_pt1_dm.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## .default = col_double(), ## hospital = col_character(), ## docid = col_character(), ## dis_date = col_character(), ## sex = col_character(), ## familyhx = col_character(), ## smokinghx = col_character(), ## cancerstage = col_character(), ## wbc = col_character() ## ) ## i Use `spec()` for the full column specifications. # a dataset of age and pain for females younger than 40 f40 &lt;- filter(d, sex==&quot;female&quot; &amp; age &lt; 40) f40_small &lt;- select(f40, age, pain) f40_small ## # A tibble: 2 x 2 ## age pain ## &lt;dbl&gt; &lt;dbl&gt; ## 1 37.3 8 ## 2 39.6 5 작업이 아주 잘 진행되었지만, 중간단계의 데이터 세트인 f40은 우리의 관심이 대상이 아니며 불필요하게 메모리와 작업공간을 차지하고 있다. 따라서 파이프 연산자(%&gt;%)를 이용하면 이러한 불필요한 부분을 제거할 수 있다: # start with d, then filter rows, then select variables f40_small &lt;- d %&gt;% filter(sex == &quot;female&quot; &amp; age &lt; 40) %&gt;% select(age, pain) f40_small ## # A tibble: 2 x 2 ## age pain ## &lt;dbl&gt; &lt;dbl&gt; ## 1 37.3 8 ## 2 39.6 5 중간단계의 데이터 세트를 생성하지 않으며, 중간 단계에서 데이터 세트의 이름도 필요하지 않다. 또한 데이터 세트를 변환하는 filter() 함수와 select() 함수를 더 쉽게 이해할 수 있게 해준다. 5.1.2 또 다른 예 파이핑은 또한 일련의 명령어의 연결을 좀더 즉각적으로 이해할 수 있게 만들어 준다. # create a plot of average age vs tumor size # by doctors, for doctors with more than 5 patients (with less than or equal to 55 average age) g1 &lt;- d %&gt;% group_by(docid) %&gt;% summarise(n_pat=n(), avg_age=mean(age), avg_tumor=mean(tumorsize)) %&gt;% filter(n_pat &gt; 5 &amp; avg_age &lt;=55) %&gt;% ggplot(aes(x=avg_age, y=avg_tumor)) + geom_point() + geom_smooth() ## `summarise()` ungrouping output (override with `.groups` argument) g1 ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; 5.2 파이프된 명령어에 ‘.’ 사용하기 x %&gt;% f(y,.) 는 f(y,x)로 변환된다. 데이터 세트 x 대신에 ‘.’을 사용할 수 있다. 예를 들어, lm()과 같은 모델링 함수는 첫 번째 인수가 데이터 세트가 아닌 모델 공식이 되는게 일반적이다. 그리고, 파이핑 체인에서의 데이터 세트를 나타내는 의미로 ‘.’을 사용할 수 있다: d %&gt;% filter(age &lt; 40) %&gt;% lm(tumorsize ~ age, data=.) # the . is the filtered dataset ## ## Call: ## lm(formula = tumorsize ~ age, data = .) ## ## Coefficients: ## (Intercept) age ## -78.219 4.116 "],["relational-data-top.html", "Chapter 6 Relational Data 6.1 결합(Append) 6.2 데이터 세트의 병합(Merge) 6.3 Relational Data 6.4 변환 조인(Mutating Join) 6.5 필터링 조인 6.6 조인 문제 6.7 집합 연산 6.8 Join Exercises", " Chapter 6 Relational Data 6.1 결합(Append) library(tidyverse) 6.1.1 데이터 프레임의 결합(append) 종종 데이터 세트들은 여러 개의 파일로 분리되어 있는데, 이는 아마도 데이터들이 여러 원천에서 또는 여러 연구자들이 수집하기 때문일 것이다. 파일들이 같은 변수들을 공유하고 있다면(희망사항이긴 하지만), 데이터 세트들을 결합하거나 행들을 함께 묶을 수 있다. 위의 그림에서 보듯이 결합(append)은 여러 개의 파일들이 컬럼 변수들을 같이 공유할 때 이 파일들의 행(rows)을 묶어 준다. 위의 그림에서 위의 표는 tb1, 아래의 표는 tb2 등으로 하여, rbind()로 결합을 한 tb3는 다음과 같다. # two tibbles tb1 &lt;- tibble(ID = c(&quot;101&quot;, &quot;102&quot;), Age = c(27, 45), Pre = c(56.3, 52.4), Post = c(74.5, 55.5)) tb2 &lt;- tibble(ID = c(&quot;201&quot;, &quot;202&quot;), Age = c(35, 47), Pre = c(35.7, 25.4), Post = c(25.6, 23.6)) # append using rbind() tb3 &lt;- rbind(tb1, tb2) tb3 ## # A tibble: 4 x 4 ## ID Age Pre Post ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 101 27 56.3 74.5 ## 2 102 45 52.4 55.5 ## 3 201 35 35.7 25.6 ## 4 202 47 25.4 23.6 # append using bind_rows() tb4 &lt;- bind_rows(tb1, tb2) tb4 ## # A tibble: 4 x 4 ## ID Age Pre Post ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 101 27 56.3 74.5 ## 2 102 45 52.4 55.5 ## 3 201 35 35.7 25.6 ## 4 202 47 25.4 23.6 여기서 tb1과 tb2의 컬럼 구조는 동일하다. 6.1.2 결합의 두 가지 방법 : rbind() 함수와 bind_rows()함수 이러한 결합은 base 패키지의 rbind() 함수나 dplyr 패키지의 bind_rows() 함수로 수행할 수 있다. 이 두 함수의 차이점은 대응되지 않는 컬럼이 있는 데이터 세트들을 결합할 때 처리방법이 다르다는 것이다. rbind() 함수는 에러가 발생한다. bind_rows() 함수는 데이터 세트를 결합하되 대응되지 않는 컬럼에 대해서는 결측값인 NA로 채우게 된다. # two tibbles tb1 &lt;- tibble(ID = c(&quot;101&quot;, &quot;102&quot;), Age = c(27, 45), Pre = c(56.3, 52.4), Post = c(74.5, 55.5)) tb2 &lt;- tibble(ID = c(&quot;201&quot;, &quot;202&quot;), Age = c(35, 47), Pre = c(35.7, 25.4)) # append using rbind() tb5 &lt;- rbind(tb1, tb2) ## Error in rbind(deparse.level, ...): numbers of columns of arguments do not match tb5 ## Error in eval(expr, envir, enclos): 객체 &#39;tb5&#39;를 찾을 수 없습니다 # append using bind_rows() tb6 &lt;- bind_rows(tb1, tb2) tb6 ## # A tibble: 4 x 4 ## ID Age Pre Post ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 101 27 56.3 74.5 ## 2 102 45 52.4 55.5 ## 3 201 35 35.7 NA ## 4 202 47 25.4 NA tb1과 tb2의 컬럼 구조가 서로 다른 경우 rbind()를 이욯한 결합은 error가 발생 bind_rows()를 이용한 결합의 경우에는 대응되지 않는 컬럼의 값은 NA로 채워진다ㅏ. 이 두 함수들은 두 개의 데이터 세트에 있는 동일한 컬럼이 서로 다른 데이터 타입일 때 이를 처리하는 방법에도 차이가 있다. (예를 들어, 하나는 문자형이고 다른 하나는 숫자형인 경우) rbind() 함수는 강제적으로 형을 변환하여 결합한다.(강제 형 변환의 순서 : 논리형 &gt; 정수형 &gt; 더블형(실수형) &gt; 문자형) bind_rows() 함수는 에러를 발생시킨다. # two tibbles tb1 &lt;- tibble(ID = c(&quot;101&quot;, &quot;102&quot;), Age = c(&quot;27&quot;, &quot;45&quot;), Pre = c(56.3, 52.4), Post = c(74.5, 55.5)) tb2 &lt;- tibble(ID = c(&quot;201&quot;, &quot;202&quot;), Age = c(35, 47), Pre = c(35.7, 25.4), Post = c(25.6, 23.6)) # append using rbind() tb7 &lt;- rbind(tb1, tb2) tb7 ## # A tibble: 4 x 4 ## ID Age Pre Post ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 101 27 56.3 74.5 ## 2 102 45 52.4 55.5 ## 3 201 35 35.7 25.6 ## 4 202 47 25.4 23.6 # append using bind_rows() tb8 &lt;- bind_rows(tb1, tb2) ## Error: Can&#39;t combine `..1$Age` &lt;character&gt; and `..2$Age` &lt;double&gt;. tb8 ## Error in eval(expr, envir, enclos): 객체 &#39;tb8&#39;를 찾을 수 없습니다 tb1과 tb2의 컬럼이 대응은 되지만 데이터 형이 다른 경우 rbind()의 경우, tb7의 Age 컬럼이 문자형으로 변환됨 bind_rows()의 경우, error 발생. tb1과 tb2의 컬럼이 대응이 되지 않는 경우는 모두 error 발생. 6.1.3 데이터 세트 결합의 예(대응되지 않는 컬럼이 있는 경우) 데이터 세트의 결합을 위해 2개의 데이터 세트 d1과 d2를 만들어 보자. 먼저 patient_pt1_dm.csv 파일을 불러와 d에 저장하고, mutate() 함수를 이용하여 agecat 변수와 highpain 변수(컬럼) 2개를 추가하여 d1을 만든다. d2는 patient_pt1_dm.csv 파일을 불러와 저장한다. 이들 두 개의 데이터 세트들은 d1이 mutate() 함수에 의해 생성된 2 개의 컬럼 이외에는 다 같은 컬럼들을 가지고 있다. # new data set that contains the same variables as d, except is missing 2 of them d &lt;- read_csv(&quot;data6/patient_pt1_dm.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## .default = col_double(), ## hospital = col_character(), ## docid = col_character(), ## dis_date = col_character(), ## sex = col_character(), ## familyhx = col_character(), ## smokinghx = col_character(), ## cancerstage = col_character(), ## wbc = col_character() ## ) ## i Use `spec()` for the full column specifications. d1 &lt;- mutate(d, agecat = cut(age, breaks=c(30,40,50,60,70,120)), highpain = pain &gt; mean(pain)) d2 &lt;- read_csv(&quot;data6/patient_pt2_dm.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## .default = col_double(), ## hospital = col_character(), ## docid = col_character(), ## dis_date = col_character(), ## sex = col_character(), ## familyhx = col_character(), ## smokinghx = col_character(), ## cancerstage = col_character(), ## wbc = col_character() ## ) ## i Use `spec()` for the full column specifications. d1과 d2의 행과 열의 갯수 확인 # rows and columns of d2 and d1 dim(d1) ## [1] 120 26 dim(d2) ## [1] 111 24 이제 두 rbind() 함수와 bind_rows() 함수를 이용하여 두 데이터 세트를 결합해 보자. rbind() 함수를 이용하여 결합하면 에러가 날 것이다. bind_rows() 함수는 첫 번째 데이터 세트에만 두 번째 데이터 세트의 관측치에 해당하는 부분을 NA로 입력할 것이다. 가장 좋은 방법은 두 번쨰 데이터 세트인 d2에 대해서도 같은 변수들을 추가한 다음 결합함수를 이용하는 것이다. 그러나, bind_rows() 함수가 어떻게 작동하는가는 보여주기 위해, 우리는 현재의 상태로 데이터 세트들을 결합한다. 원천 데이터 세트를 식별해 주는 변수를 생성하기 위해 bind_rows() 함수의 인수로 .id = 를 사용한다. 6.1.3.1 bind_rows() 함수의 이용 예 데이터 세트 d1과 d2를 bind_rows() 함수로 결합하여 d3를 만들어 보자. # a new variable called source is added to the beginning of the dataset d3 &lt;- bind_rows(d1, d2, .id=&quot;source&quot;) dim(d3) ## [1] 231 27 # these are the rows where the datasets meet # hospital is found in both datasets, agecat and highpain are not select(d3, source, hospital, agecat, highpain)[118:123,] ## # A tibble: 6 x 4 ## source hospital agecat highpain ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;lgl&gt; ## 1 1 UCSF (50,60] TRUE ## 2 1 UCSF (50,60] TRUE ## 3 1 UCSF (50,60] TRUE ## # ... with 3 more rows bind_rows() 함수 내의 .id = “source”에 의해 d3에 source 컬럼이 추가되고, 그 값은 d1에서 결합된 행인 경우(118 ~ 120 행)는 1, d2에서 결합된 행이면(121~123 행) 2의 값을 갖는다. d2에서 결합된 행의 경우 agecat 컬럼과 highpain 컬럼의 값이 NA로 채워져 있음을 알 수 있다. 6.1.3.2 rbind() 함수의 이용 예 # this will work because we restrict d1 to only variables common to both drbind &lt;- rbind(d1[,1:24], d2) drbind ## # A tibble: 231 x 24 ## hospital hospid docid dis_date sex age test1 test2 pain tumorsize co2 ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 UCLA 1 1-1 6-Sep-09 male 65.0 3.70 8.09 4 68.0 1.53 ## 2 UCLA 1 1-1 7-Jan-11 fema~ 53.9 2.63 0.803 2 64.7 1.68 ## 3 UCLA 1 1-1 4-Sep-10 male 41.4 -99 2.13 3 86.4 1.45 ## # ... with 228 more rows, and 13 more variables: wound &lt;dbl&gt;, mobility &lt;dbl&gt;, ## # ntumors &lt;dbl&gt;, remission &lt;dbl&gt;, lungcapacity &lt;dbl&gt;, married &lt;dbl&gt;, ## # familyhx &lt;chr&gt;, smokinghx &lt;chr&gt;, cancerstage &lt;chr&gt;, lengthofstay &lt;dbl&gt;, ## # wbc &lt;chr&gt;, rbc &lt;dbl&gt;, bmi &lt;dbl&gt; rbind() 함수를 이용하였으나 에러가 발생하지 않았다. 그 이유는 d1의 컬럼을 d2의 컬럼과 같게 만들기 위해 d1[, 1:24]로 제한했기 때문이다. # But this will not work drbind1 &lt;- rbind(d1, d2) ## Error in rbind(deparse.level, ...): numbers of columns of arguments do not match drbind1 ## Error in eval(expr, envir, enclos): 객체 &#39;drbind1&#39;를 찾을 수 없습니다 d1의 컬럼과 d2의 컬럼이 일치하지 않기 때문에 rbind() 함수는 에러를 발생시키고 작업을 중단함을 알 수 있다. 6.2 데이터 세트의 병합(Merge) 결합(append)은 관측치의 행들을 묶어주는데 반해, 병합(merge) 또는 조인(join)은 컬럼들을 묶어 준다. 병합될 데이터 세트들은 특정 키 변수(컬럼)럼)가 대응되어 있어야 한다. 예를 들어, 아래의 그림에서 두 개의 데이터 세트들은 docid 컬럼으로 대응되고 있다. 그러면 이 컬럼을 중심으로 두 개의 데이터 세트를 병합할 수 있다. 그 결과로 생성된 데이터 세트는 두 데이터 세트들의 컬럼을 모두 병합하고 대응하는 변수들을 공유하는 관측치들을 병합한다. dplyr패키지의 “join()” 함수가 이러한 병합을 수행하며, 데이터 세트들 사이에 같은 이름을 갖는 변수(디폴트로는 id 변수)를 이용한다. 공통의 변수를 지정하기 위해서는 by= 인수를 사용한다. 이러한 조인은 데이터 세트 x와 y로 부터의 모든 컬럼을 갖는 테이블을 리턴하지만, 대응되지 않는 행들을 처리하는데에는 여러 가지 방법이 있다: inner_join(x, y): y에 대응하는 값이 있다면 x의 행(즉 대응하는 행만)을 리턴한다. left_join(x, y): x의 모든 행은 리턴하지만 y와 대응하지 않는 행에 대해서는 NA를 리턴한다. y에 있는 대응하지 않는 행들은 리턴하지 않는다. full_join(x, y): x와 y에 있는 모든 행들을 리턴한다. 그러나 양측에 대응하지 않는 행들은 새 컬럼의 값이 모두 NA가 된다. 이러한 조인들은 base 패키지의 merge() 함수로도 가능하지만, join() 함수보다 그 처리 속도가 매우 느리다. 6.2.1 join 함수를 이용한 병합 예 병합의 예를 들기 위해 의사들에 관한 정보를 담고 있는 데이터 세트를 불러오기로 한다. 이 데이터 세트는 의사들의 근무기간, 학력 그리고 소송 횟수 등에 관한 정보를 담고 있다. d_doc &lt;- read_csv(&quot;data6/doctor_dm.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## docid = col_character(), ## experience = col_double(), ## school = col_character(), ## lawsuits = col_double(), ## medicaid = col_double() ## ) 6.2.1.1 예제 데이터 세트 병합이 어떻게 작동하는가를 이해하기 위해 데이터 세트로 작게 만들어서 작업을 하기로 한다. 지금 불러온 d_doc 데이터 세트의 일부와 앞에서 생성한 d3 데이터 세트의 일부를 병합해 보기로 한다. 먼저 d_doc의 경우는 docid 가 1-21과 2-178인 데이터를 서브세트로 선택한다. 그리고 d3의 경우는 d_doc과 대응이 되는 docid가 2-178인 행과 대응이 되지 않는 docid가 3-407인 행을 서브세트로 다음과 같이 선택한다. # select one non-matching and one matching doctor from each to demo joins # just a few variables from d3 d3.1 &lt;- select(filter(d3, docid == &quot;1-21&quot; | docid == &quot;2-178&quot;), docid, sex, age, test1, test2) d3.1 ## # A tibble: 3 x 5 ## docid sex age test1 test2 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1-21 male 48.0 3.39 -99 ## 2 2-178 male 34.2 4.63 3.26 ## 3 2-178 male 48.9 4.15 3.04 d_doc.1 &lt;- filter(d_doc, docid == &quot;3-407&quot; | docid == &quot;2-178&quot;) d_doc.1 ## # A tibble: 2 x 5 ## docid experience school lawsuits medicaid ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2-178 15 average 4 0.817 ## 2 3-407 23 average 3 0.343 이 결과를 그림으로 편집해 보면 다음과 같다. 병합된 공통의 변수의 id인 docid가 두 데이터 세트의 컬럼에 있다. 따라서 병합 변수를 새로이 지정할 필요는 없다. 6.2.1.2 병합의 예 inner_join(), left_join() 그리고 full_join() 함수를 이용하는 경우 각각의 결과가 다르게 나타나는 것을 잘 주목해 보자. 6.2.1.2.1 inner_join() # only matching rows returned # 2-178 from d_doc.1 matched twice to 2-178 in d3.1 inner_join(d3.1, d_doc.1) ## Joining, by = &quot;docid&quot; ## # A tibble: 2 x 9 ## docid sex age test1 test2 experience school lawsuits medicaid ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2-178 male 34.2 4.63 3.26 15 average 4 0.817 ## 2 2-178 male 48.9 4.15 3.04 15 average 4 0.817 6.2.1.2.2 left_join() # all rows from d3.1 returned left_join(d3.1, d_doc.1) ## Joining, by = &quot;docid&quot; ## # A tibble: 3 x 9 ## docid sex age test1 test2 experience school lawsuits medicaid ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1-21 male 48.0 3.39 -99 NA &lt;NA&gt; NA NA ## 2 2-178 male 34.2 4.63 3.26 15 average 4 0.817 ## 3 2-178 male 48.9 4.15 3.04 15 average 4 0.817 6.2.1.2.3 full_join() # all rows from both returned full_join(d3.1, d_doc.1) ## Joining, by = &quot;docid&quot; ## # A tibble: 4 x 9 ## docid sex age test1 test2 experience school lawsuits medicaid ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1-21 male 48.0 3.39 -99 NA &lt;NA&gt; NA NA ## 2 2-178 male 34.2 4.63 3.26 15 average 4 0.817 ## 3 2-178 male 48.9 4.15 3.04 15 average 4 0.817 ## 4 3-407 &lt;NA&gt; NA NA NA 23 average 3 0.343 일반적으로 병합된 데이터 세트의 행의 갯수는 inner_join() &lt;= left_join() &lt;= full_join() 순이 된다. 이 밖에도 right_join(), semi_join()그리고 anti_join() 등의 함수가 있다. 6.3 Relational Data 6.3.1 들어가기 데이터 분석에서 데이터 테이블이 단 하나만 관련된 경우는 거의 없다. 일반적으로 데이터 테이블이 많이 있고, 관심 있는 질문에 대답하기 위해 이들을 결합해야 한다. 여러 데이터 테이블을 총칭하여 관계형 데이터 라고 한다. 이렇게 부르는 이유는 중요한 것이 개별 데이터셋이 아니라 이들의 관계(relationship)이기 때문이다. 관계라는 것은 항상 두 개의 테이블 사이에서 정의된다. 이 간단한 개념으로부터 다른 모든 관계가 구성된다. 테이블 3개 이상 사이의 관계는 항상 각 쌍 사이의 관계들을 이용하여 나타낼 수 있다. 때로는 쌍을 이루는 두 요소가 같은 테이블이 될 수도 있다! 예를 들어 사람에 대한 데이터 테이블을 가지고 있고, 각 사람이 부모에 대한 참조 정보를 가지고 있다면 이런 경우가 생긴다. 관계형 데이터로 작업하려면 두 개의 테이블에 작동하는 동사가 필요하다. 관계형 데이터에 동작하도록 설계된 세 가지 동사 계열이 있다. 변환 조인(Mutating Join) : 다른 데이터프레임에 있는 해당 관측값에서 가져와 새로운 변수로 생성하여 추가 필터링 조인 : 다른 테이블의 관측값와 일치하는지에 따라 관측값을 걸러냄 집합 연산 : 관측값을 집합 원소로 취급 관계형 데이터가 있는 가장 일반적인 장소는 관계형 데이터베이스 관리 시스템(RDBMS)이다. 이 용어는 거의 모든 현대의 데이터베이스를 포괄한다. 여러분이 이전에 데이터베이스를 사용했다면 SQL을 사용했을 것이 거의 확실하다. 그렇다면 dplyr 에서의 표현이 조금 다르긴 하지만, 이 장에 나오는 개념이 익숙할 것이다. 일반적으로 dplyr 은 SQL보다 약간 사용하기 쉽다. dplyr 은 데이터 분석에 특화되었기 때문이다. 즉, 일반적인 데이터 분석 작업을 하기는 더 쉽게 만들었지만, 대신 데이터 분석에서 일반적으로 필요하지 않은 작업을 수행하기는 더 어렵게 되었다. 6.3.2 준비하기 우리는 dplyr 의 2-테이블 동사를 사용하여 nycflights13 패키지에 있는 관계형 데이터를 탐색할 것이다. library(nycflights13) 6.3.3 nycflights13 패키지 내의 데이터 세트 관계형 데이터에 대해 배우기 위해 nycflights13 패키지를 사용할 것이다. nycflights13 패키지에는 flights 테이블과 관련된 4개의 티블(tibble)이 있다. airlines 를 사용하면 해당 약어 코드로 전체 항공사명을 찾아볼 수 있다. airlines ## # A tibble: 16 x 2 ## carrier name ## &lt;chr&gt; &lt;chr&gt; ## 1 9E Endeavor Air Inc. ## 2 AA American Airlines Inc. ## 3 AS Alaska Airlines Inc. ## # ... with 13 more rows airports 에는 각 공항에 대한 정보가 faa 공항 코드로 식별되어 있다. airports ## # A tibble: 1,458 x 8 ## faa name lat lon alt tz dst tzone ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 04G Lansdowne Airport 41.1 -80.6 1044 -5 A America/New_Y~ ## 2 06A Moton Field Municipal Airp~ 32.5 -85.7 264 -6 A America/Chica~ ## 3 06C Schaumburg Regional 42.0 -88.1 801 -6 A America/Chica~ ## # ... with 1,455 more rows planes 에는 각 여객기에 대한 정보가 tailnum 으로 식별되어 있다. planes ## # A tibble: 3,322 x 9 ## tailnum year type manufacturer model engines seats speed engine ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 N10156 2004 Fixed wing mu~ EMBRAER EMB-1~ 2 55 NA Turbo-~ ## 2 N102UW 1998 Fixed wing mu~ AIRBUS INDUST~ A320-~ 2 182 NA Turbo-~ ## 3 N103US 1999 Fixed wing mu~ AIRBUS INDUST~ A320-~ 2 182 NA Turbo-~ ## # ... with 3,319 more rows weather 에는 각 NYC 공항의 매 시각 날씨 정보가 있다. weather ## # A tibble: 26,115 x 15 ## origin year month day hour temp dewp humid wind_dir wind_speed wind_gust ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 EWR 2013 1 1 1 39.0 26.1 59.4 270 10.4 NA ## 2 EWR 2013 1 1 2 39.0 27.0 61.6 250 8.06 NA ## 3 EWR 2013 1 1 3 39.0 28.0 64.4 240 11.5 NA ## # ... with 26,112 more rows, and 4 more variables: precip &lt;dbl&gt;, ## # pressure &lt;dbl&gt;, visib &lt;dbl&gt;, time_hour &lt;dttm&gt; 그림을 사용하여 테이블 간의 관계를 볼 수 있다. 이 다이어그램은 꽤 복잡해 보이지만, 실전에서 보게 될 것과 비교하면 간단한 것이다! 이와 같은 다이어그램을 이해하는 데 핵심은 각 관계가 항상 한 쌍의 테이블과 관련되어 있음을 기억하는 것이다. 여러분은 모든 것을 이해할 필요는 없다. 관심 있는 테이블 사이의 연쇄적인 관계를 이해하면 된다. nycflights13 에서 flights 는 단 하나의 변수인 tailnum 을 통해 planes 에 연결된다. flights 는 carrier 변수를 통해 airlines 에 연결된다. flights 는 origin (출발지) 및 dest (목적지) 변수를 통해 두 가지 방법으로 airports 에 연결된다. flgiths 는 origin (위치), year, month, day, hour (시간)를 통해 weather 에 연결된다. flights : 항공편, planes : 여객기, airlines : 항공사, airports : 공항, weather : 날씨 6.3.4 연습문제 각 여객기가 출발지에서 목적지까지 날아가는 경로를 대략 그려보고 싶다고 상상해보라. 어떤 변수가 필요한가? 어떤 테이블을 결합해야 하는가? 우리는 앞에서 weather 와 airports 사이의 관계를 그리는 것을 잊어버렸다. 어떻게 관계되며, 다이어그램을 이용하여 어떻게 그려야 하는가? weather는 출발지 (NYC) 공항에 대한 정보만 포함한다. 미국의 모든 공항에 대한 날씨 기록이 포함되어 있다면 flights 와 어떤 관계가 추가되는가? 우리는 일 년 중 어떤 날이 ‘특별하다’는 것을 알고 있으며, 이 날에는 평소보다 적은 수의 사람들이 항공여행을 한다는 것을 알고 있다. 이 데이터를 데이터프레임으로 어떻게 표현하겠는가? 이 테이블의 기본키는 무엇이겠는가? 기존 테이블에 어떻게 연결되는가? 6.3.5 키(Key) 각 테이블 쌍을 연결하는 데 사용되는 변수를 키라고 한다. 키는 관측값을 고유하게 식별하는 변수 (또는 변수 집합)이다. 간단한 경우 단일 변수만으로 관측값을 식별할 수 있다. 예를 들어, 각 여객기(`planes)는 tailnum 으로 고유하게 식별된다. 어떤 경우에는 여러 변수가 필요할 수 있다. 예를 들어 weather 의 관측값을 식별하려면 year, month, day, hour, origin 의 다섯 개의 변수가 필요하다. (위의 그림에서 5개의 데이터 세트에 대해 각각의 속성을 표시하고 있으며, 그 중 진한 색깔의 속성이 키이다.) 키에는 두 가지 유형의 키가 있다. 기본키(주키, primary key) 는 자신의 테이블에서 관측값을 고유하게 식별한다. 예를 들어, planes$tailnum 은 planes 테이블의 각 여객기를 고유하게 식별하므로 기본키이다. 외래키(외부키, foreigh key) 는 다른 테이블의 관측값을 고유하게 식별한다. 예를 들어, flight$tailnum 은 flights 테이블에서 각 항공편(flights)을 고유한 여객기(planes)와 매칭시키기 때문에 외래키이다. (flights 테이블의 tailnum 컬럼은 상대 테이블인 planes 테이블의 기본키이다.) 한 변수가 동시에 기본키이며 외래키일 수 있다(이런 경우의 키를 교차참조키라 한다). 예를 들어, 출발지(origin) 컬럼은 weather 테이블의 기본키의 일부이며, flights 테이블의 외래키이기도 하다. 테이블에서 기본키를 확인한 후에는 실제로 기본키가 각 관측값을 고유하게 식별하는지 확인하는 것이 좋다. 이를 수행하는 한 가지 방법은 기본키를 count() 하고 n 이 1보다 큰 항목을 찾는 것이다. planes %&gt;% count(tailnum) %&gt;% filter(n &gt; 1) ## # A tibble: 0 x 2 ## # ... with 2 variables: tailnum &lt;chr&gt;, n &lt;int&gt; planes 테이블의 경우 tailnum이 기본키로서 각 관측값을 고유하게(unique, 유일하게) 식별하고 있다. weather %&gt;% count(year, month, day, hour, origin) %&gt;% filter(n &gt; 1) ## # A tibble: 3 x 6 ## year month day hour origin n ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2013 11 3 1 EWR 2 ## 2 2013 11 3 1 JFK 2 ## 3 2013 11 3 1 LGA 2 반면에 weather 테이블의 경우, year, month, day, hour, orgin 등의 5개의 변수를 동시에 고려한 경우(이를 합성키라고 함) 중복값이 3개 나옴을 알 수 있다. 즉, 이 5개의 변수를 합성하여 기본키로 사용할 수 없음을 의미한다. 때로 테이블에 명시적인 기본키가 없는 경우가 있다. 모든 행은 관측값이지만 어떤 변수를 조합해도 각 행을 신뢰성있게 구분하지 못하는 경우이다. 예를 들어, flight 테이블의 기본키는 무엇인가? 여러분은 date 에 flight 혹은 tailnum 을 더한 것으로 생각하겠지만 이들 중 어느 것도 고유하지 않다. flights %&gt;% count(year, month, day, flight) %&gt;% filter(n &gt; 1) ## # A tibble: 29,768 x 5 ## year month day flight n ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 1 2 ## 2 2013 1 1 3 2 ## 3 2013 1 1 4 2 ## # ... with 29,765 more rows flights 테이블의 경우, year, month, day, flight 등의 4개의 변수를 동시에 고려한 경우에도 많은 중복값들이 나옴을 알 수 있다. 즉, 이 4개의 변수를 합성하여 기본키로 사용할 수 없음을 의미한다. flights %&gt;% count(year, month, day, tailnum) %&gt;% filter(n &gt; 1) ## # A tibble: 64,928 x 5 ## year month day tailnum n ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 2013 1 1 N0EGMQ 2 ## 2 2013 1 1 N11189 2 ## 3 2013 1 1 N11536 2 ## # ... with 64,925 more rows 이 데이터로 작업을 시작할 때 나는 각 항공편 번호(flight )가 하루에 한 번만 사용된다고 순진하게 추측했다. 그런 경우라면 특정 항공편(flight)의 문제에 대해 훨씬 쉽게 의사 소통할 수 있었을 것이었다. 불행히도 그것은 사실이 아니다! 테이블에 기본키가 없으면 mutate() 와 row_number() 를 이용하여 기본키를 추가해 보라. 이렇게 하면 필터링을 수행하고 난 후 원래 데이터와 다시 점검할 때 관측값을 쉽게 일치시킬 수 있다. 이를 대체키(surrogate key) 라고 한다. 기본키와 이와 대응되는 다른 테이블의 외래키는 관계(relationship) 를 형성한다. 관계는 대개 일대다 관계(one-to-many)이다. 예를 들어, 각 항공편에는 여객기가 하나 있지만, 각 여객기에는 여러 항공편이 있다. 다른 데이터에서는 가끔 일대일 관계를 보게 된다. 이것을 일대다 관계의 특별한 경우라고 생각할 수 있다. 다대일(many-to-one) 관계와 일대다 관계를 사용하여 다대다(many-to-many) 관계를 모델링할 수 있다. 예를 들어 이 데이터에는 항공사(airline )와 공항(airport ) 간 다대다 관계가 있다. 즉, 각 항공사는 많은 공항으로 운항하고, 각 공항에는 많은 항공사가 있다. 6.3.6 연습문제 flights 에 대체키를 추가하라. 다음 데이터 세트의 (기본)키를 식별하라. Lahman::Batting babynames::babynames nasaweather::atmos fueleconomy::vehicles ggplot2::diamonds (이를 위해 패키지를 설치하고 설명서를 읽어야 할 수도 있다.) Lahman 패키지의 Batting, Master, Salaries 테이블 간의 연결을 나타내는 다이어그램을 그려라. Master, Managers, AwardsManagers 사이의 관계를 보여주는 또 다른 다이어그램을 그려라. Batting, Pitching, Fielding 테이블 간의 관계를 어떻게 규정하겠는가? 6.4 변환 조인(Mutating Join) 한 쌍의 테이블을 결합하기 위해 살펴 볼 첫 번째 도구는 변환 조인(Mutating Join) 이다. 변환조인을 사용하면 두 테이블의 변수를 결합할 수 있다. 먼저 관측값을 키로 매칭시킨 다음, 한 테이블에서 다른 테이블로 변수들을 복사한다. mutate() 와 마찬가지로 조인 함수는 오른쪽에 변수를 추가하므로 이미 많은 변수가 있는 경우 새 변수가 출력되지 않는다. 이 예제에서는 어떤 일이 일어나는지 더 쉽게 보기 위해 더 좁은 데이터셋을 작성한다. flights2 &lt;- flights %&gt;% select(year:day, hour, origin, dest, tailnum, carrier) flights2 ## # A tibble: 336,776 x 8 ## year month day hour origin dest tailnum carrier ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA ## 2 2013 1 1 5 LGA IAH N24211 UA ## 3 2013 1 1 5 JFK MIA N619AA AA ## # ... with 336,773 more rows (RStudio에서는 View() 를 사용하여 이 문제를 피할 수도 있음을 기억하라.) flight2 데이터에 항공사 전체 이름을 추가하려고 한다고 가정하자. left_join() 으로 airlines 와 flights2 데이터프레임을 결합할 수 있다. flights2 %&gt;% select(-origin, -dest) %&gt;% left_join(airlines, by = &quot;carrier&quot;) ## # A tibble: 336,776 x 7 ## year month day hour tailnum carrier name ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 N14228 UA United Air Lines Inc. ## 2 2013 1 1 5 N24211 UA United Air Lines Inc. ## 3 2013 1 1 5 N619AA AA American Airlines Inc. ## # ... with 336,773 more rows flights2 은 airlines 와 결합하여, 새로운 변수 name 이 추가되었다. 이것이 내가 이 유형의 조인을 변환 조인이라고 부르는 이유이다. 이 경우 mutate() 와 R 의 base 서브세팅 작업을 사용하여 같은 위치에 도달할 수 있다. flights2 %&gt;% select(-origin, -dest) %&gt;% mutate(name = airlines$name[match(carrier, airlines$carrier)]) ## # A tibble: 336,776 x 7 ## year month day hour tailnum carrier name ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 2013 1 1 5 N14228 UA United Air Lines Inc. ## 2 2013 1 1 5 N24211 UA United Air Lines Inc. ## 3 2013 1 1 5 N619AA AA American Airlines Inc. ## # ... with 336,773 more rows 그러나 이 방법은 여러 변수를 매치시켜야 할 경우 일반화하기 어렵고, 또 전체적인 의도를 파악하기 위해서는 코드를 자세히 읽어야 한다는 단점이 있다. 다음 절에서는 변환 조인의 작동 방식에 대해 자세히 설명한다. 우선 조인을 어떻게 시각적으로 표현하는지부터 배운다. 그런 다음 이를 사용하여 4개의 뮤테이팅 조인 함수, 즉 하나의 내부 조인(inner join)과 3개의 외부 조인(outer join)을 설명한다. 실제 데이터로 작업할 때 키가 항상 관측값을 고유하게 식별하지는 않기 때문에 다음으로는 고유한 매치가 없을 때 발생하는 상황에 대해 이야기하겠다. 마지막으로 조인이 정해졌을 때 어떤 변수가 이 조인의 키인지 dplyr 에 알려주는 방법을 배운다. 6.4.1 조인 이해하기 조인이 어떻게 작동하는지 배우기 위해 시각적 표현을 사용한다. 6.4.1.1 예제 데이터의 생성 x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) x ## # A tibble: 3 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) y ## # A tibble: 3 x 2 ## key val_y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y3 색상이 있는 열은 ’키’ 변수(컬럼)를 나타내며, 테이블 사이의 행을 일치(대응, matching)시키는 데 사용된다. 회색 열은 함께 따라가는 ’값’ 열(컬럼)을 나타낸다. 이 예제에서는 단일 키 변수와 단일 값 변수가 있지만, 다중 키와 다중 값으로 자연스럽게 일반화된다. 조인은 테이블 x 의 각 행을, 테이블 y 의 행과 대조하면서 (0개, 1 개 또는 여러 행에) 연결하는 방법이다. 다음 다이어그램은 각각의 매칭 후보를 한 쌍의 선의 교차점으로 보여준다. (다음의 그림은 x와 y의 모든 연결 가능성을 보여 준다. Cartesian Product) (주의 깊게 살펴보면 x 의 키 열과 값 열의 순서가 바뀌었음을 알 수 있다. 이는 조인이 키를 기반으로 매칭하며 값은 단지 따라간다는 것을 강조하기 위한 것이다.) 실제 조인에서는 매치 항목이 점으로 표시된다. 도트 수 = 매치 수 = 출력의 행 수이다. 6.4.2 내부 조인 (inner join) 가장 간단한 조인 유형은 내부 조인 이다. 내부 조인은 테이블 x의 키와 테이블 y의 키가 같을 때 두 관측값을 매칭한다. (정확하게 말하면 같음 연산자(equality operator)를 사용하여, 키가 매치되기 때문에 내부 동등 조인(equijoin) 이다. 대부분의 조인은 동등 조인이므로 우리는 일반적으로 이러한 상세한 내용을 생략한다.) 내부 조인(inner join)의 출력은 키, x 값 및 y 값을 포함하는 새로운 데이터프레임이다. by 를 사용하여 어떤 변수가 키인지를 지정한다. x %&gt;% inner_join(y, by = &quot;key&quot;) ## # A tibble: 2 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 내부 조인의 가장 중요한 특성은 매칭되지 않는 행은 결과에 포함되지 않는다는 점이다. 즉, 내부 조인은 관측값을 잃어버리기 쉽기 때문에 일반적으로 분석에 사용하기에 적합하지 않다. 6.4.3 외부 조인 (outer join) 내부 조인에서는 두 테이블 모두에 나타나는 관측값이 보존된다. 외부 조인(outer join)에서는 적어도 하나의 테이블에 있는 관측값은 보존된다. 외부 조인에는 세 가지 유형이 있다. 왼쪽 조인(left join) 은 x 의 모든 관측값을 보존한다. 오른쪽 조인(right join) 은 y 의 모든 관측값을 보존한다. 전체 조인(full join) 은 x 와 y 의 모든 관측값을 보존한다. 이러한 조인은 각 테이블에 ’가상’ 관측값을 추가하여 작동한다. 이 관측값에는 항상 매칭되는 키 (다른 키가 매칭되지 않는 경우)와 NA 로 채워진 값이 있다. 그래픽으로 보면 다음과 같다. # left_join() x %&gt;% left_join(y, by = &quot;key&quot;) ## # A tibble: 3 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 &lt;NA&gt; # right_join() x %&gt;% right_join(y, by = &quot;key&quot;) ## # A tibble: 3 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 4 &lt;NA&gt; y3 # full_join() x %&gt;% full_join(y, by = &quot;key&quot;) ## # A tibble: 4 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 &lt;NA&gt; ## 4 4 &lt;NA&gt; y3 가장 일반적으로 사용되는 조인은 왼쪽 조인이다. 매칭되지 않는 경우에도 원본 관측값을 보존하므로 다른 테이블에서 추가 데이터를 조회할 때마다 이 작업을 사용한다. 왼쪽 조인이, 작업 시 기본 조인이 되어야 한다. 다른 조인을 선호해야 하는 명백한 이유가 없다면 왼쪽 조인을 사용하라. 서로 다른 유형의 조인을 묘사하는 또 다른 방법은 벤 다이어그램을 사용하는 것이다. 그러나 이 표현법은 완벽하지 않다. 조인 유형들이 각각 어떤 테이블의 관측값을 보존하는지 알려주긴 하지만, 커다란 제약사항이 있다. 벤 다이어그램은 키가 고유하게 관측값을 식별하지 못할 때 어떤 일이 발생하는지를 표현할 수 없다. 6.4.4 중복키 지금까지 모든 테이블은 키가 고유하다고 가정했다. 하지만 항상 그런 것은 아니다. 이 절에서는 키가 고유하지 않은 경우 어떻게 되는지 설명한다. 두 가지 경우가 있다. 하나의 테이블에 중복값을 갖는 키가 있다. 중복키는 추가적인 정보를 넣을 때 유용한데 일반적으로 일대다 관계가 있기 때문이다. 출력에서 약간 다른 위치에 키 열을 놓은 것을 확인하라. 이것은 키가 y 의 기본키이고 x 의 외래키임을 보여준다. x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 1, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot; ) left_join(x, y, by = &quot;key&quot;) ## # A tibble: 4 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 2 x3 y2 ## 4 1 x4 y1 두 테이블 모두 중복 키가 있다. 키가 어느 테이블에서도 고유하게 관측값을 식별하지 않기 때문에 이것은 일반적으로 에러이다. 중복 키를 결합하면 가능한 모든 조합인 데카르트곱(Cartesian product)을 얻을 수 있다. x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 3, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 2, &quot;y3&quot;, 3, &quot;y4&quot; ) left_join(x, y, by = &quot;key&quot;) ## # A tibble: 6 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 2 x2 y3 ## # ... with 3 more rows 6.4.5 키열 정의하기 지금까지 테이블 쌍은 항상 하나의 변수에 의해 조인되었으며 그 변수는 두 테이블에서 같은 이름을 가졌었다. 그 제약은 by = \"key\" 로 코드화되었다. by 에 다른 값을 사용하여 다른 방법으로 테이블을 연결할 수 있다. 기본값 by = NULL 을 사용하면 두 테이블에 있는 모든 변수를 사용하며 이는 자연 조인(natural join)이라 부른다. 예를 들어 flights 및 weather 테이블은 공통 변수인 year, month, day, hour, origin 으로 매치된다. flights2 %&gt;% left_join(weather) ## Joining, by = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;, &quot;hour&quot;, &quot;origin&quot;) ## # A tibble: 336,776 x 18 ## year month day hour origin dest tailnum carrier temp dewp humid ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA 39.0 28.0 64.4 ## 2 2013 1 1 5 LGA IAH N24211 UA 39.9 25.0 54.8 ## 3 2013 1 1 5 JFK MIA N619AA AA 39.0 27.0 61.6 ## # ... with 336,773 more rows, and 7 more variables: wind_dir &lt;dbl&gt;, ## # wind_speed &lt;dbl&gt;, wind_gust &lt;dbl&gt;, precip &lt;dbl&gt;, pressure &lt;dbl&gt;, ## # visib &lt;dbl&gt;, time_hour &lt;dttm&gt; 문자형 벡터 by = \"x\" . 이것은 자연 결합과 같지만 일부 공통 변수만 사용한다. 예를 들어 flights 와 planes 에는 year 변수가 있지만 서로 다른 의미이므로 tailnum 으로만 조인하고 싶다. flights2 %&gt;% left_join(planes, by = &quot;tailnum&quot;) ## # A tibble: 336,776 x 16 ## year.x month day hour origin dest tailnum carrier year.y type ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA 1999 Fixe~ ## 2 2013 1 1 5 LGA IAH N24211 UA 1998 Fixe~ ## 3 2013 1 1 5 JFK MIA N619AA AA 1990 Fixe~ ## # ... with 336,773 more rows, and 6 more variables: manufacturer &lt;chr&gt;, ## # model &lt;chr&gt;, engines &lt;int&gt;, seats &lt;int&gt;, speed &lt;int&gt;, engine &lt;chr&gt; year 변수 (두 입력 데이터프레임 모두에 나타나지만 같지 않도록 제한시킴)는 접미사가 붙어서 출력에서 헷갈리지 않게 된 것을 확인하라. 이름있는 문자 벡터, by = c(\"a\" = \"b\") . 테이블 x 의 변수 a 와 테이블 y 의 변수 b 를 매칭시킨다. x 의 변수가 출력에 사용된다. 예를 들어, 지도를 그리려면 flights 데이터를 각 공항의 위치(lat 과 lon , 위도와 경도)가 포함된 airports 데이터와 결합해야 한다. 각 항공편에는 출발 공항(origin)과 도착 공항(dest)이 있으므로 어떤 것에 조인할지 지정해야 한다. flights2 %&gt;% left_join(airports, c(&quot;dest&quot; = &quot;faa&quot;)) ## # A tibble: 336,776 x 15 ## year month day hour origin dest tailnum carrier name lat lon alt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA Geor~ 30.0 -95.3 97 ## 2 2013 1 1 5 LGA IAH N24211 UA Geor~ 30.0 -95.3 97 ## 3 2013 1 1 5 JFK MIA N619AA AA Miam~ 25.8 -80.3 8 ## # ... with 336,773 more rows, and 3 more variables: tz &lt;dbl&gt;, dst &lt;chr&gt;, ## # tzone &lt;chr&gt; flights2 %&gt;% left_join(airports, c(&quot;origin&quot; = &quot;faa&quot;)) ## # A tibble: 336,776 x 15 ## year month day hour origin dest tailnum carrier name lat lon alt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 EWR IAH N14228 UA Newa~ 40.7 -74.2 18 ## 2 2013 1 1 5 LGA IAH N24211 UA La G~ 40.8 -73.9 22 ## 3 2013 1 1 5 JFK MIA N619AA AA John~ 40.6 -73.8 13 ## # ... with 336,773 more rows, and 3 more variables: tz &lt;dbl&gt;, dst &lt;chr&gt;, ## # tzone &lt;chr&gt; 6.4.6 연습문제 목적지별 평균 연착시간을 계산한 다음, airports 데이터프레임에 조인하여 연착의 공간 분포를 표시하라. 다음을 이용하여 미국 지도를 쉽게 그릴 수 있다. airports %&gt;% semi_join(flights, c(&quot;faa&quot; = &quot;dest&quot;)) %&gt;% ggplot(aes(lon, lat)) + borders(&quot;state&quot;) + geom_point() + coord_quickmap() (semi_join() 이 무엇인지 몰라도 걱정하지 마라. 다음에 배울 것이다.) 점의 크기 또는 색깔로 각 공항의 평균 연착 시간을 표시할 수 있다. flights 에 출발지와 목적지의 위치 (즉, lat 과 lon )를 추가하라. 여객기의 나이와 연착 시간 사이에 관계가 있는가? 어떤 기상 조건이 연착 가능성을 더 높이는가? 2013년 6 월 13 일에 무슨 일이 일어났는가? 연착의 공간 패턴을 표시한 다음 구글을 사용하여 날씨와 상호참조하라. 6.4.7 기타 구현 base::merge() 는 네 가지 유형의 변환 조인을 모두 수행할 수 있다. dplyr merge inner_join(x, y) merge(x, y) left_join(x, y) merge(x, y, all.x = TRUE) right_join(x, y) merge(x, y, all.y = TRUE), full_join(x, y) merge(x, y, all.x = TRUE, all.y = TRUE) 특정 dplyr 동사의 장점은 코드의 의도를 좀 더 명확하게 전달한다는 것이다. 즉, 조인 간의 차이는 실제로 중요하지만 merge() 인수에 숨어 있다. dplyr 의 조인은 상당히 빠르며 행 순서를 어지럽히지 않는다. dplyr 의 규칙은 SQL에 기반을 두므로 서로 옮겨쓰는 것은 복잡하지 않다. dplyr SQL inner_join(x, y, by = \"z\") SELECT * FROM x INNER JOIN y USING (z) left_join(x, y, by = \"z\") SELECT * FROM x LEFT OUTER JOIN y USING (z) right_join(x, y, by = \"z\") SELECT * FROM x RIGHT OUTER JOIN y USING (z) full_join(x, y, by = \"z\") SELECT * FROM x FULL OUTER JOIN y USING (z) ’INNER’및 ’OUTER’는 선택적이며 종종 생략된다. inner_join(x, y, by = c(\"a\" = \"b\")) 과 같이 테이블 간에 다른 변수를 결합하는 것은, SQL에서 약간 다른 문법을 사용한다. SELECT * FROM x INNER JOIN y ON x.a = y.b . 이 구문에서 알 수 있듯이, SQL은 dplyr 보다 폭넓은 조인 유형을 지원하는데 등식이 아닌 다른 제약 조건을 사용하여 테이블을 연결할 수도 있다. (비동등 조인(non-equisjoins)라고도 함) 6.5 필터링 조인 필터링 조인(Filtering join)은 변환 조인과 같은 방식으로 관측값을 매칭하지만 변수가 아닌 관측값에 영향을 준다. 두 가지 유형이 있다. semi_join(x, y) 는 y 와 매치되는 x 의 모든 관측값을 보존한다 . anti_join(x, y) 는 y 와 매치되는 x 의 모든 관측값을 삭제한다 . 세미 조인(Semi-joins)은 필터링된 요약 테이블을 다시 원래 행과 매치시키는 데 유용하다. 예를 들어 가장 인기 있는 상위 10개 도착지(dest)를 구했다고 가정해보자. top_dest &lt;- flights %&gt;% count(dest, sort = TRUE) %&gt;% head(10) top_dest ## # A tibble: 10 x 2 ## dest n ## &lt;chr&gt; &lt;int&gt; ## 1 ORD 17283 ## 2 ATL 17215 ## 3 LAX 16174 ## # ... with 7 more rows 이제 그 목적지 중 한 곳(dest %in% top_dest$dest)으로 운행한 항공편(flihts)을 찾고 싶다면 직접 필터를 만들 수 있다. flights %&gt;% filter(dest %in% top_dest$dest) ## # A tibble: 141,145 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 542 540 2 923 850 ## 2 2013 1 1 554 600 -6 812 837 ## 3 2013 1 1 554 558 -4 740 728 ## # ... with 141,142 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 그러나 이러한 접근 방식을 여러 변수로 확장하는 것은 어렵다. 예를 들어 평균 연착시간(average arr_delay)이 가장 길었던 날 10일을 골라냈다고 상상해보라. year, month, day 를 사용하여 다시 항공편(flights)과 일치시키는 필터 구문을 어떻게 작성할 수 있는가? 한편 변환 조인과 같이 두 테이블을 연결하는 세미 조인을 사용할 수 있지만, 새 열을 추가하는 대신 y 에서 일치하는 x 의 행만 보존한다. flights %&gt;% semi_join(top_dest) ## Joining, by = &quot;dest&quot; ## # A tibble: 141,145 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 542 540 2 923 850 ## 2 2013 1 1 554 600 -6 812 837 ## 3 2013 1 1 554 558 -4 740 728 ## # ... with 141,142 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; 세미 조인(semi-join)은 그래픽으로 다음과 같이 표현된다. x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) x %&gt;% semi_join(y, by=&quot;key&quot;) ## # A tibble: 2 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 매칭되었는지 여부만이 중요하다. 즉, 어떤 관측값이 매칭되는지는 중요하지 않다. 이는 필터링 조인은 뮤테이팅 조인처럼 행을 복제하지는 않는다는 것을 의미한다. x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 2, &quot;x3&quot;, 3, &quot;x4&quot; ) y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 2, &quot;y3&quot;, 3, &quot;y4&quot; ) x %&gt;% semi_join(y, by=&quot;key&quot;) ## # A tibble: 4 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 2 x3 ## 4 3 x4 세미 조인의 반대는 안티 조인(Anti-join)이다. 안티 조인은 매칭되지 않는 행을 보존한다. x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) x ## # A tibble: 3 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) y ## # A tibble: 3 x 2 ## key val_y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y3 x %&gt;% anti_join(y, by=&quot;key&quot;) ## # A tibble: 1 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 3 x3 안티 조인(Anti-join)은 조인 불일치를 진단하는 데 유용하다. 예를 들어 flights과 planes 를 연결하는 경우, planes 에 매치되지 않는 flights 이 많다는 것을 알고 싶을 수 있다. flights %&gt;% anti_join(planes, by = &quot;tailnum&quot;) %&gt;% count(tailnum, sort = TRUE) ## # A tibble: 722 x 2 ## tailnum n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 2512 ## 2 N725MQ 575 ## 3 N722MQ 513 ## # ... with 719 more rows 6.5.1 연습문제 항공편에 tailnum 이 없는 것은 무엇을 의미하는가? planes 에 매치되는 관측값이 없는 tailnum 관측값의 공통점은 무엇인가? (힌트: 한 변수가 문제의 약 90%를 설명한다.) flights 를 필터링하여 최소 100 편의 운행을 한 여객기의 항공편만 표시하라. fueleconomy::vehicles 와 fueleconomy::common 을 결합하여 가장 많은 차량 모델의 레코드만 찾아라. 최악의 연착 시간을 가진 (1년 중) 48시간을 찾아라. 날씨 데이터와 교차 참조하라. 어떤 패턴을 볼 수 있는가? anti_join(flights, airports, by = c(\"dest\" = \"faa\")) 을 보고 무엇을 알 수 있는가? anti_join(airports, flights, by = c(\"faa\" = \"dest\")) 은 어떤가? 각 항공기는 단일 항공사에 의해 운항되므로 항공기와 항공사 간에 암묵적인 관계가 있을 것으로 예상할 수 있다. 이전 절에서 배운 도구를 사용하여 이 가설을 확인하거나 기각하라. 6.6 조인 문제 이 장에서 작업하고 있는 데이터는 문제가 거의 발생하지 않도록 미리 정제되었다. 여러분의 데이터는 그리 깨끗하지 않을 것이므로 조인을 원활하게 하기 위해서 주어진 데이터에 수행해야 하는 몇 가지 작업이 있다. 우선 각 테이블에서 기본키를 구성하는 변수들을 식별하라. 경험적이 아니라 데이터 이해를 바탕으로, 고유한 식별자가 되는 변수의 조합을 찾아야 한다. 변수가 의미하는 바를 고려하지 않고 찾는다면 우연히도 현재의 데이터에서는 고유한 조합이지만 일반적으로는 그렇지 않을 수 있다. 예를 들어, 고도(alt)와 경도(lat)는 각 공항(airports)을 고유하게 식별하지만 좋은 식별자는 아니다! airports %&gt;% count(alt, lon) %&gt;% filter(n &gt; 1) #&gt; # A tibble: 0 x 3 #&gt; # ... with 3 variables: alt &lt;int&gt;, lon &lt;dbl&gt;, n &lt;int&gt; 기본 키의 변수들에 결측값이 없는지 확인하라. 값이 결측된 경우에는 관측값을 식별할 수 없다! (기본키는 기본적으로 NOT NULL, 즉, 결측치가 존재하면 안된다) 외래 키가 다른 테이블의 기본 키와 매칭되는지 확인하라. 가장 좋은 방법은 anti_join() 을 사용하는 것이다. 데이터 입력 에러로 인해 키가 매칭되지 않는 경우는 흔하다. 이를 고치는 것은 큰 작업일 때가 많다. 키가 결측된 경우 매칭되지 않는 행을 삭제할 것인지를 신중하게 고려하면서 내부 조인과 외부 조인을 신중히 고려해야 한다. 조인이 원활하게 진행되었는지 확인하기 위해 조인 전후의 행 수만 살피는 것은 충분하지 않다. 두 테이블 모두에 중복 키가 있는 내부 조인의 경우, 불행히도, 삭제된 행 수가 복제된 행 수와 정확히 같을 수 있다! 6.7 집합 연산 2 테이블 동사의 마지막 유형은 집합 연산이다. 일반적으로 이 필터는 가장 드물게 사용하지만, 복잡한 필터를 단순한 필터들로 분해하려는 경우에 가끔 유용하다. 이 모든 연산은 행 전체에 동작하는데 모든 변수의 값을 비교한다. 이 집합 연산은 x 와 y 입력이 같은 변수를 가지는 것을 간주하며 관측값을 집합으로 취급한다. intersect(x, y): x, y 모두에 있는 관측값만 반환 union(x, y) : x 와 y 의 고유한 관측값을 반환. (중복값은 제외) setdiff(x, y) : x 에 있지만, y 에 없는 관측값을 반환 아래의 간단한 데이터에 대해서, df1 &lt;- tribble( ~x, ~y, 1, 1, 2, 1 ) df2 &lt;- tribble( ~x, ~y, 1, 1, 1, 2 ) 네 가지 연산은 다음과 같다. intersect(df1, df2) ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 # 열이 4개가 아니라 3개임을 주목 union(df1, df2) ## # A tibble: 3 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 1 ## 3 1 2 setdiff(df1, df2) ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 2 1 setdiff(df2, df1) ## # A tibble: 1 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 union_all(x, y, ...) : x와 y 에 있는 모든 행들을 결합. (결합된 데이터 세트의 중복 행을 제거하지 않음.) setequal(x, y, ...) : x와 y의 행이 같은 지 비교. union_all(df1, df2) ## # A tibble: 4 x 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 ## 2 2 1 ## 3 1 1 ## 4 1 2 setequal(df1, df2) ## [1] FALSE Reference http://www.datasciencemadesimple.com/union-union_all-function-r-using-dplyr-union-data-frames/ 6.8 Join Exercises 이번 장에서는 dplyr 패키지를 이용한 데이터의 병합과 관련하여 사용할 수 있는 다음의 함수들에 대하여 살펴보기로 한다: inner_join() left_join() right_join() full_join() semi_join() anti_join() nest_join() 먼저 이 함수들의 기본 개념과 (간단한 예를 들어) 차이점들에 대하여 살펴볼 것이다. 그런 다음 좀 더 복잡한 예제들을 살펴보기로 한다: 복수 데이터 프레임의 조인 복수 개 컬럼에 의한 조인 데이터 조인과 ID 삭제 6.8.1 예제 데이터의 생성 먼저 예제에 사용될 예제 데이터 프레임들을 생성해 보기로 한다. data1 &lt;- data.frame(ID = 1:2, # Create first example data frame X1 = c(&quot;a1&quot;, &quot;a2&quot;), stringsAsFactors = FALSE) data1 ## ID X1 ## 1 1 a1 ## 2 2 a2 data2 &lt;- data.frame(ID = 2:3, # Create second example data frame X2 = c(&quot;b1&quot;, &quot;b2&quot;), stringsAsFactors = FALSE) data2 ## ID X2 ## 1 2 b1 ## 2 3 b2 다음의 그림은 지금 생성한 두 개의 데이터 프레임과 dplyr 패키지의 다양한 조인 함수를 이용하여 이들 데이터 프레임을 병합하는 방법을 보여주고 있다. 그림의 제일 위에 예제 데이터 프레임의 구조를 보여주고 있다. 각 데이터 프레임은 두 개의 컬럼을 가지고 있다. data1은 ID와 X1 컬럼을, 그리고 data2는 ID와 X2 컬럼을 가지고 있다. ID 컬럼은 두 데이터 프레임의 공통 컬럼이며, 또한 공통의 값인 2를 가지고 있다. ~ (6) : 두 데이터 프레임을 조인하는 방법에 따라 결과로 생성되는 데이터 프레임을 보여주고 있다. 이들 각각에 대하여 예를 들어 살펴보기로 한다. 6.8.2 예제 1: inner_join() 먼저 dplyr 패키지를 설치하여 불러오기를 해야 한다: install.packages(&quot;dplyr&quot;) # Install dplyr package ## Warning: package &#39;dplyr&#39; is in use and will not be installed library(&quot;dplyr&quot;) # Load dplyr package 이 예제에서는 예제 데이터 프레임의 inner_join() 함수에 대하여 살펴보기로 한다. 6.8.2.1 inner_join() 함수의 기본 형식 inner_join( x, y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ..., na_matches = c(&quot;na&quot;, &quot;never&quot;) ) 6.8.2.2 inner_join() 함수의 예 inner_join 방식으로 데이터 프레임을 병합하기 위해서는, 병합할 두 개의 데이터 프레임의 이름들(data1과 data2)과 병합에 사용될 공통의 컬럼(여기서는 ID 컬럼)을 inner_join() 함수의 인수(by = ”ID”)로 지정해 주면 된다. inner_join(data1, data2, by = &quot;ID&quot;) # Apply inner_join dplyr function ## ID X1 X2 ## 1 2 a2 b1 이 그림은 inner_join의 결과를 보여준다. 이 그림에서 볼 수 있듯이, inner_join() 함수는 두 개의 데이터 프레임의 컬럼들을 병합하지만, 공통의 컬럼인 ID에 대해 같은 값을 갖는 행만(ID = 2)을 병합한다. 6.8.3 예제 2: left_join() 6.8.3.1 left_join() 함수의 기본 형식 left_join( x, y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ..., keep = FALSE ) 6.8.3.2 left_join() 함수의 예 left_join(data1, data2, by = &quot;ID&quot;) # Apply left_join dplyr function ## ID X1 X2 ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 inner_join과의 차이는 left_join은 left_join() 함수에 첫 번째로 입력된(left) 데이터 프레임(data1)의 모든 행들을 포함하고 있다. 이때 결과로 생성되는 데이터 프레임의 ID = 1에 해당하는 행의 X2 컬럼에는 NA로 채워진다. 6.8.4 예제 3: right_join() left_join() 함수의 상대적 함수가 right_join() 함수이다. 6.8.4.1 right_join() 함수의 기본 형식 이 함수의 기본 형식은 다음과 같다: right_join( x, y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ..., keep = FALSE ) 6.8.4.2 right_join() 함수의 예 right_join(data1, data2, by = &quot;ID&quot;) # Apply right_join dplyr function ## ID X1 X2 ## 1 2 a2 b1 ## 2 3 &lt;NA&gt; b2 right_join() 함수에 두 번째로 입력된(right) 데이터 프레임(data2)의 모든 행들을 포함하고 있다. 이때 결과로 생성되는 데이터 프레임의 ID = 3 에 해당하는 행의 X1 컬럼에는 NA로 채워진다. 6.8.5 예제 4: full_join() 6.8.5.1 full_join() 함수의 기본 형식 full_join() 함수는 join() 함수 중에서 가장 많은 데이터를 유지한다. 이 함수의 기본 형식은 다음과 같다: full_join( x, y, by = NULL, copy = FALSE, suffix = c(&quot;.x&quot;, &quot;.y&quot;), ..., keep = FALSE ) 6.8.5.2 full_join() 함수의 예 full_join(data1, data2, by = &quot;ID&quot;) # Apply full_join dplyr function ## ID X1 X2 ## 1 1 a1 &lt;NA&gt; ## 2 2 a2 b1 ## 3 3 &lt;NA&gt; b2 full_join() 함수는 두 데이터 프레임(data1과data2`)의 모든 행들을 포함하고 있다. 이때 결과로 생성되는 데이터 프레임의 ID = 1 에 해당하는 행의 X2 컬럼과 ID=3에 해당하는 행의 X1컬럼은 NA로 채워진다. 6.8.6 예제 5: semi_join() 앞의 4개의 join 함수들(inner_join(), left_join(), right_join(), 그리고 full_join())은 변환 조인(mutating joins)이라고도 불린다. 변환 조인은 두 데이터 소스의 변수(컬럼)들을 결합한다. 다음의 두 개의 join 함수들(semi_join()과 anti_join())은 필터링 조인(filtering joins)이라고 불린다. 필터링 조인은 왼쪽 데이터(x)의 모든 경우를 유지하며, 오른 쪽 데이터(y)를 필터로 사용한다. 6.8.6.1 semi_join() 함수의 기본 형식 이 함수의 기본 형식은 다음과 같다: semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c(&quot;na&quot;, &quot;never&quot;)) 6.8.6.2 semi_join() 함수의 예 semi_join(data1, data2, by = &quot;ID&quot;) # Apply semi_join dplyr function ## ID X1 ## 1 2 a2 semi_join() 함수는 왼쪽의 데이터 프레임(data1)에 대하여 오른 쪽 데이터 프레임(data2)에 있는 공통 컬럼인 ID 값과 비교하여 대응이 되는 행만을 유지한다. 이 때, 결과로 생성되는 데이터 프레임의 구조는 왼쪽 데이터 프레임의 구조와 같다. 6.8.7 예제 6 : anti_join() 6.8.7.1 anti_join() 함수의 기본 형식 anti_join() 함수는 앞에서 살펴 본 semi_join() 함수의 결과의 반대이다. 이 함수의 기본 형식은 다음과 같다: semi_join(x, y, by = NULL, copy = FALSE, ..., na_matches = c(&quot;na&quot;, &quot;never&quot;)) 6.8.7.2 anti_join() 함수의 예 anti_join(data1, data2, by = &quot;ID&quot;) # Apply anti_join dplyr function ## ID X1 ## 1 1 a1 anti_join() 함수는 왼쪽의 데이터 프레임(data1)에 대하여 오른 쪽 데이터 프레임(data2)에 있는 공통 컬럼인 ID 값과 비교하여 대응이 되지 않는 행만을 유지한다. 이 때, 결과로 생성되는 데이터 프레임의 구조는 왼쪽 데이터 프레임의 구조와 같다. 지금까지 dplyr 패키지의 6 개 join 함수들의 기본 개념에 대하여 살펴 보았다. 그러나, 실제에 있어서는 지금까지 살펴 본 예제보다는 훨씬 더 복잡하다. 다음에서 좀 더 복잡한 상황에서 join 함수를 어떻게 적용할 수 있는지 살펴보기로 한다. 6.8.8 예제 7: 복수 개의 데이터 프레임 조인 좀 더 복잡한 상황을 만들기 위해 세 번째 데이터 프레임 예제 데이터를 생성한다: 6.8.8.1 예제 데이터의 생성 data3 &lt;- data.frame(ID = c(2, 4), # Create third example data frame X2 = c(&quot;c1&quot;, &quot;c2&quot;), X3 = c(&quot;d1&quot;, &quot;d2&quot;), stringsAsFactors = FALSE) data3 # Print data to RStudio console ## ID X2 X3 ## 1 2 c1 d1 ## 2 4 c2 d2 세 번째 데이터 프레임인 data3은 ID, X2, X3 등의 컬럼을 가지고 있다. 이 컬럼들 중 X2 컬럼은 data2에도 존재하고 있음을 주목하기 바란다. 이번 예제에서는 복수 개의 데이터 프레임들을 하나의 데이터 세트로 병합하는 방법에 대하여 살펴보기로 한다. 여기서는 full_join() 함수를 사용하겠지만, 다른 종류의 join 함수들도 같은 방법으로 이용할 수 있다. full_join(data1, data2, by = &quot;ID&quot;) %&gt;% # Full outer join of multiple data frames full_join(., data3, by = &quot;ID&quot;) ## ID X1 X2.x X2.y X3 ## 1 1 a1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 2 a2 b1 c1 d1 ## 3 3 &lt;NA&gt; b2 &lt;NA&gt; &lt;NA&gt; ## 4 4 &lt;NA&gt; &lt;NA&gt; c2 d2 full_join(data1, data2, by = \"ID\") 먼저 data1과 data2를 공통 컬럼인 ID를 기준으로 해서 full_join을 한다. 그런 다음, 그 결과로 생성된 객체(.)를 data3와 역시 공통 컬럼인 ID를 기준으로 full_join을 한다. 왼쪽 테이블의 X2는 X2.x로, 오른쪽 테이블의 X2는 X2.y로 변환되어 있음을 알 수 있다. 최종으로 생성된 데이터의 첫 3개 행은 왼쪽 테이블, 그리고 네 번째 행은 오른쪽 테이블에 의해 생성되었다. 다만 X2.y 컬럼과 X3 컬럼 중 첫 번째와 세 번째 행의 데이터, 그리고 네 번째 행의 X1과 X2.x 컬럼의 값은 모두 NA로 채워져 있음을 알 수 있다. 6.8.9 예제 8: 복수 컬럼에 의한 조인 예제 7에서 본 것처럼, data2와 data3은 ID와 X2 컬럼을 같이 가지고 있다. 이 두 컬럼을 기준으로 두 개의 데이터 프레임을 조인하고자 한다면, by = 옵션에 동시에 그 변수들을 조인 변수로 지정하면 된다. full_join(data2, data3, by = c(&quot;ID&quot;, &quot;X2&quot;)) # Join by multiple columns ## ID X2 X3 ## 1 2 b1 &lt;NA&gt; ## 2 3 b2 &lt;NA&gt; ## 3 2 c1 d1 ## 4 4 c2 d2 주의 : 최종적으로 생성된 데이터 세트에서 ID가 2 인 행의 경우, ‘1번 행’은 data2에는 X3가 없으므로 NA가 그리고 ‘4번 행’은 data3에는 X3가 d1 이므로 d1 값이 복사됨을 알 수 있다. 6.8.10 예제 9: 데이터 조인과 ID 삭제 마지막의 예로, 데이터 프레임을 조인하는데 사용된 공통의 컬럼인 ID가 더 이상 필요하지 않을 때가 있다. 이러한 ID 컬럼을 제거하기 위해서는 다음과 같은 코드를 사용하면 된다: inner_join(data1, data2, by = &quot;ID&quot;) %&gt;% # Automatically delete ID select(- ID) ## X1 X2 ## 1 a2 b1 Further Reading The merge Function in R The cbind R Function [rbind &amp; rbind.fill plyr] in R List of Useful R Functions The R Programming Language https://statisticsglobe.com/r-dplyr-join-inner-left-right-full-semi-anti "],["tidy-data.html", "Chapter 7 Tidy Data 7.1 타이디 데이터 철학 7.2 Untidy data 7.3 컬럼 제목들이 변수 명이 아니고 값들인 경우 7.4 하나의 컬럼에 복수 개의 변수들이 있는 경우 7.5 하나의 셀에 저장된 여러 변수 또는 여러 셀에 흩어져 있는 한 변수 7.6 separate() 함수와 unite() 함수 7.7 tidyverse 참조표 References", " Chapter 7 Tidy Data library(tidyverse) 7.1 타이디 데이터 철학 (tidyverse 패키지와 함께 불려와 지는) “타이디(tidy)” 데이터 세트를 생성하는tidyr 패키지에 있는 도구들에 대하여 살펴보기로 한다. 타이디 데이터 세트는 다음과 같은 단순한 구조적 규칙을 준수한다: 데이터 세트는 변수(컬럼)과 관측치(행)으로 조직화된 값들의 집합이다. 변수는 관측치에 대한 동일 속성을 측정해야한다. 관측치는 변수로 측정되는 동일한 단위를 나타내야 한다. 타이디 데이터 관습은 데이터를 조직화해야 할 필요가 있을 때마다 “다시 생각하게 만드는 것을” 피하게 해 주는 표준 조직을 제공한다. 좀 더 적극적으로 데이터를 “타이디”하게 만드는 것은 나중에 더 많은 시간을 절약하게 줄 것이다. 7.1.1 분석의 단위 데이터 센트의 각 행이 분석의 단위(unit of anlysis)를 나타내야 한다. 단위는 대상, 또는 대상 내의 시험 또는 주제의 모든 그룹 등이 될 수 있다. 일부 분석은 개별 단위와 종합된 단위를 설명하는 변수들을 포함할 수 있다. 예를 들어, 학생 수준의 분석은 학교 수준의 변수를 포함할 수 있다. 종단적 연구(longitudinal studies)들은 대상 내에서 그리고 대상 간의 변수들을 포함할 수 있다. 다차원 분석에 대해서는 분석의 단위가 일반적으로 가장 낮은 수준이다. 7.1.2 데이터 세트 patient_pt1_dm.csv 파일을 read_csv() 함수로 불러와서 티블 변수 d에 대입한다. d &lt;- read_csv(&quot;data7/patient_pt1_dm.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## .default = col_double(), ## hospital = col_character(), ## docid = col_character(), ## dis_date = col_character(), ## sex = col_character(), ## familyhx = col_character(), ## smokinghx = col_character(), ## cancerstage = col_character(), ## wbc = col_character() ## ) ## i Use `spec()` for the full column specifications. 7.1.3 docid 별 그루핑 데이터 세트 d를 docid 로 그루핑하여, by_doc 데이터 세트를 생성한다. # group_by creates a grouped_df (grouped data frame) class structure by_doc &lt;- group_by(d, docid) class(by_doc) ## [1] &quot;grouped_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 7.1.4 요약 정보 확인 summarise() 함수를 이용하여 by_doc 데이터 세트의 요약 정보를 확인하고, 그 결과를 변수 pat_summ에 대입한다. # Create summaries of patients by doctor pat_summ &lt;- summarise(by_doc, n_pat = n(), # number of patients longest_los = max(lengthofstay), # longest length of stay avg_age = mean(age), # average age n_stage_four = sum(cancerstage==&quot;IV&quot;) # number of stage IV patients ) ## `summarise()` ungrouping output (override with `.groups` argument) pat_summ ## # A tibble: 22 x 5 ## docid n_pat longest_los avg_age n_stage_four ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1-1 7 6 52.5 0 ## 2 1-100 9 7 86.2 0 ## 3 1-11 8 7 51.7 1 ## # ... with 19 more rows 7.1.5 다중 레벨 데이터 확인 doc_id에 의해 d와 pat_sum을 inner join 해서, 의사별 환자에 대한 다중 레벨의 데이터를 확인한다. # data at multiple levels - patients nested in doctors d %&gt;% inner_join(pat_summ) %&gt;% select(sex, age, lengthofstay, docid, avg_age, longest_los) %&gt;% head(n=3) ## Joining, by = &quot;docid&quot; ## # A tibble: 3 x 6 ## sex age lengthofstay docid avg_age longest_los ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 male 65.0 6 1-1 52.5 6 ## 2 female 53.9 6 1-1 52.5 6 ## 3 male 41.4 5 1-1 52.5 6 7.2 Untidy data 분석가에 의해 수집되지 않은 데이터의 사용은 생각보다 더 untidy data를 자주 대하게 만든다. 데이터는 다양한 방식으로 엉망이 될 수 있지만, tidyr 도구들로 타이디하게 될 수 있는 두 가지 방법에 대하여 살펴보기로 한다: 컬럼 제목들은 변수명이 아닌 값이다. 복수의 변수들이 하나의 컬럼에 저장되어 있다. untidy 데이터 세트에 대하여 살펴보고, tidyr 패키지의 pivot_longer() 함수와 pivot_wider() 함수가 어떻게 그것들을 타이디하게 만들어 주는지 살펴보기로 한다. 7.3 컬럼 제목들이 변수 명이 아니고 값들인 경우 3년간 3개의 학과로 부터 졸업생에 대한 데이터(dept1.csv)를 먼저 불러오기로 한다. 계획된 분석은 수년간 졸업자 수가 얼마나 증가했는지를 알아보는 것이다. 여기서 분석의 단위는 특정 년도(2015, 2016, 2017 등)에 있어서 특정 학과의 졸업율이다. 각각의 행은 학과별 해당 년도의 인원을 나타낸다. 7.3.1 데이터 세트 dept &lt;- read_csv(&quot;data7/dept1.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## id = col_character(), ## `2015` = col_double(), ## `2016` = col_double(), ## `2017` = col_double() ## ) dept ## # A tibble: 3 x 4 ## id `2015` `2016` `2017` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biology 207 211 259 ## 2 math 96 75 99 ## 3 physics 112 126 125 2015, 2016, 2017 등의 연도(Year)는 분석의 ‘예측 변수(predictor)’이므로 컬럼 변수가 되어야 한다. 각 3개 학과들은 3년간의 데이터를 가지고 있으므로, 매 년도마다 3개의 행을 가지고 있다. 또한, 전체 값들로 구성되는 테이블은 동일한 값들로 해당 년도에 있어서 해당 학과의 졸업자 수를 측정하고 있다. 그러므로, 해당 년도의 값들을 한 컬럼에 넣을 수 있다. 7.3.2 사용할 수 있는 함수의 종류 tidyr 패키지의 pivot_longer() 함수 tidyr 패키지의 gather() 함수 reshape2 패키지의 melt() 함수 7.3.3 pivot_longer() 함수 pivot_longer() 함수를 사용하기 위해서는, 재구성할 변수의 집합(‘컬럼의 제목’과 ‘값’)을 선택한다: 원래 테이블의 컬럼의 제목들은 새로운 테이블의 컬럼 변수가 되고 그 컬럼의 값으로 반복적으로 축적이 된다 (names_to =) 원래 테이블의 컬럼 변수에 있는 값들은 새로운 테이블의 단일 컬럼 변수의 값으로 축적이 된다(values_to = ) 이 과정을 “long 형태로 재구성(reshaping)”한다고 말한다. 7.3.3.1 pivot_longer() 함수의 구문 pivot_longer( data, cols, names_to = “name,” names_prefix = NULL, names_sep = NULL, names_pattern = NULL, names_ptypes = list(), names_transform = list(), names_repair = “check_unique,” values_to = “value,” values_drop_na = FALSE, values_ptypes = list(), values_transform = list(), … ) 주요 인수 : data : 피봇할 데이터 프레임 names_to =\"name\": 컬럼 제목을 값으로 유지할 새로운 컬럼 변수 명 (name) values_to = “value”: 데이터 값들을 저장할 새로운 컬럼 변수 명(value) 디폴트 값으로 pivot_longer 함수는 축적되는 모든 컬럼을 선택할 것이다. 그러나 새로운 names_to =에 있는 값들이 변화하지 않는 컬럼들은 축적되지 않아야 한다. 7.3.3.2 pivot_longer() 함수의 사용 예 재구성할 데이터 세트는 다음과 같다: dept ## # A tibble: 3 x 4 ## id `2015` `2016` `2017` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 biology 207 211 259 ## 2 math 96 75 99 ## 3 physics 112 126 125 새롭게 재구성되는 데이터 세트에는 ‘년도(year)’와 ‘졸업율(grad)’ 등의 2 개의 컬럼으로 표시하고 싶다. 년도는 원래 데이터의 컬럼 제목이기 때문에, names_to = 인수에 변수명을 year로 지정할 것이다. 또한 2015, 2016 그리고 2017 컬럼에 있는 졸업율의 값들은 또 다른 새로운 변수에 축적이 되어야 하는데 이를 values_to = 인수로 grad 변수를 지정하여 저장할 것이다. 학과명(id)은 연도(year)와 상관없이 변함이 없으며 따라서 축적할 필요가 없다. 여기서 c(`2015`, `2016`, `2017`)로 압축이 되어야 하는 컬럼에 대해서만 컬럼을 지정하여 재구성을 할 것이며(주의 : 문자로 시작하지 않는 컬럼 명에 대해서는 컬럼 명을 지정할 때 ` 기호가 필요), 이처럼 압축될 필요가 없는 컬럼에 대해서는 ‘- ’기호 다음에 컬럼을 지정한다. # the new column &quot;year&quot; uses the column headings as values, # the new column &quot;graduates&quot; will be the collapsed values # we do not want to collapse id dept_by_year &lt;- dept %&gt;% pivot_longer(names_to=&quot;year&quot;, values_to=&quot;grad&quot;, -id) dept_by_year ## # A tibble: 9 x 3 ## id year grad ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 biology 2015 207 ## 2 biology 2016 211 ## 3 biology 2017 259 ## # ... with 6 more rows 7.3.3.3 pivot_longer() 함수의 활용 단계 pivot_longer(names_to=\"year\", values_to=\"grad\", -id) 단계별 분석 7.3.3.3.1 [Step 1]names_to=\"year\" : 컬럼 제목들을 값으로 하는 변수(year) 지정 7.3.3.3.2 [Step 2]values_to=\"grad\" : 데이터 값들을 저장할 변수(grad) 지정 7.3.3.3.3 [Step 3] -id : 선택되지 않는 컬럼 지정. (- 컬럼명) 7.3.4 gather() 함수 gather() 함수를 사용하기 위해서는, 재구성할 변수의 집합(‘컬럼의 제목’과 ‘값’)을 선택한다: 원래 테이블의 컬럼의 제목들은 새로운 테이블의 컬럼 변수가 되고 그 컬럼의 값으로 반복적으로 축적이 된다 (key = \"year\") 원래 테이블의 컬럼 변수에 있는 값들은 새로운 테이블의 단일 컬럼 변수의 값으로 축적이 된다(value =grad ) 7.3.4.1 gather() 함수의 구문 gather( data, key = “key,” value = “value,” …, na.rm = FALSE, convert = FALSE, factor_key = FALSE ) 주요 인수 data : 피봇할 데이터 프레임 key = “key” : 컬럼 제목을 값으로 유지할 새로운 컬럼 변수 명 (key) value = “value” : 데이터 값들을 저장할 새로운 컬럼 변수 명(value) df %&gt;% gather(\"key\", \"value\", x, y, z)는 df %&gt;% pivot_longer(c(x, y, z), names_to = \"key\", values_to = \"value\")와 같다. 7.3.4.2 gather() 함수의 사용 예 앞의 예를 그대로 이용하기로 한다. 원래의 테이블인 dept에서 `2015`, `2016`, `2017` 세 개의 컬럼이 새롭게 재구성되는 데이터 세트에서는 ‘년도(year)’로 그리고 이 세 개의 컬럼에 있는 값들은 새로운 테이블의 ‘졸업율(grad)’ 컬럼의 값으로 표시하고 싶다. 이를 위해, 먼저 `2015`, `2016`, `2017` 등의 세 개의 컬럼을 선정한다. 이 세 개의 컬럼제목을 값으로 하는 새로운 테이블의 컬럼 이름을 지정한다. (key = “year”) 이 세 개의 컬럼에 저장되어 있는 값들을 저장할 새로운 테이블의 컬럼 이름을 지정한다. (value = “grad” `2015`, `2016`, `2017` 등이 원래 데이터의 컬럼 제목이기 때문에 key = 인수에 변수명을 year로 지정할 것이다. 또한 2015, 2016 그리고 2017 컬럼에 있는 졸업율의 값들은 또 다른 새로운 변수에 축적이 되어야 하는데 이를 value = 인수로 grad 변수를 지정하여 저장할 것이다. dept %&gt;% gather(`2015`, `2016`, `2017`, key = &quot;year&quot;, value = &quot;grad&quot;) ## # A tibble: 9 x 3 ## id year grad ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 biology 2015 207 ## 2 math 2015 96 ## 3 physics 2015 112 ## # ... with 6 more rows year 변수에 `2015`, `2016`, `2017` 등의 컬럼 제목이 값으로 저장됨을 알 수 있다. grad 변수에 `2015`, `2016`, `2017` 등의 컬럼 값들이 저장되어 있음을 알 수 있다. 7.3.4.3 gather() 함수의 활용 단계 dept %&gt;% gather(`2015`, `2016`, `2017`, key = “year,” value = “grad”) 선택되지 않은 나머지 컬럼(id)은 그대로 새로운 테이블에 반복적으로 저장되어 있음을 알 수 있다. 단계별 분석 이와 같은 타이디 데이터를 만들려면 해당 열을 새로운 부 변수로 수집(gather)해야 한다. 이 작업은 다음의 세 단계로 이루어진다. 7.3.4.3.1 [Step 1] gather(`2015`, `2016`, `2017`, : 컬럼 제목들 선택 2015, 2016, 2017 등 값으로 되어 있는 컬럼 제목 세 개를 선택한다. 이 때, 선택된 컬럼 제목을 (``, 역 따옴표)안에 기입한다. 7.3.4.3.2 [Step 2] key = \"year\" : 새로운 테이블의 컬럼 명 지정 선택된 세 개의 컬럼이 새로운 테이블에 저장될 컬럼 명을 지정한다. 여기서는 year로 정하고 있다. 7.3.4.3.3 [Step 3] value = \"grad\" : 새로운 테이블의 컬럼 명 지정 선택된 세 개의 컬럼이 새로운 테이블에 저장될 컬럼 명을 지정한다. 여기서는 year로 정하고 있다. 7.3.5 melt() 함수 melt() 함수를 사용하기 위해서는, 재구성할 변수의 집합(‘컬럼의 제목’과 ‘값’)을 선택하는 것이 아니고 원래의 테이블에서 사용하고 있는 컬럼 중 새로운 테이블에서도 계속 사용할 컬럼을 지정해 주면 된다. id 변수를 지정한다. (id.vars = “id”) 원래 테이블의 컬럼의 제목을 저장할 변수를 지정한다(variable.name = year). 원래 테이블의 컬럼 변수에 있는 값들을 저장한 새로운 테이블의 컬럼 변수의 이름을 지정한다(value.name = \"grad\") 7.3.5.1 reshape2 패키지의 설치 melt() 함수를 사용하기 위해 reshape2 패키지를 설치한다. # install.packages(&quot;reshape2&quot;) library(reshape2) 7.3.5.2 melt() 함수의 구문 melt( data, id.vars, measure.vars, variable.name = “variable,” …, na.rm = FALSE, value.name = “value,” factorsAsStrings = TRUE ) 주요 인수 data : 재구성할 데이터 프레임 id.vars : id 변수들의 벡터 measure.vars : 측정된 변수들의 벡터. 정수(변수의 위치) 또는 문자열(변수명). 빈 칸이면 id.vars 가 아닌 변수를 사용. variable.name = “variable” : 측정된 변수 명을 저장하는데 사용하는 변수의 이름. 디폴트 값은 “variable” ...: 추가적 인수들 na.rm : NA 값을 데이터 세트에서 제거할 지 여부 value.name =\"value\" : 값들을 저장하기 위해 사용될 변수의 이름. 디폴트 값은 “value” factorsAsStrings : 측정 변수로서 멜트될 때 factor 변수를 문자형으로 변환할 지 여부. 7.3.5.3 melt() 함수의 사용 예 dept %&gt;% melt(id.vars = &quot;id&quot;, variable.name = &quot;year&quot;, value.name = &quot;grad&quot;) ## id year grad ## 1 biology 2015 207 ## 2 math 2015 96 ## 3 physics 2015 112 ## 4 biology 2016 211 ## 5 math 2016 75 ## 6 physics 2016 126 ## 7 biology 2017 259 ## 8 math 2017 99 ## 9 physics 2017 125 단계별 분석 7.3.5.3.1 [Step 1] id.vars = “id” : id 컬럼을 지정한다. dept 테이블의 id.vars 컬럼으로 id 컬럼을 지정한다. 7.3.5.3.2 [Step 2] variable.name = “year” : id 컬럼 이외의 컬럼 이름(variable)을 값으로 저장할 변수 지정 dept 테이블의 id 컬럼 이외의 2015, 2016, 2017 컬럼 이름을 값으로 재구성할 컬럼의 이름을 year로 지정한다. 7.3.5.3.3 [Step 3] value.name = “grad” : id 컬럼 이외의 컬럼 값(value)을 저장할 변수 지정 dept 테이블의 id 컬럼 이외의 2015, 2016, 2017 컬럼의 행의 값을 저장할 컬럼의 이름을 grad로 지정한다. 7.4 하나의 컬럼에 복수 개의 변수들이 있는 경우 컬럼들은 한 변수를 나타내는 값들을 담고 있어야 하지만, 종종 복수 개의 변수들이 같은 컬럼에 저장되는 데이터 세트를 종종 접할 때가 있다. 나이(age), 길이(length), 몸무게(weight) 등의 관측치를 한 개의 컬럼에 저장한 곤충(worms)에 대한 데이터 세트를 살펴보기로 한다. 7.4.1 데이터 세트 worms &lt;- read_csv(&quot;data7/worms.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## worm = col_double(), ## feature = col_character(), ## measure = col_double() ## ) worms ## # A tibble: 9 x 3 ## worm feature measure ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 age 5 ## 2 1 length 3.2 ## 3 1 weight 4.1 ## # ... with 6 more rows 곤충에 대한 분석의 단위로 나이(age)가 길이(length)와 몸무게(weight)를 예측할 수 있는지 알고 싶다. 따라서 각 행은 한 마리의 곤충에 대한 데이터이다. 여기서는 특성(feature) 컬럼에 저장되어 있는 3 종류의 데이터 값(age,length, weight)들을 세 개의 컬럼(age,length, weight)으로 확장하고자 한다. 7.4.2 사용할 수 있는 함수의 종류 tidyr 패키지의 pivot_wider() 함수 tidyr 패키지의 spread() 함수 reshape2 패키지의 dcast() 함수 7.4.3 pivot_wider() 함수 이 문제는 컬럼의 제목들이 실제로 변수의 값이 되어야 할 문제를 pivot_longer() 함수로 해결하였던 앞의 문제와 반대가 되는 상황이다. 여기서는 age, length, 그리고 weight 값들을 컬럼 제목으로 변환하고자 한다. 이러한 반대가 되는 절차에서는 names_from=에 컬럼 제목으로 전환될 컬럼 변수(기존 데이터의 feature 컬럼)를 지정해주고, values_from=에는 새로운 컬럼으로 확장될 값이 저장되어 있는 컬럼(measure)을 지정해 준다. 이 과정을 “wide 형태로 재구성”한다고 말한다. 7.4.3.1 pivot_wider() 함수의 구문 pivot_wider( data, id_cols = NULL, names_from = name, **names_prefix = \"“, names_sep =”_“, names_glue = NULL, names_sort = FALSE, names_repair =”check_unique\", values_from = value, values_fill = NULL, values_fn = NULL, … )** 주요 인수 : data : 데이터 프레임 id_cols = NULL : names_from=: 컬럼 제목으로 확장해야 할 값을 갖고 있는 컬럼 변수 명 values_from=: 확장된 컬럼의 값들로 채워질 값을 저장하고 있는 컬럼 변수 명 7.4.3.2 pivot_wider() 함수의 사용 예 여기에서, 새롭게 만들어지는 테이블의 컬럼 제목의 일부로 feature 변수에 저장되어 있는 값들을 사용할 것이다. 따라서 이 feature 변수를 names_from=에 지정할 것이다. 또한, measure 컬럼에 있는 값들을 새롭게 만들어진 컬럼의 행으로 채울 것이다. 따라서 measure 변수를 values_from=의 값으로 지정할 것이다. by_worm &lt;- worms %&gt;% pivot_wider(names_from=feature, values_from=measure) by_worm ## # A tibble: 3 x 4 ## worm age length weight ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5 3.2 4.1 ## 2 2 4 2.6 3.5 ## 3 3 5 3.6 5.5 원 테이블(worm)의 feature 컬럼이 새로운 테이블(by_worm)의 age, length 그리고 weight 컬럼으로 확장되었다. 이 확장된 컬럼들의 값들은 원 테이블의 measure 컬럼의 값들로 채워졌음을 알 수 있다. 7.4.3.3 pivot_wider() 함수의 활용 단계 pivot_wider(names_from=feature, values_from=measure) 7.4.4 spread() 함수 spread() 함수는 gather() 함수의 역함수로서 관측변수를 다시 되돌린다. 그리고 나면 데이터 세트를 ‘wide’ 형식으로 펼치게 된다. 앞의 예에서 사용한 long 형태의 worms 데이터 세트를 wide 형태로 펼쳐 보기로 한다. 7.4.4.1 spread() 함수의 구문 spread(data, key, value, fill = NA, convert = FALSE, drop = TRUE, sep = NULL) 주요 인수 data : spread 할 데이터 세트 key : 컬럼 명이나 위치 value : 값들의 컬럼 명이나 위치 df %&gt;% spread(key, value)는 df %&gt;% pivot_wider(names_from = key, values_from = value)와 같다. 7.4.4.2 spread() 함수의 사용 예 worms %&gt;% spread(key=feature, value=measure) ## # A tibble: 3 x 4 ## worm age length weight ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5 3.2 4.1 ## 2 2 4 2.6 3.5 ## 3 3 5 3.6 5.5 7.4.4.3 spread() 함수의 활용 단계 7.4.5 dcast() 함수 dcast() 함수는 melt() 함수의 역함수로서 관측변수를 다시 되돌린다. 그리고 나면 데이터 세트를 ‘wide’ 형식으로 펼치게 된다. 앞의 예에서 사용한 long 형태의 worms 데이터 세트를 wide 형태로 펼쳐 보기로 한다. 7.4.5.1 dcast() 함수의 구문 dcast( data, formula, fun.aggregate = NULL, …, margins = NULL, subset = NULL, fill = NULL, drop = TRUE, value.var = guess_value(data) ) 주요 인수 data : melt 되어 있는 데이터 프레임 formula : 재구성 공식 value.var : 값을 저장하고 있는 컬럼 명 7.4.5.2 dcast() 함수의 사용 예 worms %&gt;% dcast(worm ~ feature, value.var=&quot;measure&quot;) ## worm age length weight ## 1 1 5 3.2 4.1 ## 2 2 4 2.6 3.5 ## 3 3 5 3.6 5.5 # or worms %&gt;% dcast(worm ~ ...) ## Using measure as value column: use value.var to override. ## worm age length weight ## 1 1 5 3.2 4.1 ## 2 2 4 2.6 3.5 ## 3 3 5 3.6 5.5 7.4.5.3 dcast() 함수의 활용 단계 7.4.5.4 dcast() 함수를 이용한 aggregation 7.4.5.4.1 Chickweight 데이터 세트 Chickweight 데이터 세트를 보면, 578개의 행과 Weight, Time, Chick, Diet라는 4개의 열(Column)로 이루어져 있다. (? datasets::ChickWeight로 자세한 내용을 확인할 수 있다.) Weight : 각 Chick(병아리)들의 무게 Time : 무게를 잴 때의 병아리 나이(부화한 후의 날 수) 1일~21일 Chick : 1~50번까지의 병아리 번호 Diet : 병아리에게 투여한 모이 종류 1~4가지 #Chick weight example head(ChickWeight) ## Grouped Data: weight ~ Time | Chick ## weight Time Chick Diet ## 1 42 0 1 1 ## 2 51 2 1 1 ## 3 59 4 1 1 ## 4 64 6 1 1 ## 5 76 8 1 1 ## 6 93 10 1 1 str(ChickWeight) ## Classes &#39;nfnGroupedData&#39;, &#39;nfGroupedData&#39;, &#39;groupedData&#39; and &#39;data.frame&#39;: 578 obs. of 4 variables: ## $ weight: num 42 51 59 64 76 93 106 125 149 171 ... ## $ Time : num 0 2 4 6 8 10 12 14 16 18 ... ## $ Chick : Ord.factor w/ 50 levels &quot;18&quot;&lt;&quot;16&quot;&lt;&quot;15&quot;&lt;..: 15 15 15 15 15 15 15 15 15 15 ... ## $ Diet : Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## - attr(*, &quot;formula&quot;)=Class &#39;formula&#39; language weight ~ Time | Chick ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;outer&quot;)=Class &#39;formula&#39; language ~Diet ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_EmptyEnv&gt; ## - attr(*, &quot;labels&quot;)=List of 2 ## ..$ x: chr &quot;Time&quot; ## ..$ y: chr &quot;Body weight&quot; ## - attr(*, &quot;units&quot;)=List of 2 ## ..$ x: chr &quot;(days)&quot; ## ..$ y: chr &quot;(gm)&quot; 7.4.5.5 melt() 함수의 사용 names(ChickWeight) &lt;- tolower(names(ChickWeight)) chick_m &lt;- melt(ChickWeight, id=2:4, na.rm=TRUE) head(chick_m) ## time chick diet variable value ## 1 0 1 1 weight 42 ## 2 2 1 1 weight 51 ## 3 4 1 1 weight 59 ## 4 6 1 1 weight 64 ## 5 8 1 1 weight 76 ## 6 10 1 1 weight 93 tail(chick_m) ## time chick diet variable value ## 573 12 50 4 weight 155 ## 574 14 50 4 weight 175 ## 575 16 50 4 weight 205 ## 576 18 50 4 weight 234 ## 577 20 50 4 weight 264 ## 578 21 50 4 weight 264 7.4.5.6 dcast() 함수의 사용 dcast(chick_m, time ~ variable, mean) # average effect of time ## time weight ## 1 0 41.06000 ## 2 2 49.22000 ## 3 4 59.95918 ## 4 6 74.30612 ## 5 8 91.24490 ## 6 10 107.83673 ## 7 12 129.24490 ## 8 14 143.81250 ## 9 16 168.08511 ## 10 18 190.19149 ## 11 20 209.71739 ## 12 21 218.68889 dcast(chick_m, diet ~ variable, mean) # average effect of diet ## diet weight ## 1 1 102.6455 ## 2 2 122.6167 ## 3 3 142.9500 ## 4 4 135.2627 acast(chick_m, diet ~ time, mean) # average effect of diet &amp; time ## 0 2 4 6 8 10 12 14 16 ## 1 41.4 47.25 56.47368 66.78947 79.68421 93.05263 108.5263 123.3889 144.6471 ## 2 40.7 49.40 59.80000 75.40000 91.70000 108.50000 131.3000 141.9000 164.7000 ## 3 40.8 50.40 62.20000 77.90000 98.40000 117.10000 144.4000 164.5000 197.4000 ## 4 41.0 51.80 64.50000 83.90000 105.60000 126.00000 151.4000 161.8000 182.0000 ## 18 20 21 ## 1 158.9412 170.4118 177.7500 ## 2 187.7000 205.6000 214.7000 ## 3 233.1000 258.9000 270.3000 ## 4 202.9000 233.8889 238.5556 dcast(chick_m, diet ~ time, mean) ## diet 0 2 4 6 8 10 12 14 ## 1 1 41.4 47.25 56.47368 66.78947 79.68421 93.05263 108.5263 123.3889 ## 2 2 40.7 49.40 59.80000 75.40000 91.70000 108.50000 131.3000 141.9000 ## 3 3 40.8 50.40 62.20000 77.90000 98.40000 117.10000 144.4000 164.5000 ## 4 4 41.0 51.80 64.50000 83.90000 105.60000 126.00000 151.4000 161.8000 ## 16 18 20 21 ## 1 144.6471 158.9412 170.4118 177.7500 ## 2 164.7000 187.7000 205.6000 214.7000 ## 3 197.4000 233.1000 258.9000 270.3000 ## 4 182.0000 202.9000 233.8889 238.5556 7.5 하나의 셀에 저장된 여러 변수 또는 여러 셀에 흩어져 있는 한 변수 데이터 세트를 untidy하게 만드는 두 개의 다른 이슈로는 1) 동일한 셀에 여러 개 변수가 저장되어 있는 경우와, 2) 한 변수가 여러 셀에 흩어져 저장되어 있는 경우이다. tidyr 패키지에 내장되어 있는 table5 데이터는 이 두 문제를 동시에 보여주고 있다. 7.5.1 데이터 세트 table5 ## # A tibble: 6 x 4 ## country century year rate ## * &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 19 99 745/19987071 ## 2 Afghanistan 20 00 2666/20595360 ## 3 Brazil 19 99 37737/172006362 ## # ... with 3 more rows rate 변수는 실제 cases를populations으로 나눈 식으로 표시되어, 두 개의 변수를 담고 있다. 또한 century와 year 라는 두 개의 컬럼으로 분리되어 있는 부분은 사실 year 변수로 통합될 수 있다. Data Wrangling with dplyr and tidyr Data Wrangling with dplyr and tidyr 7.6 separate() 함수와 unite() 함수 컬럼의 분리와 결합을 위한 separate() 함수와 unite() 함수는 서로 보완적인다. 7.6.1 separate() 함수 separate() : 여러 개의 컬럼으로 분리하기 위해 한 컬럼에 있는 각 셀을 분리한다. separate(data, col, into, sep=, remove = TRUE) data : 데이터 프레임 col: 분리할 컬럼 명 into: 새로운 문자형 변수 컬럼 명 sep= : 컬럼 사이의 분리 문자 remove= : 데이터 프레임에서 원 컬럼의 제거 여부, 디폴트 값은 TRUE 7.6.2 unite() 함수 unite(): 한 개의 컬럼으로 결합하기 위해 여러 컬럼에 있는 셀의 값들을 묶어 준다. unite(data, col, … , sep = “_,” remove = TRUE) col: 결합 컬럼이 될 새로운 컬럼의 이름 ... : 결합될 컬럼의 목록 sep = : 분리자, 디폴트 값은 “_” 7.6.3 separate() 함수와 unite() 함수의 예 table5 %&gt;% separate(col=rate, into=c(&quot;cases&quot;, &quot;population&quot;), sep=&quot;/&quot;) %&gt;% unite(col=&quot;year&quot;, century, year, sep=&quot;&quot;) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## # ... with 3 more rows table5에 있던 century와 year 컬럼이 새로운 테이블의 year 컬럼으로 합쳐졌다. table5에 있던 rate 컬럼이 cases 컬럼과 population 컬럼으로 분리되었다. 7.7 tidyverse 참조표 RStudio의 도움말(Help) 메뉴에 tidyverse 패키지가 제공하는 다양한 도구의 활용 방법 및 구문법을 요약해 놓은 “Cheatsheets”에 대한 서브 메뉴가 있다. dplyr과 tidyr의 참조표 와 별도의 ggplot2의 참조표를 발견할 수 있다. img References tidyr 패키지 사용법 : cheat_sheet : data import cheat_sheet : data wrangling 5 tidy data 개념과 dplyr+tidyr로 데이터 다루기 tidyr 연습문제 An Introduction to reshape2 tidyr 연습문제 - 예제가 좋음 (Python의 Pandas로 처리함) "],["dates.html", "Chapter 8 Dates 8.1 R에서의 날짜 데이터 8.2 lubridate 패키지 8.3 날짜-시간 변수 8.4 Date 변수에서 정보 추출하기 8.5 날짜-시간(POSIXct) 변수에서 정보 추출하기 8.6 날짜-시간 산술연산을 위한 두 종류의 함수", " Chapter 8 Dates library(tidyverse) 8.1 R에서의 날짜 데이터 R에 데이터 세트에 있는 날짜 데이터가 불려오기 전에는 보통 날짜 데이터들은 문자(문자열) 값들을 가진 컬럼에 저장이 된다. 그러나 날짜 데이터들은 원래 수치 데이터이며, 문자열로 저장이 되면 아주 중요한 정보를 잃게 된다. 예를 들어, “2018년 3월 5일”에서 하루가 경과된 날을 계산하려면 다음과 같이 하면되는데, 그 결과를 에러가 날 것이다: # string dates have no numeric value, so this errors &quot;2018-03-05&quot; + 1 ## Error in &quot;2018-03-05&quot; + 1: 이항연산자에 수치가 아닌 인수입니다 ## Error in &quot;2018-03-05&quot; + 1: non-numeric argument to binary operator R에서는 이처럼 문자열로 저장된 날짜 데이터는 R의 Date 클래스로 변환해야 한다. 이 Date 클래스는 수치 데이터로 날짜를 보관하며, R에서 제공하는 다양한 날짜 관련 함수들을 활용할 수 있게 해 준다. 일단 Date 클래스로 변환이 되면, , 날짜에 대한 수치 값은 January 1, 1970 (1970-01-01) 이후의 날짜 수를 나타낸다. 8.1.1 as.Date() 함수 R의 base 패키지는 문자열 형태의 날짜 데이터를 Date 클래스로 변환할 수 있는 as.Date() 함수를 제공한다. 그러나 사용하는데에 두 가지의 디폴트 형태(자세한 날짜 형태에 대해서는 ?srtptime을 참고바람)로 날짜 데이터가 저장되어 있지 않다면 사용하는데 많은 어려움을 겪을 수 있다. 다음의 예를 살펴보기로 한다. # as.Date only accepts a couple of formats by default # good as.Date(&quot;2015-02-14&quot;) ## [1] &quot;2015-02-14&quot; # bad as.Date(&quot;02/14/2014&quot;) ## Error in charToDate(x): character string is not in a standard unambiguous format # specify a format to fix as.Date(&quot;02/14/2014&quot;, format=&quot;%m/%d/%Y&quot;) ## [1] &quot;2014-02-14&quot; “2015-2-14” 형태의 문자열에 대해서는 Date 클래스로 변환해 준다. “02/14/2014” 형태의 문자열은 Date 클래스로 변환하지 못한다. “02/14/2014” 형태의 문자열을 Date 클래스로 변환하기 위해서는 format = 인수를 이용하여 형태를 맞춰 줘야 한다. 일단 날짜 데이터가 Date 클래스로 변환이 되면, 날짜 데이터에 대한 산술연산을 수행할 수 있다. a &lt;- as.Date(&quot;1971-01-01&quot;) class(a) ## [1] &quot;Date&quot; # days since 1970-01-01 as.numeric(a) ## [1] 365 # date arithmetic a &lt;- as.Date(&quot;1970/12/31&quot;) a + 2 ## [1] &quot;1971-01-02&quot; a 변수는 Date 클래스가 되었다. 그러면서 또한 a 변수는 수치형 데이터이다. 날짜의 산술연산이 가능하다. 그 결과는 경과된 날짜 수(1 days)가 된다. a + 2는 결국 2일이 경과된 날짜를 확인해 준다. 이제 좀더 쉽게 문자열을 다양한 형태의 Date 클래스로 변환하는 방법에 대하여 살펴 보기로 한다!!! 8.2 lubridate 패키지 tidyverse 패키지는 문자열 날짜 데이터를 더 쉽게 Date 형식으로 변환할 수 있도록 도와주고 또 그러한 날짜형 데이터를 처리하기 위한 함수를 제공하는 lubridate 라는 재미있는 이름을 가진 패키지를 제공하고 있다. lubridate 패키지가 제공하는 Date 변환 함수는 아주 다양한 날짜 형식을 받아들이면서도, 그러한 형식에 대한 사양을 기억할 필요를 없애준다. 단지 y, m, 그리고 d 등의 문자를 취하고, 날짜 컬럼에 데이터를 저장할 때 이러한 문자 각각에 대하여 ‘년,’ ‘월,’ 그리고 ‘일’ 등의 순서를 메겨 준다. 그러한 순서가 해당 컬럼을 Date 로 변환하는 함수의 이름을 생성한다(예를 들어, ymd() 함수, mdy() 함수, dmy() 함수 등). lubridate 패키지는 tidyverse 패키지를 설치할 때 같이 설치는 되지만, library(tidyverse)를 불러올 때 자동으로 불러와 지지 않는다. 따라서, 이제 이 패키지를 불러온다. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:hms&#39;: ## ## hms ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union 8.2.1 lubridate 패키지의 활용 lubridate 함수의 유연성을 보여주기 위해 먼저 다양한 날짜 형식을 가지고 있는 데이터 세트를 불어오기로 한다. d &lt;- read_csv(&quot;data8/dates.csv&quot;) ## ## -- Column specification -------------------------------------------------------- ## cols( ## fmt1 = col_character(), ## fmt2 = col_character(), ## fmt3 = col_date(format = &quot;&quot;), ## fmt4 = col_double(), ## decision_time = col_character() ## ) d ## # A tibble: 3 x 5 ## fmt1 fmt2 fmt3 fmt4 decision_time ## &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 01/15/89 December 8, 2015 2015-02-27 20090101 Approved 10-10-15 07:15:55 ## 2 02/13/92 January 22, 2012 2016-11-15 20080819 Denied 09-27-11 14:57:23 ## 3 03/15/84 March 3, 2010 2017-12-25 20071011 Approved 04-24-15 02:03:03 현재, 앞의 4개 컬럼들이 chr, chr, date, 그리고 dbl 형식으로 저장이 되어 있다. 세 번째 컬럼은 read_csv() 함수로 날짜임을 알려 주는 특정한 형식으로 인해 , 사실상 read_csv() 함수에 의해 Date 형식으로 인식이 되어 있다. 첫 두 개의 컬럼은 월-일-년의 형식을 사용하고 있지만, 세 번째와 네 번째 컬럼은 년-월-일 형식을 사용하고 있다. 다섯 번째 컬럼의 decision_time은 ‘날짜-시간’ 값을 포함하고 있다. 따라서, mdy() 함수와 ymd() 함수를 사용해 본다. 그 유연성이 놀라울 따름이다. # no format specifications needed # just ordering y,m, and d dates &lt;- data.frame(f1=mdy(d$fmt1), f2=mdy(d$fmt2), f3=ymd(d$fmt3), f4=ymd(d$fmt4)) dates ## f1 f2 f3 f4 ## 1 1989-01-15 2015-08-20 2015-02-27 2009-01-01 ## 2 1992-02-13 2012-02-02 2016-11-15 2008-08-19 ## 3 1984-03-15 2010-03-20 2017-12-25 2007-10-11 str(dates) ## &#39;data.frame&#39;: 3 obs. of 4 variables: ## $ f1: Date, format: &quot;1989-01-15&quot; &quot;1992-02-13&quot; ... ## $ f2: Date, format: &quot;2015-08-20&quot; &quot;2012-02-02&quot; ... ## $ f3: Date, format: &quot;2015-02-27&quot; &quot;2016-11-15&quot; ... ## $ f4: Date, format: &quot;2009-01-01&quot; &quot;2008-08-19&quot; ... 이제 네 개의 컬럼 모두가 같은 형식의 Date 클래스로 변환되었음을 알 수 있다. 8.3 날짜-시간 변수 만일 날짜 컬럼이 시간 정보(예, 날짜-시간)를 추가적으로 포함하고 있다면, 문자열을 POSIXct 클래스로 변환하기 위해 함수 이름의 y, m, d에 하나 이상의 h, m, s 등을 추가할 수 있다. POSIXct 클래스는 1970년 초를 기준으로 이후 경과된 초에 대한 수치를 나타내는 숫자로 날짜-시간 변수를 저장한다. dates 데이터 세트의 다섯 번째 컬럼인 decision_time은 날짜-시간 변수이다(물론 lubridate() 함수가 무시할 Approved/Denied 문자열을 데이터의 앞 부분에 포함하고 있다). 구체적으로 날짜-시간은 월, 일, 년, 시, 분, 초 등으로 기록되어 있기 때문에, mdy_hms() 함수를 사용할 것이다: # month day year hour minute second mdy_hms(d$decision_time) ## [1] &quot;2015-10-10 07:15:55 UTC&quot; &quot;2011-09-27 14:57:23 UTC&quot; ## [3] &quot;2015-04-24 02:03:03 UTC&quot; # POSIXct is a standard way of representing calendar time class(mdy_hms(d$decision_time)) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; 표준 시간대(“time zone” standard)의 디폴트 값으로 UTC (Coordinated Universal Time)가 사용되었다. 시간대를 설정하기 위해서는 tz = 인수를 사용한다. 유효한 시간대 사양 목록을 확인하려면 OlsonNames()함수를 시행하기 바란다. # we&#39;ll use this for our dates variable dates$decision_time &lt;- mdy_hms(d$decision_time, tz=&quot;US/Pacific&quot;) dates$decision_time ## [1] &quot;2015-10-10 07:15:55 PDT&quot; &quot;2011-09-27 14:57:23 PDT&quot; ## [3] &quot;2015-04-24 02:03:03 PDT&quot; # first 20 valid time zones head(OlsonNames(), n=20) ## [1] &quot;Africa/Abidjan&quot; &quot;Africa/Accra&quot; &quot;Africa/Addis_Ababa&quot; ## [4] &quot;Africa/Algiers&quot; &quot;Africa/Asmara&quot; &quot;Africa/Asmera&quot; ## [7] &quot;Africa/Bamako&quot; &quot;Africa/Bangui&quot; &quot;Africa/Banjul&quot; ## [10] &quot;Africa/Bissau&quot; &quot;Africa/Blantyre&quot; &quot;Africa/Brazzaville&quot; ## [13] &quot;Africa/Bujumbura&quot; &quot;Africa/Cairo&quot; &quot;Africa/Casablanca&quot; ## [16] &quot;Africa/Ceuta&quot; &quot;Africa/Conakry&quot; &quot;Africa/Dakar&quot; ## [19] &quot;Africa/Dar_es_Salaam&quot; &quot;Africa/Djibouti&quot; 8.4 Date 변수에서 정보 추출하기 8.4.1 관련 함수 lubridate 패키지는 Date 변수로부터 특정 정보를 추출할 수 있게 해 주는 다음과 같은 함수들을 제공한다: day(): 월의 날짜 wday(): 평일 yday(): 년의 날짜 month(): 년의 월 year(): 년 8.4.2 Date 변수의 정보 추출 예 # we&#39;ll use the first column of our dates dataset dates$f1 ## [1] &quot;1989-01-15&quot; &quot;1992-02-13&quot; &quot;1984-03-15&quot; # day of the month day(dates$f1) ## [1] 15 13 15 # day of the year yday(dates$f1) ## [1] 15 44 75 dates$f1 : dates 데이터 세트의 f1 컬럼에 있는 날짜 데이터 확인 day(dates$f1) : dates 데이터 세트의 f1 컬럼에 있는 날짜 데이터의 해당 월의 날짜 yday(dates$f1) : dates 데이터 세트의 f1 컬럼에 있는 날짜 데이터의 해당 년도의 날짜 추가적인 예: # weekday as numbers wday(dates$f1) ## [1] 1 5 5 # weekday with labels wday(dates$f1, label=TRUE) ## [1] 일 목 목 ## Levels: 일 &lt; 월 &lt; 화 &lt; 수 &lt; 목 &lt; 금 &lt; 토 # month of the year month(dates$f1) ## [1] 1 2 3 wday(dates$f1) : 해당 주의 날짜 (일=1, 월=2, 화=3, 수=4, 목=5, 금=6, 토=7) wday(dates$f1, label=TRUE) : 해당 주의 요일 month(dates$f1): 해당 월 8.5 날짜-시간(POSIXct) 변수에서 정보 추출하기 8.5.1 관련 함수 lubridate 패키지는 또한 POSIXct 날짜-시간 변수에서 시간 정보를 추출할 수 있게 해 주는 다음과 같은 함수를 제공한다: hour() minute() second() 8.5.2 POSIXct 변수에서 정보 추출 예 # break up the time variable decision time # display as a data.frame with 4 columns with(dates, ## with() tells R to look for variables in object &quot;dates&quot; data.frame(time=decision_time, h=hour(decision_time), m=minute(decision_time), s=second(decision_time))) ## time h m s ## 1 2015-10-10 07:15:55 7 15 55 ## 2 2011-09-27 14:57:23 14 57 23 ## 3 2015-04-24 02:03:03 2 3 3 8.6 날짜-시간 산술연산을 위한 두 종류의 함수 날짜 변수에 시간을 더하거나 빼야할 경우를 위해 lubridate 패키지는 두 종류의 함수들을 제공한다. 한 종류의 함수들은 “직관적인” 결과를 가져오는데, 윤년(leap year) 같은 관습은 무시한다. 이러한 종류의 함수로는 seconds(), minutes(), hours(), days(), weeks(), years() 등이 있다. 또 다른 종류의 함수들은 그러한 관습을 고수하는데, 앞의 함수들의 이름에 d를 추가되어 있는 함수들로서 dseconds(), dminutes(), dhours(), ddays(), dweeks(), dyears() 등이 있다. 직관적인 날짜-시간 연산의 예: # 2016 is a leap year # the intuitive result years(2) ## [1] &quot;2y 0m 0d 0H 0M 0S&quot; ymd(&quot;2015-02-14&quot;) + years(2) ## [1] &quot;2017-02-14&quot; years(2) : “y m d H M S” 형식으로 날짜 시간 데이터를 처리한다. ymd(\"2015-02-14\") + years(2) : 2015-2-14에 2y를 더한 연산으로 그 결과는 직관적으로 2017-2-14가 된다. 정확한 날짜-시간 연산의 예 # the exact result dyears(2) ## [1] &quot;63115200s (~2 years)&quot; ymd(&quot;2015-02-14&quot;) + dyears(2) ## [1] &quot;2017-02-13 12:00:00 UTC&quot; dyears(2) : s(초) 형식으로 날짜-시간 데이터를 연산한다. 결과는 63115200s (~2 years) ymd(\"2015-02-14\") + dyears(2) : 2016년은 윤년이어서 최종 결과는 2017-02-13 12:00:00 UTC가 되었다. "],["dates-and-time.html", "Chapter 9 Dates and Times 9.1 들어가기 9.2 날짜/시간 생성하기 9.3 데이트-타임형 구성요소 9.4 시간 범위 9.5 시간대 References", " Chapter 9 Dates and Times 9.1 들어가기 이 장에서는 R 에서 날짜와 시간을 다루는 법을 볼 것이다. 언뜻 생각하면 날짜와 시간은 간단해 보인다. 일상 생활에서 늘 사용하고 있으며 복잡할 것이 없을 것 같다. 그러나 날짜와 시간에 대해 배울수록 더 복잡해 보일 것이다. 몸풀기로, 간단해 보이는 다음 세 문제를 보자. 1년은 항상 365일인가? 1일은 항상 24시인가? 1분은 항상 60초인가? 1년이 항상 365일은 아니라는 걸 대부분 알고 있을 것이다. 하지만 한 해가 윤년인지를 결정하는 규칙을 완벽하게 알고 있는가?(세 파트가 있다.) 세계 많은 곳에서 일광절약제(daylight saving time, DST)를 이용하고 있고, 따라서 어떤 날은 23시이고, 다른 날은 25시라는 것을 기억하는 사람도 있을 것이다. 지구 자전이 점차 느려지기 때문에 윤초가 추가되어 가끔씩 1분이 61초가 된다는 것을 아는 사람은 많지 않을 것이다. 날짜와 시간은 두 가지 물리 현상(지구 자전과 공전)과 월, 시간대, 일광절약제를 포함한 많은 지정학적 현상을 조화시켜야 하기 때문에 쉬운 문제가 아니다. 이 장에서는 날짜와 시간에 대해 세부 사항을 속속들이 배우지는 않겠지만 일반적인 데이터 분석 문제에 이용할 수 있는 기술들을 탄탄히 배울 것이다. 9.1.1 준비하기 이 장에서는 lubridate 패키지를 주로 살펴볼 것인데, 이 패키지를 쓰면 R에서 날짜와 시간을 다룰 수 있다. lubridate 는 날짜/시간 작업을 할 때만 필요하기 때문에, 핵심 tidyverse 에 포함되어 있지 않다. 실습데이터로 이용할 nycflights13 도 필요하다. library(tidyverse) library(lubridate) library(nycflights13) 9.2 날짜/시간 생성하기 시각을 나타내는 날짜/시간의 세 가지 유형이 있다. 날짜형 (date) : 날짜. 티블에서 &lt;date&gt; 로 출력한다. 시간형 (time) : 하루 중 시간. 티블에서 &lt;time&gt; 으로 출력한다. 날짜-시간형 (date-time) : 날짜 더하기 시간. 시점을 고유하게 (일반적으로 가장 가까운 초로) 식별한다. 티블에서 &lt;dttm&gt; 으로 출력한다. R의 다른 부분에서는 POSIXct 라고 부른다. R에는 시간 저장을 위한 네이티브 클래스가 없기 때문에 이 장에서는 데이트형과 데이트-타임형에만 집중할 것이다. 네이티브 클래스가 필요하다면 hms 패키지를 이용해보라. 사용자 요구를 충족하는 데이터 유형 중, 가능한 한 가장 간단한 것을 사용해야 한다. 즉 데이트-타임형 대신 데이트형을 써도 된다면 그래야 한다는 말이다. 데이트-타임형은 시간대를 다루기 때문에 훨씬 더 복잡한데 이 장의 끝에서 살펴볼 것이다. 현재 날짜 또는 데이트-타임을 얻으려면 today() 또는 now() 를 사용하면 된다. (Sys.date()) today() ## [1] &quot;2020-12-06&quot; now() ## [1] &quot;2020-12-06 22:12:44 KST&quot; 이 외에 날짜/시간을 생성하는 세 가지 방법이 있다. 문자열로부터 개별 데이트-타임형 구성요소로부터 기존의 날짜/시간 객체로부터 이들의 작동 방식을 살펴보자. 9.2.1 문자열에서 생성 날짜/시간 데이터는 종종 문자열로 주어진다. 우리는 이미 date-times 에서 문자열을 데이트-타임형으로 파싱하는 법을 보았다. 다른 방법은 lubridate 에서 제공하는 도우미를 사용하는 것이다. 구성요소의 순서만 지정하면 자동으로 형식을 맞춘다. 도우미를 이용하는 법은 주어진 날짜에 나타난 연, 월, 일의 순서를 확인한 후, “y”, “m”, “d” 를 같은 순서로 배치하는 것이다. 이것이 바로 lubridate 함수의 이름이 되고 주어진 날짜를 파싱한다. 예를 들면 ymd(&quot;2017-01-31&quot;) ## [1] &quot;2017-01-31&quot; mdy(&quot;January 31st, 2017&quot;) ## [1] &quot;2017-03-01&quot; dmy(&quot;31-Jan-2017&quot;) ## [1] &quot;2017-01-31&quot; 이 함수들은 따옴표로 둘러싸이지 않은 숫자도 받아들인다. 이는 단일 날짜/시간 객체를 생성하는 방법들 중 가장 간결한 방법인데, 날짜/시간 데이터를 필터링할 때 사용할 수 있다. ymd() 는 간결하고 모호하지 않다. ymd(20170131) ## [1] &quot;2017-01-31&quot; ymd() 와 같은 함수들은 데이트형을 생성한다. 데이트-타임형을 생성하려면 파싱 함수 이름에 언더스코어와 “h,” “m,” “s” 중 하나 이상을 추가해야 한다. ymd_hms(&quot;2017-01-31 20:11:59&quot;) ## [1] &quot;2017-01-31 20:11:59 UTC&quot; mdy_hm(&quot;01/31/2017 08:01&quot;) ## [1] &quot;2017-01-31 08:01:00 UTC&quot; 시간대를 제공하여 날짜로부터 데이트-타임형을 강제 생성할 수도 있다. ymd(20170131, tz = &quot;UTC&quot;) ## [1] &quot;2017-01-31 UTC&quot; 9.2.2 개별 구성요소로 생성 때로는 문자열이 아니라 데이트-타임형의 개별 구성요소들이 여러 열에 걸쳐 있는 경우가 있을 것이다. flights 데이터에 있는 것이 그렇다. flights %&gt;% select(year, month, day, hour, minute) ## # A tibble: 336,776 x 5 ## year month day hour minute ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 15 ## 2 2013 1 1 5 29 ## 3 2013 1 1 5 40 ## # ... with 336,773 more rows 이러한 입력으로 날짜/시간을 생성하려면 데이트형은 make_date() 를, 데이트-타임형은 make_datetime() 를 쓰면 된다. flights %&gt;% select(year, month, day, hour, minute) %&gt;% mutate(departure = make_datetime(year, month, day, hour, minute)) ## # A tibble: 336,776 x 6 ## year month day hour minute departure ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 2013 1 1 5 15 2013-01-01 05:15:00 ## 2 2013 1 1 5 29 2013-01-01 05:29:00 ## 3 2013 1 1 5 40 2013-01-01 05:40:00 ## # ... with 336,773 more rows ‘flights’ 네 개의 시간 열 각각에 대해 같은 작업을 하자. 시간이 약간 이상한 형식으로 표시되었으므로, 나머지 연산으로 시와 분 구성요소를 추출한다. 이제 데이트-타임형 변수를 생성했으니 이 장의 나머지 부분에서는 이 변수들을 탐색해 볼 것이다. make_datetime_100 &lt;- function(year, month, day, time) { make_datetime(year, month, day, time %/% 100, time %% 100) } flights_dt &lt;- flights %&gt;% filter(!is.na(dep_time), !is.na(arr_time)) %&gt;% mutate( dep_time = make_datetime_100(year, month, day, dep_time), arr_time = make_datetime_100(year, month, day, arr_time), sched_dep_time = make_datetime_100(year, month, day, sched_dep_time), sched_arr_time = make_datetime_100(year, month, day, sched_arr_time) ) %&gt;% select(origin, dest, ends_with(&quot;delay&quot;), ends_with(&quot;time&quot;)) flights_dt ## # A tibble: 328,063 x 9 ## origin dest dep_delay arr_delay dep_time sched_dep_time ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 EWR IAH 2 11 2013-01-01 05:17:00 2013-01-01 05:15:00 ## 2 LGA IAH 4 20 2013-01-01 05:33:00 2013-01-01 05:29:00 ## 3 JFK MIA 2 33 2013-01-01 05:42:00 2013-01-01 05:40:00 ## # ... with 328,060 more rows, and 3 more variables: arr_time &lt;dttm&gt;, ## # sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt; 이 데이터로 한 해에 걸친 출발 시간의 분포를 시각화할 수 있다. flights_dt %&gt;% ggplot(aes(dep_time)) + geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day 하루 내에서의 분포로 보려면 flights_dt %&gt;% filter(dep_time &lt; ymd(20130102)) %&gt;% ggplot(aes(dep_time)) + geom_freqpoly(binwidth = 600) # 600 s = 10 minutes 수치형 맥락에서 데이트-타임형을 사용할 경우(히스토그램에서와 같이) 1은 1초를 의미하고, 따라서 86400 빈너비(binwidth)는 하루를 의미한다는 것을 주목하라. 데이트형에서는 1은 1일을 의미한다. 9.2.3 기타 유형에서 생성 데이트-타임형과 데이트형 사이를 상호 전환하고 싶을 때도 있을 것이다. as_datetime() 과 as_date() 가 바로 이를 수행한다. as_datetime(today()) ## [1] &quot;2020-12-06 UTC&quot; as_date(now()) ## [1] &quot;2020-12-06&quot; 때로 날짜/시간을 ‘유닉스 신기원(Unix Epoch)’인 1970-01-01에서 수치형 오프셋으로 가지고 있을 수 있다. 오프셋이 초 단위인 경우엔 as_datetime() , 일 단위인 경우엔 as_date() 을 사용한다. as_datetime(60 * 60 * 10) ## [1] &quot;1970-01-01 10:00:00 UTC&quot; as_date(365 * 10 + 2) ## [1] &quot;1980-01-01&quot; 9.2.4 연습문제 유효하지 않은 날짜를 포함한 문자열을 파싱하면 어떻게 되는가? ymd(c(&quot;2010-10-10&quot;, &quot;bananas&quot;)) ## Warning: 1 failed to parse. ## [1] &quot;2010-10-10&quot; NA today() 의 tzone 인수의 역할은 무엇인가? 이 인수는 왜 중요한가? 적절한 lubridate 함수를 이용하여, 다음 날짜를 각각 파싱하라. d1 &lt;- &quot;January 1, 2010&quot; d2 &lt;- &quot;2015-Mar-07&quot; d3 &lt;- &quot;06-Jun-2017&quot; d4 &lt;- c(&quot;August 19 (2015)&quot;, &quot;July 1 (2015)&quot;) d5 &lt;- &quot;12/30/14&quot; # Dec 30, 2014 9.3 데이트-타임형 구성요소 날짜/시간 데이터를 R의 데이트-타임형 데이터 구조로 얻는 방법을 이제 알았으니 이를 이용해 할 수 있는 것을 탐색해보자. 이 절에서는 개별 구성요소를 얻고 설정하는 설정 함수(accessor function)에 초점을 맞출 것이다. 다음 절에서는 산술연산이 데이트-타임형에 어떻게 동작하는지 살펴 볼 것이다. 9.3.1 구성요소 가져오기 다음 설정 함수로 데이트형의 개별 부분을 가져올 수 있다. year(), month(), mday() (한 달에서 일), yday() (한 해에서 일), wday (한 주 중 일), hour(), minute(), second() . datetime &lt;- ymd_hms(&quot;2016-07-08 12:34:56&quot;) year(datetime) ## [1] 2016 month(datetime) ## [1] 7 mday(datetime) ## [1] 8 yday(datetime) ## [1] 190 wday(datetime) ## [1] 6 month() 와 wday() 에서 label = TRUE 를 설정하여 월이나 일의 약식 이름을 반환할 수 있다. abbr = FALSE 를 설정하면 이름 전체를 반환할 수 있다. month(datetime, label = TRUE) ## [1] 7 ## Levels: 1 &lt; 2 &lt; 3 &lt; 4 &lt; 5 &lt; 6 &lt; 7 &lt; 8 &lt; 9 &lt; 10 &lt; 11 &lt; 12 wday(datetime, label = TRUE, abbr = FALSE) ## [1] 금요일 ## Levels: 일요일 &lt; 월요일 &lt; 화요일 &lt; 수요일 &lt; 목요일 &lt; 금요일 &lt; 토요일 wday() 를 사용하여 주말보다 평일에 출발하는 항공편이 더 많다는 것을 확인할 수 있다. flights_dt %&gt;% mutate(wday = wday(dep_time, label = TRUE)) %&gt;% ggplot(aes(x = wday)) + geom_bar() 출발 지연시간 평균을 매 시의 각 분(0~59 분)에 대해서 살펴보면 흥미로운 패턴이 있다. 20~30분과 50~60분에 출발하는 항공편은 나머지 시간보다 훨씬 덜 지연되는 것으로 보인다. flights_dt %&gt;% mutate(minute = minute(dep_time)) %&gt;% group_by(minute) %&gt;% summarise( avg_delay = mean(arr_delay, na.rm = TRUE), n = n()) %&gt;% ggplot(aes(minute, avg_delay)) + geom_line() ## `summarise()` ungrouping output (override with `.groups` argument) 흥미롭게도 예정된 출발시간으로 보면 이러한 강한 패턴을 볼 수 없다. sched_dep &lt;- flights_dt %&gt;% mutate(minute = minute(sched_dep_time)) %&gt;% group_by(minute) %&gt;% summarise( avg_delay = mean(arr_delay, na.rm = TRUE), n = n()) ## `summarise()` ungrouping output (override with `.groups` argument) ggplot(sched_dep, aes(minute, avg_delay)) + geom_line() 그러면 왜 실제 출발시간에는 그 패턴이 있는가? 사람에 의해 수집된 많은 데이터가 그런 것처럼, ’좋은‘ 출발시간에 떠나는 항공편 방향으로 편향(bias)이 강하게 존재한다. 인간의 판단이 관여된 데이터로 작업할 때마다 이런 종류의 패턴을 항상 유의해야 한다. ggplot(sched_dep, aes(minute, n)) + geom_line() 9.3.2 반올림 개별 구성요소를 플롯하는 또 다른 방법은 floor_date() , round_date() , ceiling_date() 로 인근 시간 단위로 날짜를 반올림하는 것이다. 각 ceiling_date() 함수의 입력값으로는, 조정할 날짜 벡터와, 내림(floor), 올림(ceiling), 혹은 반올림(round)해서 맞출 단위의 이름이다. 예를 들어 주당 항공편 수를 플롯할 수 있다. flights_dt %&gt;% count(week = floor_date(dep_time, &quot;week&quot;)) %&gt;% ggplot(aes(week, n)) + geom_line() 날짜 반올림 전후 차이를 계산하는 것은 특히 유용할 수 있다. 9.3.3 구성요소 설정 설정 함수를 사용하여 날짜/시간의 구성 요소를 설정할 수 있다. (datetime &lt;- ymd_hms(&quot;2016-07-08 12:34:56&quot;)) ## [1] &quot;2016-07-08 12:34:56 UTC&quot; year(datetime) &lt;- 2020 datetime ## [1] &quot;2020-07-08 12:34:56 UTC&quot; month(datetime) &lt;- 01 datetime ## [1] &quot;2020-01-08 12:34:56 UTC&quot; hour(datetime) &lt;- hour(datetime) + 1 datetime ## [1] &quot;2020-01-08 13:34:56 UTC&quot; 수정하는 대신, update() 로 새로운 데이트-타임형을 생성할 수도 있다. 이 방법을 사용하여 여러 개의 값을 한 번에 설정할 수도 있다. update(datetime, year = 2020, month = 2, mday = 2, hour = 2) ## [1] &quot;2020-02-02 02:34:56 UTC&quot; 값이 너무 큰 경우에는 이월된다. ymd(&quot;2015-02-01&quot;) %&gt;% update(mday = 30) ## [1] &quot;2015-03-02&quot; ymd(&quot;2015-02-01&quot;) %&gt;% update(hour = 400) ## [1] &quot;2015-02-17 16:00:00 UTC&quot; update() 를 사용하여 관심있는 해의 하루 동안 항공편의 분포를 볼 수 있다. flights_dt %&gt;% mutate(dep_hour = update(dep_time, yday = 1)) %&gt;% ggplot(aes(dep_hour)) + geom_freqpoly(binwidth = 300) 날짜의 상위 구성 요소를 상수로 설정하면, 하위 구성 요소의 패턴을 탐색할 수 있어서 매우 유용한 방법이다 9.3.4 연습문제 하루 동안 비행시간의 분포는 한 해 동안 어떻게 변화했는가? dep_time, sched_dep_time, dep_delay 를 비교하라. 이들은 일관성이 있는가? 무엇을 발견했는지 설명하라. 출발, 도착 사이의 시간과 air_time 을 비교하라. 무엇을 발견했는지 설명하라. (힌트: 공항의 위치를 살펴보라.) 하루 동안 평균 지연시간은 어떻게 변화하는가? dep_time 또는 sched_dep_time 를 사용해야 하는가? 이유는 무엇인가? 지연 가능성을 최소화하려면 한 주 중 어느 요일에 떠나야 하는가? 왜 diamonds$carat 과 flights$sched_dep_time 분포가 비슷한가? 20-30분과 50-60분에서 출발이 빠른 것은 일찍 출발하도록 계획된 항공편 때문이라는 우리의 가설을 확인하라. 힌트: 항공편이 지연되었는지 여부를 알려주는 이진 변수를 생성하라. 9.4 시간 범위 다음으로 뺄셈, 덧셈, 나눗셈 같은 산술연산이 데이트형에 어떻게 동작하는지 알아보자. 여기에서는 시간 범위(time span)를 대표하는 중요한 클래스 세 가지를 배우게 된다. 듀레이션형 (duration): 정확한 초를 나타냄. 피리어드형 (period): 주와 월과 같은 인간의 단위를 나타냄. 인터벌형 (interval): 시점과 종점을 나타냄. 9.4.1 듀레이션형 R에서 두 데이트형 뺄셈을 하면 difftime형 객체가 생긴다. # 해들리의 나이는? h_age &lt;- today() - ymd(19791014) h_age ## Time difference of 15029 days difftime 클래스 객체는 초, 분, 시, 일 또는 주의 시간 범위를 기록한다. 이러한 애매함 때문에 difftime형으로 작업하는 것이 약간 고통스러울 수 있다. 따라서 lubridate 는 항상 초를 사용하는 대안 클래스, 듀레이션형 을 제공한다. as.duration(h_age) ## [1] &quot;1298505600s (~41.15 years)&quot; 듀레이션형에는 편리한 생성자가 많다. dseconds(15) ## [1] &quot;15s&quot; dminutes(10) ## [1] &quot;600s (~10 minutes)&quot; dhours(c(12, 24)) ## [1] &quot;43200s (~12 hours)&quot; &quot;86400s (~1 days)&quot; ddays(0:5) ## [1] &quot;0s&quot; &quot;86400s (~1 days)&quot; &quot;172800s (~2 days)&quot; ## [4] &quot;259200s (~3 days)&quot; &quot;345600s (~4 days)&quot; &quot;432000s (~5 days)&quot; dweeks(3) ## [1] &quot;1814400s (~3 weeks)&quot; dyears(1) ## [1] &quot;31557600s (~1 years)&quot; 듀레이션형은 항상 초 단위로 시간 범위를 기록한다. 이보다 큰 단위를 생성하려면 분, 시, 일, 주, 연을 표준비율로 변환해야 한다(분당 60초, 시당 60분, 일당 24시, 주당 7일, 연당 365일). 듀레이션형을 더하거나 곱할 수 있다. 2 * dyears(1) ## [1] &quot;63115200s (~2 years)&quot; dyears(1) + dweeks(12) + dhours(15) ## [1] &quot;38869200s (~1.23 years)&quot; 일(day)에서 듀레이션형을 더하고 뺄 수 있다.{r} tomorrow &lt;- today() + ddays(1) last_year &lt;- today() - dyears(1) 그러나 듀레이션형은 정확한 초 개수로 표시하므로 때로는 예상치 못한 결과를 얻을 수도 있다. one_pm &lt;- ymd_hms(&quot;2016-03-12 13:00:00&quot;, tz = &quot;America/New_York&quot;) one_pm ## [1] &quot;2016-03-12 13:00:00 EST&quot; one_pm + ddays(1) ## [1] &quot;2016-03-13 14:00:00 EDT&quot; 3월 12일 오후 1시의 1일 후가 왜 3월 13일 오후 2시인가? 날짜를 주의 깊게 보면 시간대가 바뀌어 있다. 일광절약제 때문에 3월 12일에는 23시만 있다. 따라서 하루에 해당하는 초를 더하면 다른 시간을 갖게 된다. 9.4.2 피리어드형 이 문제를 해결하기 위해 lubridate 는 **피리어드형을 제공한다. 피리어드형은 시간 범위이지만 정해진 초 길이가 없다. 대신 일과 월과 같은 ’사람의‘ 시간으로 동작한다. 따라서 작동 방식이 보다 직관적이다. one_pm ## [1] &quot;2016-03-12 13:00:00 EST&quot; one_pm + days(1) ## [1] &quot;2016-03-13 13:00:00 EDT&quot; 듀레이션형과 마찬가지로 피리어드형은 다수의 생성 함수로 편리하게 생성할 수 있다. seconds(15) ## [1] &quot;15S&quot; minutes(10) ## [1] &quot;10M 0S&quot; hours(c(12, 24)) ## [1] &quot;12H 0M 0S&quot; &quot;24H 0M 0S&quot; days(7) ## [1] &quot;7d 0H 0M 0S&quot; months(1:6) ## [1] &quot;1m 0d 0H 0M 0S&quot; &quot;2m 0d 0H 0M 0S&quot; &quot;3m 0d 0H 0M 0S&quot; &quot;4m 0d 0H 0M 0S&quot; ## [5] &quot;5m 0d 0H 0M 0S&quot; &quot;6m 0d 0H 0M 0S&quot; weeks(3) ## [1] &quot;21d 0H 0M 0S&quot; years(1) ## [1] &quot;1y 0m 0d 0H 0M 0S&quot; 피리어드형을 더하거나 곱할 수 있다. 10 * (months(6) + days(1)) ## [1] &quot;60m 10d 0H 0M 0S&quot; days(50) + hours(25) + minutes(2) ## [1] &quot;50d 25H 2M 0S&quot; 그리고 물론, 데이트형에 더해진다. 듀레이션형과 달리 피리어드형은 의도한 대로 동작한다. # 윤년 ymd(&quot;2016-01-01&quot;) + dyears(1) ## [1] &quot;2016-12-31 06:00:00 UTC&quot; ymd(&quot;2016-01-01&quot;) + years(1) ## [1] &quot;2017-01-01&quot; # 일광절약제 one_pm + ddays(1) ## [1] &quot;2016-03-13 14:00:00 EDT&quot; one_pm + days(1) ## [1] &quot;2016-03-13 13:00:00 EDT&quot; 이제 피리어드형을 사용해서 비행 날짜에 관련된 문제를 해결해보자. 일부 항공편은 뉴욕시에서 출발하기 전에 목적지에 도착한 것으로 보여진다. flights_dt %&gt;% filter(arr_time &lt; dep_time) ## # A tibble: 10,633 x 9 ## origin dest dep_delay arr_delay dep_time sched_dep_time ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dttm&gt; ## 1 EWR BQN 9 -4 2013-01-01 19:29:00 2013-01-01 19:20:00 ## 2 JFK DFW 59 NA 2013-01-01 19:39:00 2013-01-01 18:40:00 ## 3 EWR TPA -2 9 2013-01-01 20:58:00 2013-01-01 21:00:00 ## # ... with 10,630 more rows, and 3 more variables: arr_time &lt;dttm&gt;, ## # sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt; 이들은 심야 항공편이다. 우리는 출발과 도착시간 모두에 같은 날짜 정보를 사용했었지만, 이 항공편들은 도착시간이 다음날이다. 심야 항공편의 도착시간에 days(1) 을 더해서 문제를 해결할 수 있다. flights_dt &lt;- flights_dt %&gt;% mutate( overnight = arr_time &lt; dep_time, arr_time = arr_time + days(overnight * 1), sched_arr_time = sched_arr_time + days(overnight * 1) ) 이제 모든 항공편이 물리학의 법칙을 벗어나지 않는다. flights_dt %&gt;% filter(overnight, arr_time &lt; dep_time) ## # A tibble: 0 x 10 ## # ... with 10 variables: origin &lt;chr&gt;, dest &lt;chr&gt;, dep_delay &lt;dbl&gt;, ## # arr_delay &lt;dbl&gt;, dep_time &lt;dttm&gt;, sched_dep_time &lt;dttm&gt;, arr_time &lt;dttm&gt;, ## # sched_arr_time &lt;dttm&gt;, air_time &lt;dbl&gt;, overnight &lt;lgl&gt; 9.4.3 인터벌형 dyears(1) / ddays(365) 가 반환해야 하는 값은 명백하다. 바로 1인데 왜냐하면, 듀레이션형은 항상 초 단위로 표현하며 듀레이션형 1년은 365일에 해당하는 초로 정의되기 때문이다. years(1) / days(1) 이 반환해야 하는 값은 무엇인가? 음… 2015년이라면 365를 반환해야하지만 2016년이면 366을 반환해야 한다! lubridate 가 하나의 명확한 답을 주기에 충분한 정보가 없다. 대신 경고와 함께 예측값을 준다. years(1) / days(1) ## [1] 365.25 더 정확한 값을 원한다면 인터벌형 을 사용해야 한다. 인터벌형은 시작점이 있는 듀레이션형이어서 기간이 정확히 얼마인지 확인할 수 있도록 만든다. next_year &lt;- today() + years(1) (today() %--% next_year) / ddays(1) ## [1] 365 한 인터벌형이 피리어드형 얼마에 해당하는지 확인하려면 정수 나누기를 사용해야 한다. (today() %--% next_year) %/% days(1) ## [1] 365 9.4.4 요약 듀레이션형, 피리어드형, 인터벌형 중에서 선택은 어떻게 해야 하는가? 언제나 그렇듯이 주어진 문제를 해결하는 가장 간단한 데이터 구조를 선택하라. 단지 물리적인 시간만 고려하는 경우에는 듀레이션형을 사용하라. 사람의 시간을 추가해야 하는 경우에는 피리어드형을 사용하라. 사람이 사용하는 시간단위로 파악해야 하는 경우에는 인터벌형을 사용하라. Figure 9.1 은 다른 데이터 유형 사이에 허용된 산술연산을 요약한 것이다. Figure 9.1: The allowed arithmetic operations between pairs of date/time classes. 9.4.5 연습문제 왜 months() 는 있고 dmonths() 는 없는가? R을 막 배우기 시작한 사람에게 days(overnight * 1) 을 설명하라. 어떻게 동작하는가? 2015년 매월 첫 날짜를 주는 데이트형 벡터를 생성하라. 현재 연도의 매월 첫 날짜를 주는 데이트형 벡터를 생성하라. 여러분의 생일이 (데이트형으로) 주어질 때, 나이를 연으로 반환하는 함수를 작성하라. 왜 다음은 작동하지 않는가? (today() %--% (today() + years(1)) / months(1) 9.5 시간대 시간대는 엄청나게 복잡한 주제인데, 지정학적 요소들과 상호작용이 있기 때문이다. 다행히 데이터 분석을 할 때 시간대가 항상 중요하지는 않기 때문에 세부사항을 모두 파고들지 않아도 되지만, 정면으로 맞서야 하는 문제가 몇 개 있다. 첫 번째 문제는 일상적인 시간대 이름은 모호하다는 것이다. 예를 들어 여러분이 미국인이라면 아마 EST, 즉 동부 표준시가 익숙할 것이다. 그러나 호주와 캐나다에도 EST가 있다! 혼란을 방지하기 위해, R은 국제 표준 IANA 시간대를 사용한다. 이는 일반적으로 ’/’ 형태로 ’/’를 쓰는 일관된 명명 체계를 사용한다 (모든 국가가 대륙에 위치하는 것은 아니기 때문에 몇 가지 예외도 있다). 예를 들면 ’America/New_York‘, ’Europe/Paris‘와 ’Pacific/Auckland‘ 등이 있다. 시간대가 국가, 혹은 국가 내 지역과 관련되었다고 일반적으로 생각하면 왜 시간대가 도시를 사용하는지 궁금할 것이다. 이는 IANA 데이터베이스가 시간대 규칙을 수십 년 분량이나 기록해야 하기 때문이다. 수십 년 사이에 국가 이름은 꽤 자주 변경(또는 분리)되지만, 도시의 이름은 유지되는 편이다. 또 다른 문제는 이름은 현재의 행동뿐만 아니라 전체 역사를 반영해야 한다는 것이다. 예를 들어 ’America/New_York‘과 ’America/Detroit‘ 시간대가 있다. 두 도시는 현재 모두 동부 표준시간을 사용하지만 (디트로이트가 위치한) 미시간주는 1969-1972’에, 일광절약제를 따르지 않았기 때문에 이름이 따로 필요한 것이다. 이러한 이야기들이 있는 원시 시간대 데이터베이스(http://www.iana.org/time-zones)를 읽어볼 만하다! Sys.timezone() 를 사용해서 현재 R이 인식하고 있는 시간대를 알아볼 수 있다. (우리나라 시간대는 “Asia/Seoul”이다.) Sys.timezone() ## [1] &quot;Asia/Seoul&quot; (R이 모르는 경우 NA 가 나올 것이다.) 그리고 OlsonNames() 를 사용해서 모든 시간대 이름의 전체 목록을 볼 수 있다. length(OlsonNames()) ## [1] 594 head(OlsonNames()) ## [1] &quot;Africa/Abidjan&quot; &quot;Africa/Accra&quot; &quot;Africa/Addis_Ababa&quot; ## [4] &quot;Africa/Algiers&quot; &quot;Africa/Asmara&quot; &quot;Africa/Asmera&quot; R에 있어서, 시간대는 출력 제어만 하는 데이트-타임형의 한 속성이다. 예를 들어 이 세 가지 객체는 같은 시점을 나타낸다. (x1 &lt;- ymd_hms(&quot;2015-06-01 12:00:00&quot;, tz = &quot;America/New_York&quot;)) ## [1] &quot;2015-06-01 12:00:00 EDT&quot; (x2 &lt;- ymd_hms(&quot;2015-06-01 18:00:00&quot;, tz = &quot;Europe/Copenhagen&quot;)) ## [1] &quot;2015-06-01 18:00:00 CEST&quot; (x3 &lt;- ymd_hms(&quot;2015-06-02 04:00:00&quot;, tz = &quot;Pacific/Auckland&quot;)) ## [1] &quot;2015-06-02 04:00:00 NZST&quot; 이들이 같은 시점이라는 것을 뺄셈을 사용하여 확인할 수 있다. x1 - x2 ## Time difference of 0 secs x1 - x3 ## Time difference of 0 secs 별도 명시가 없는 한, lubridate 는 항상 UTC를 사용한다. UTC(Coordinated Universal Time)는 과학계에서 사용하는 표준 시간대이며 그 전신인 GMT(그리니치 표준시)와 거의 같다. UTC는 DST가 없는데, 이로 인해 계산에 용이한 표현 방법이 된다. c() 와 같이 데이트-타임형을 조합하는 연산은 종종 시간대를 제거한다. 이 경우 데이트-타임형은 현지 시간대로 표시된다. x4 &lt;- c(x1, x2, x3) x4 ## [1] &quot;2015-06-01 12:00:00 EDT&quot; &quot;2015-06-01 12:00:00 EDT&quot; ## [3] &quot;2015-06-01 12:00:00 EDT&quot; 두 가지 방법으로 시간대를 변경할 수 있다. 시각을 유지하고 표시 방법을 변경한다. 시각은 맞지만 더 자연스러운 표시를 원한다면 이 방법을 써라. x4a &lt;- with_tz(x4, tzone = &quot;Australia/Lord_Howe&quot;) x4a ## [1] &quot;2015-06-02 02:30:00 +1030&quot; &quot;2015-06-02 02:30:00 +1030&quot; ## [3] &quot;2015-06-02 02:30:00 +1030&quot; x4a - x4 ## Time differences in secs ## [1] 0 0 0 (이 예시는 시간대의 다른 어려운 점을 보여준다. 시간대 오프셋이 모두 정수-시 (integer hour) 인 것은 아니다!) 기본 시각을 변경한다. 시각에 잘못된 시간대가 붙어 있어서 이를 수정해야 한다면 이 방법을 사용하라. x4b &lt;- force_tz(x4, tzone = &quot;Australia/Lord_Howe&quot;) x4b ## [1] &quot;2015-06-01 12:00:00 +1030&quot; &quot;2015-06-01 12:00:00 +1030&quot; ## [3] &quot;2015-06-01 12:00:00 +1030&quot; x4b - x4 ## Time differences in hours ## [1] -14.5 -14.5 -14.5 References Time Data Types https://sulgik.github.io/r4ds/dates-and-times.html "],["strings.html", "Chapter 10 Strings 10.1 들어가기 10.2 문자열 기초 10.3 정규표현식을 이용한 패턴 매칭 10.4 패턴 매칭 10.5 기타 패턴 유형 10.6 정규 표현식의 기타 용도 10.7 stringi Reference", " Chapter 10 Strings 10.1 들어가기 이 장에서는 R에서의 문자열 조작(string manipulation)을 소개한다. 문자열이 동작하는 방식과 문자열을 직접 생성하는 법의 기초를 배우겠지만, 이 장의 초점은 정규표현식(regular expressions), 줄여서 regexps 이다. 문자열은 일반적으로 비정형 및 반정형 데이터를 포함하는데, 정규표현식은 문자열의 패턴을 간결하게 기술하는 언어라는 점에서 유용하다. 정규표현식을 처음 보면 고양이가 키보드를 밟고 간 것처럼 보이겠지만, 이해도가 높아질수록 의미가 눈에 들어올 것이다. 10.1.1 준비하기 이 장에서는 문자열 조작을 할 수 있는 stringr 패키지에 초점을 맞출 것이다. 보통은 항상 텍스트 데이터를 다루어야 하는 것은 아니기 때문에, stringr 은 핵심 tidyverse에 포함되어 있지 않다. 따라서 명시적으로 로드해야 한다. library(tidyverse) library(stringr) 10.2 문자열 기초 작은따옴표나 큰따옴표로 문자열을 생성할 수 있다. 다른 언어와는 달리 두 동작에 차이가 없다. 여러 개의 \" 를 포함하는 문자열을 생성하려는 것이 아니라면 항상 \" 를 사용할 것을 추천한다. string1 &lt;- &quot;문자열입니다&quot; string2 &lt;- &#39;문자열 내에 &quot;인용문&quot;이 포함된 경우, 나는 작은 따옴표를 사용한다&#39; 따옴표 닫는 것을 잊어 버린 경우, 연속문자(continuation character)인 + 가 나타난다. &gt; &quot;닫는 따옴표가 없는 문자열이다 + + + 도와줘요 갇혔어요 이 같은 일이 발생했다면 이스케이프키를 누르고 다시 시도하라! 작은따옴표 문자나 큰따옴표 문자를 문자열에 포함하려면 ‘벗어나기 (escape)’ 위해 \\ (이스케이프 키)를 사용할 수 있다. double_quote &lt;- &quot;\\&quot;&quot; # or &#39;&quot;&#39; double_quote ## [1] &quot;\\&quot;&quot; single_quote &lt;- &#39;\\&#39;&#39; # or &quot;&#39;&quot; single_quote ## [1] &quot;&#39;&quot; 같은 원리로 역슬래시 문자를 포함하려면 \"\\\\\" 과 같이 두 번 입력해야 한다. 문자열의 출력 표시는 문자열 자체와 같지 않다는 것에 주의하라. 출력에선 이스케이프가 보이기 때문이다. 문자열의 원시 형태를 보려면 writeLines() 를 사용하라. x &lt;- c(&quot;\\&quot;&quot;, &quot;\\\\&quot;) x ## [1] &quot;\\&quot;&quot; &quot;\\\\&quot; writeLines(x) ## &quot; ## \\ 이 외의 특수 문자들도 매우 많다. 줄바꿈, \"\\n\" , 탭, \"\\t\" 은 가장 일반적인 것들이다. ?'\"' , 혹은 ?\"'\" 로 볼 수 있는 도움말을 통해 전체 목록을 볼 수 있다. 또한 \"\\u00b5\" 과 같은 문자열을 간혹 볼 수도 있는데, 이는 비영어 문자를 모든 플랫폼에서 동작하도록 작성한 것이다. x &lt;- &quot;\\u00b5&quot; x ## [1] &quot;μ&quot; 복수의 문자열은 종종 c() 로 만들 수 있는 문자형 벡터에 저장된다. c(&quot;one&quot;, &quot;two&quot;, &quot;three&quot;) ## [1] &quot;one&quot; &quot;two&quot; &quot;three&quot; 10.2.1 문자열 길이 베이스 R에는 문자열에 동작하는 함수가 많이 있지만 일관성이 없고, 또 따라서 기억해내기 어렵기 때문에 여기에서는 사용하지 않을 것이다. 대신 우리는 stringr 의 함수를 사용할 것이다. 이 함수들의 이름은 좀 더 직관적이며 모두 str_ 로 시작한다. 예를 들어 str_length() 는 문자열의 문자 개수를 알려준다. str_length(c(&quot;a&quot;, &quot;R for data science&quot;, NA)) ## [1] 1 18 NA 공통된 str_ 접두사는 RStudio 이용자에게 특히 유용하다. str_ 을 타이핑하면 자동완성을 불러와서 모든 stringr 함수를 볼 수 있기 때문이다. img 10.2.2 문자열 결합 문자열을 두 개 이상 결합하기 위해서는 str_c() 를 사용하라. str_c(&quot;x&quot;, &quot;y&quot;) ## [1] &quot;xy&quot; str_c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;) ## [1] &quot;xyz&quot; 구분 방식을 컨트롤하기 위해 sep = 인수를 사용하라. str_c(&quot;x&quot;, &quot;y&quot;, sep = &quot;, &quot;) ## [1] &quot;x, y&quot; #&gt; [1] &quot;x, y&quot; 대부분의 R 함수들에서 그렇듯 결측값은 설정된 것이 이후로 계속 파급된다(contagious). 결측값을 \"NA\" 로 출력되길 원하면 str_replace_na() 를 사용하라. x &lt;- c(&quot;abc&quot;, NA) str_c(&quot;|-&quot;, x, &quot;-|&quot;) ## [1] &quot;|-abc-|&quot; NA str_c(&quot;|-&quot;, str_replace_na(x), &quot;-|&quot;) ## [1] &quot;|-abc-|&quot; &quot;|-NA-|&quot; 앞의 코드에서 본 것처럼 str_c() 는 벡터화되고 짧은 벡터가 긴 벡터와 길이가 같도록 자동으로 재사용한다. str_c(&quot;prefix-&quot;, c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), &quot;-suffix&quot;) ## [1] &quot;prefix-a-suffix&quot; &quot;prefix-b-suffix&quot; &quot;prefix-c-suffix&quot; 길이가 0인 객체는 조용히 삭제된다. 이 특성은 if 와 함께 쓰면 특히 유용하다. name &lt;- &quot;Hadley&quot; time_of_day &lt;- &quot;morning&quot; birthday &lt;- FALSE str_c( &quot;Good &quot;, time_of_day, &quot; &quot;, name, if (birthday) &quot; and HAPPY BIRTHDAY&quot;, &quot;.&quot; ) ## [1] &quot;Good morning Hadley.&quot; 문자열 벡터를 하나의 문자열로 합치려면 collapse 를 사용하라. str_c(c(&quot;x&quot;, &quot;y&quot;, &quot;z&quot;), collapse = &quot;, &quot;) ## [1] &quot;x, y, z&quot; 10.2.3 문자열 서브셋하기 문자열의 일부는 str_sub() 를 사용하여 추출할 수 있다. 이 함수는 문자열과 더불어 부분문자열의 위치를 지정하는 start 와 end 인수를 취한다. x &lt;- c(&quot;Apple&quot;, &quot;Banana&quot;, &quot;Pear&quot;) str_sub(x, 1, 3) ## [1] &quot;App&quot; &quot;Ban&quot; &quot;Pea&quot; # 음수는 끝에서부터 반대 방향으로 센다 str_sub(x, -3, -1) ## [1] &quot;ple&quot; &quot;ana&quot; &quot;ear&quot; str_sub() 는 문자열이 너무 짧은 경우에도 오류가 발생하지 않고 가능한 만큼 반환한다는 것을 주목하라. str_sub(&quot;a&quot;, 1, 5) ## [1] &quot;a&quot; str_sub() 의 할당 형식을 사용하여 문자열을 수정할 수도 있다. str_sub(x, 1, 1) &lt;- str_to_lower(str_sub(x, 1, 1)) x ## [1] &quot;apple&quot; &quot;banana&quot; &quot;pear&quot; 10.2.4 로케일 앞서 str_to_lower() 를 사용하여 텍스트를 소문자로 변경했다. str_to_upper() 또는 str_to_title() 을 사용할 수도 있다. 그러나 각각의 언어는 대소문자 규칙이 다르므로 대소문자 변경은 생각보다 더 복잡하다. 로케일을 지정하여, 어떤 규칙 집합을 사용할지 정할 수 있다. # 터키어는 i가 점이 있는 것과 없는 것 두 개이다 # 또한 대문자도 다르다 str_to_upper(c(&quot;i&quot;, &quot;ı&quot;)) ## [1] &quot;I&quot; &quot;I&quot; str_to_upper(c(&quot;i&quot;, &quot;ı&quot;), locale = &quot;tr&quot;) ## [1] &quot;&lt;U+0130&gt;&quot; &quot;I&quot; 로케일은 두 글자 또는 세 글자 줄임말인 ISO 639 언어 코드로 지정된다. 설정하고자 하는 언어의 ISO639 코드를 모르는 경우, 위키피디아에 잘 정리되어 있다. 로케일을 비워 둘 경우에는 운영체제에서 제공한 현재 로케일을 사용한다. 로케일의 영향을 받는 또 다른 중요한 작업은 정렬이다. 베이스R의 order() 및 sort() 함수는 현재 로케일을 사용하여 정렬한다. 다른 컴퓨터에서도 변함없는 동작을 원한다면 로케일 추가인수를 취하는 str_sort() 와 str_order() 를 사용하면 된다. x &lt;- c(&quot;apple&quot;, &quot;eggplant&quot;, &quot;banana&quot;) str_sort(x, locale = &quot;en&quot;) # English ## [1] &quot;apple&quot; &quot;banana&quot; &quot;eggplant&quot; str_sort(x, locale = &quot;haw&quot;) # Hawaiian ## [1] &quot;apple&quot; &quot;eggplant&quot; &quot;banana&quot; 10.2.5 연습문제 stringr 을 사용하지 않는 코드에서 paste() 와 paste0() 를 종종 볼 것이다. 두 함수의 차이점은 무엇인가? 이들에 상응하는 stringr 함수는 무엇인가? 이 함수들은 NA 를 다룰 때 어떻게 다른가? str_c() 의 sep 인수와 collapse 인수의 차이를 자신의 말로 기술하라. str_length() 과 str_sub() 을 이용하여 문자열 중앙 문자를 추출하라. 문자열에 짝수 개의 문자가 있다면 어떻게 하겠는가? str_wrap() 의 기능은 무엇인가? 어떤 경우에 이 함수를 사용하겠는가? str_trim() 의 기능은 무엇인가? str_trim() 의 반대는 무엇인가? 예를 들어 벡터 c( \"a\", \"b\", \"c\") 를 문자열 a, b, c 로 변환하는 함수를 작성하라. 길이가 0, 1, 2인 벡터일 경우 어떻게 해야 하는지에 대해 신중하게 생각해보라. 10.3 정규표현식을 이용한 패턴 매칭 정규표현식은 문자열의 패턴을 기술하는 매우 간결한 언어이다. 이해하는 데 다소 시간이 걸리지만 한번 이해하면 매우 유용함을 알 수 있을 것이다. 정규표현식을 배우기 위해 우리는 str_view() 와 str_view_all() 를 사용할 것이다. 이 두 함수는 문자 벡터와 정규표현식을 취해, 이들이 어떻게 매칭되는지를 보여준다. 우리는 매우 단순한 정규표현식부터 시작해서 점진적으로 복잡한 형태를 볼 것이다. 패턴 매칭을 충분히 익힌 후에는 다양한 stringr 함수로 적용하는 법을 배울 것이다. 10.3.1 기본 매칭 가장 간단한 패턴은 문자열 전체 (exact) 매칭이다. x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;an&quot;) R Studio의 Viewer 패널에 결과가 표시된다. \"an\" 패턴과 일치하는 문자열은 \"banana\" 다음으로 간단한 단계는 (줄바꿈을 제외한) 임의의 문자와 매칭하는 . 이다. str_view(x, &quot;.a.&quot;) apple 그런데 \".\" 이 임의의 문자와 매칭된다면, 문자 \".\" 는 어떻게 매칭하겠는가? ’이스케이프’를 사용하여 우리가 특별 동작을 사용하려는 것이 아니라, 정확하게 매칭하고 싶다는 것을 정규표현식에 표현해야 한다. 정규표현식도 문자열과 마찬가지로 특별한 동작을 이스케이프하기 위해 역슬래시(\\ )를 사용한다. 따라서 . 를 매칭하기 위해서는 정규표현식 \\. 을 써야한다. 그런데 이렇게 하면 문제가 생긴다. 정규표현식을 나타내기 위해 문자열을 사용했고 \\ 도 문자열에서 이스케이프 상징어로 사용하였다. 따라서 정규표현식 \\. 를 작성하기 위해서는 문자열 \"\\\\.\" 이 필요하다. # To create the regular expression, we need \\\\ dot &lt;- &quot;\\\\.&quot; # But the expression itself only contains one: writeLines(dot) ## \\. # And this tells R to look for an explicit . str_view(c(&quot;abc&quot;, &quot;a.c&quot;, &quot;bef&quot;), &quot;a\\\\.c&quot;) 정규표현식에서 \\ 를 이스케이프 문자로 사용한다면 문자 \\ 는 도대체 어떻게 매칭하겠는가? 정규표현식 \\\\ 를 만들어 이스케이프해야 한다. 앞의 정규표현식을 만들려면 \\ 를 이스케이프하는 문자열이 필요하다. 즉, 문자 \\ 을 매칭하기 위해서 \"\\\\\\\\\" 라고 작성해야 한다. 즉, 하나를 매칭하기 위해 네 개의 역슬래시가 필요하다! x &lt;- &quot;a\\\\b&quot; writeLines(x) ## a\\b str_view(x, &quot;\\\\\\\\&quot;) 여기서 정규표현식은 \\. 과 같이 쓰고 정규표현식을 나타내는 문자열은 \"\\\\.\" 과 같이 쓸 것이다. 10.3.1.1 연습문제 다음의 각 문자열 \"\\\", \"\\\\\", \"\\\\\\\" 이 \\ 과 매칭되지 않는 이유를 설명하라. 시퀀스 \"'\\ 를 어떻게 매칭하겠는가? 정규표현식 \\..\\..\\.. 은 어떤 패턴과 매칭되겠는가? 문자열로 어떻게 표현하겠는가? 10.3.2 앵커 기본적으로 정규표현식은 문자열의 일부를 매치한다. 정규표현식을 앵커로 고정(anchor) 하여 문자열의 시작 또는 끝과 매칭하면 유용한 경우가 많다. 다음을 사용할 수 있다. ^ : 문자열의 시작과 매칭 $ : 문자열의 끝과 매칭 x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_view(x, &quot;^a&quot;) str_view(x, &quot;a$&quot;) 두 기호를 올바로 기억하기 위해, 에반 미슐라가 알려준 다음의 연상 구문을 시도해보자. 파워(^ )로 시작하면, 돈($ )으로 끝나게 된다. 정규표현식을 문자열 전체와 강제로 매칭하도록 하려면 ^ 와 $ 로 고정하라. x &lt;- c(&quot;apple pie&quot;, &quot;apple&quot;, &quot;apple cake&quot;) str_view(x, &quot;apple&quot;) str_view(x, &quot;^apple$&quot;) 단어 사이의 경계(boundary)를 매칭시키려면 \\b 를 사용하면 된다. 나는 R에서 이 방법을 자주 사용하지는 않지만 RStudio에서 다른 함수의 구성요소인 함수의 이름을 찾고자 할 때 한 번씩 사용한다. 예를 들어 \\bsum\\b 를 사용하여 summarize, summary, rowsum 등이 매칭되는 것을 피할 수 있다. 10.3.2.1 연습문제 문자열 \"$^$\" 을 어떻게 매칭하겠는가? stringr::words 의 일반적인 단어의 말뭉치(corpus)에서 다음에 해당하는 단어들을 찾는 정규표현식을 구하라. “y”로 시작. “x”로 끝남. 정확히 세 글자. (str_length() 를 사용하는 부정행위를 하지 말 것!) 7개 이상의 글자. 이 리스트는 길기 때문에 str_view() 의 match 인수를 이용하여 매칭되는 단어들만, 혹은 매칭되지 않는 단어들만 볼 수 있다. 10.3.3 문자 클래스와 대체구문 하나 이상의 문자를 매칭하는 특별한 패턴들이 많이 있다. 우린 이미 하나를 보았는데, 줄바꿈을 제외하고 임의의 문자를 매칭하는 . 이다. 이 밖에도 네 개의 유용한 도구가 있다. \\d 는 임의의 숫자와 매치한다. \\s 는 임의의 여백 문자(whitespace, 예를 들어 공백, 탭, 줄바꿈)와 매치한다. [abc] 는 a, b 또는 c와 매치한다. [^abc] 는 a, b, 또는 c를 제외한 임의의 문자와 매치한다. \\d 나 \\s 를 포함하는 정규표현식을 만들기 위해서는 해당 문자열에서 \\ 을 이스케이프 해야 하므로 \"\\\\d\" 나 \"\\\\s\" 로 입력해야 한다는 것을 기억하라. 단일 문자를 포함하는 문자형 클래스는 정규표현식에서 메타문자 하나를 포함하고 싶을때 역슬래시 이스케이프의 대안이 될 수 있다. 많은 사람들에게 가독성이 좋아진다. # Look for a literal character that normally has special meaning in a regex str_view(c(&quot;abc&quot;, &quot;a.c&quot;, &quot;a*c&quot;, &quot;a c&quot;), &quot;a[.]c&quot;) str_view(c(&quot;abc&quot;, &quot;a.c&quot;, &quot;a*c&quot;, &quot;a c&quot;), &quot;.[*]c&quot;) str_view(c(&quot;abc&quot;, &quot;a.c&quot;, &quot;a*c&quot;, &quot;a c&quot;), &quot;a[ ]&quot;) 이 방법은 대부분 (전부는 아님) 정규표현식 메타문자에 적용된다: $ . | ? * + ( ) [ {. 안타깝게도 문자 클래스 내에서 조차 특수 의미가 있는 문자가 몇 있으며 백슬래시 이스케이프와 함께 해야 한다. ] \\ ^ -. 대체구문을 이용하여 하나 이상의 대체 패턴 사이에서 선택하도록 할 수 있다. 예를 들어 abc|d..f 는 \"abc\" 또는 \"deaf\" 중 하나와 매치한다. | 는 우선순위가 높다. 따라서 abc|xyz 는 abc 혹은 xyz 와 매칭하라는 의미이지 abcyz 나 abxyz 와 매칭하라는 의미가 아니다. 수식 표현에서와 같이 연산 우선순위가 조금이라도 헷갈린다면 의도한 바를 분명히 하기 위해 괄호를 사용하라. str_view(c(&quot;grey&quot;, &quot;gray&quot;), &quot;gr(e|a)y&quot;) 10.3.3.1 연습문제 다음에 해당하는 모든 단어를 찾는 정규표현식을 작성하라. 모음으로 시작함 자음만 포함함 (힌트: ‘비’-자음 매칭에 대해 생각해보라.) ed 로 끝나지만 eed 로 끝나지는 않음 ing 혹은 ize 로 끝남 다음의 규칙을 데이터기반으로 증명하라. ‘c 뒤를 제외하고는 i가 e 앞’ (영어 스펠링에서 ei와 ie가 헷갈릴 경우 이 두 글자 앞에 c 가 나온 경우를 제외하고는 ei가 맞다는 규칙) ‘q’ 다음은 항상 ‘u’ 인가? 미국 영어가 아닌 영국 영어로 쓰여진 단어를 매칭하는 정규표현식을 작성하라. 여러분의 나라에서 일반적으로 쓰이는 전화번호를 매칭하는 정규표현식을 작성하라. 10.3.4 반복 다음 단계는 패턴이 몇 회 매칭하는지를 조정하는 것이다. ? : 0 또는 1회 + : 1회 이상 * : 0회 이상 x &lt;- &quot;1888 is the longest year in Roman numerals: MDCCCLXXXVIII&quot; str_view(x, &quot;CC?&quot;) str_view(x, &quot;CC+&quot;) str_view(x, &#39;C[LX]+&#39;) 이 연산자의 우선순위는 낮음을 주목하라. 예를 들어 colou?r 를 사용하여 미국식이나 영국식 스펠링을 매치할 수 있다. 따라서 bana(na)+ 에서와 같이 대부분의 경우 괄호가 필요하다. 또한 매칭 횟수를 정확하게 지정할 수 있다. {n} : 정확히 n회 {n,} : n회 이상 {,m} : 최대 m회 {n,m} : n과 m회 사이 str_view(x, &quot;C{2}&quot;) str_view(x, &quot;C{2,}&quot;) str_view(x, &quot;C{2,3}&quot;) 기본값으로 이러한 매칭은 ‘그리디(greedy)’ 매칭이다. 즉, 가능한 가장 긴 문자열과 매칭한다. 이를 ‘게으르게(lazy)’ 만들 수 있다. 뒤에 ? 를 넣으면 가장 짧은 문자열과 매칭된다. 정규표현식의 고급 기능이지만 이런 것도 있다는 것을 알아놓으면 유용하다. str_view(x, &#39;C{2,3}?&#39;) str_view(x, &#39;C[LX]+?&#39;) 10.3.4.1 연습문제 ?, +, * 이 같음을 {m,n} 형식으로 설명하라. 다음의 정규표현식이 어떤 것과 매칭하는지를 말로 설명하라. (사용하는 것이 정규표현식인지 아니면 그것을 정의하는 문자열인지 주의 깊게 읽고 확인하라.) ^.*$ \"\\\\{.+\\\\}\" \\d{4}-\\d{2}-\\d{2} \"\\\\\\\\{4}\" 다음의 모든 단어를 찾는 정규표현식을 작성하라. 세 개의 자음으로 시작. 세 개 이상의 모음이 연달아 있음. 두 개 이상의 모음-자음 쌍이 연달아 있음. 다음의 초보자 정규표현식 십자말풀이를 풀어보라. https://regexcrossword.com/challenges/beginner 10.3.5 그룹화와 역참조 앞서 괄호를 사용하여 복잡한 표현을 명확하게 하는 법을 배웠다. 괄호는 또한 (number 1, 2 등) 숫자달린 캡쳐 그룹을 생성한다. 캡쳐 그룹은 괄호 내에서 정규표현식의 일부와 매치되는 문자열 부분을 저장한다. \\1, \\2 등과 같이 역참조(backreference)로 캡쳐 그룹에 매칭된 텍스트를 참조할 수 있다. 예를 들어 다음의 정규표현식은 두 글자가 반복되는 과일 이름과 매칭한다. fruit &lt;- c(&quot;banana&quot;, &quot;coconut&quot;, &quot;cucumber&quot;, &quot;jujube&quot;, &quot;papaya&quot;, &quot;salal berry&quot;) str_view(fruit, &quot;(..)\\\\1&quot;, match = TRUE) (str_match() 와 함께 쓰면 왜 유용한지 곧 알게 될 것이다.) 10.3.5.1 연습문제 다음의 표현식이 어떤 것과 매칭할지 말로 설명하라. (.)\\1\\1 \"(.)(.)\\\\2\\\\1\" (..)\\1 \"(.).\\\\1.\\\\1\" \"(.)(.)(.).*\\\\3\\\\2\\\\1\" 다음의 단어와 매칭하는 정규표현식을 작성하라. 같은 문자로 시작하고 끝남. 두 문자 반복이 있음(예를 들어 ’church’는 ’ch’를 두 번 반복). 적어도 세 곳에서 반복되는 문자가 있음(예컨대, ’eleven’은 ’e’가 세 개). 10.4 패턴 매칭 이제 정규표현식의 기초를 배웠으므로 실제 문제에 적용하는 법에 대해 알아보자. 이 절에서는 다음을 수행하는 다양한 stringr 함수들을 배울 것이다. 어떤 문자열이 패턴과 매칭하는지 결정. 매칭의 위치를 찾기. 매칭의 내용을 추출. 매칭된 것을 새 값으로 교체. 매칭를 기반으로 문자열 분할. 계속 진행하기 전에 주의할 점은, 정규표현식은 너무 강력해서 모든 문제를 정규표현식 하나로 접근하려고 하기 쉽다는 것이다. 제이미 자윈스키(Jamie Zawinski)의 말을 들어보자. 문제에 직면했을 때 어떤 사람들은 ’풀 수 있어. 정규표현식을 사용하면 돼’라고 생각한다. 이제 그들에겐 풀어야 할 문제가 두 개이다. 조심하라는 뜻으로 이메일 주소가 유효한지를 검사하는 다음의 정규표현식을 살펴보라. (?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t] )+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?: \\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:( ?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\0 31]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\ ](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+ (?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?: (?:\\r\\n)?[ \\t])*))*|(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z |(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n) ?[ \\t])*)*\\&lt;(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\ r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n) ?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t] )*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])* )(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t] )+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*) *:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+ |\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r \\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?: \\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t ]))*&quot;(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031 ]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\]( ?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(? :(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(? :\\r\\n)?[ \\t])*))*\\&gt;(?:(?:\\r\\n)?[ \\t])*)|(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(? :(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)? [ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)*:(?:(?:\\r\\n)?[ \\t])*(?:(?:(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]| \\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt; @,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot; (?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t] )*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\ &quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(? :[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[ \\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000- \\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|( ?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)*\\&lt;(?:(?:\\r\\n)?[ \\t])*(?:@(?:[^()&lt;&gt;@,; :\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([ ^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot; .\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\ ]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\ [\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\ r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\] |\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)?(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\0 00-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\ .|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@, ;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(? :[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*))*@(?:(?:\\r\\n)?[ \\t])* (?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;. \\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t])*(?:[ ^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\] ]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\&gt;(?:(?:\\r\\n)?[ \\t])*)(?:,\\s*( ?:(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\ &quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:( ?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[ \\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t ])*))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t ])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(? :\\.(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+| \\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*|(?: [^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\ ]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)*\\&lt;(?:(?:\\r\\n) ?[ \\t])*(?:@(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot; ()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n) ?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt; @,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*(?:,@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@, ;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?:\\r\\n)?[ \\t] )*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\ &quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*)*:(?:(?:\\r\\n)?[ \\t])*)? (?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;. \\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t])*)(?:\\.(?:(?: \\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z|(?=[\\[ &quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|&quot;(?:[^\\&quot;\\r\\\\]|\\\\.|(?:(?:\\r\\n)?[ \\t]))*&quot;(?:(?:\\r\\n)?[ \\t]) *))*@(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t]) +|\\Z|(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*)(?:\\ .(?:(?:\\r\\n)?[ \\t])*(?:[^()&lt;&gt;@,;:\\\\&quot;.\\[\\] \\000-\\031]+(?:(?:(?:\\r\\n)?[ \\t])+|\\Z |(?=[\\[&quot;()&lt;&gt;@,;:\\\\&quot;.\\[\\]]))|\\[([^\\[\\]\\r\\\\]|\\\\.)*\\](?:(?:\\r\\n)?[ \\t])*))*\\&gt;(?:( ?:\\r\\n)?[ \\t])*))*)?;\\s*) 이는 (이메일 주소는 놀랍게도 실제로는 단순하지 않기 때문에) 다소 극단적인 예이지만, 실제 코드에서 사용된다. 자세한 내용은 스택오버플로 토론 을 참조하라. 우리는 프로그래밍 언어를 사용하고 있으며, 활용할 수 있는 다른 도구들이 있다는 것을 잊지 않아야 한다. 하나의 복잡한 정규표현식을 작성하는 것보다, 간단한 정규표현식을 여러 개 작성하는 것이 쉬운 경우가 많다. 문제를 해결해줄 단일 정규표현식이 떠오르지 않는다면, 잠시 뒤로 물러서서, 문제를 작은 조각들로 분해하여, 작은 문제들을 하나씩 해결하면서 다음 단계로 나아갈 수 있는지 생각해보라. 10.4.1 매칭 탐지 문자형 벡터가 패턴과 매칭하는지 확인하려면, str_detect() 를 사용하라. 이 함수는 입력과 같은 길이의 논리형 벡터를 반환한다. x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_detect(x, &quot;e&quot;) ## [1] TRUE FALSE TRUE 논리형 벡터를 수치형 맥락에서 사용할 경우, FALSE 는 0 이 되고, TRUE 는 1 이 된다는 것을 명심하라. 따라서 긴 벡터에서의 매치 결과가 궁금할 때는, sum() 과 mean() 을 유용하게 사용할 수 있다. # How many common words start with t? sum(str_detect(words, &quot;^t&quot;)) ## [1] 65 # What proportion of common words end with a vowel? mean(str_detect(words, &quot;[aeiou]$&quot;)) ## [1] 0.2765306 복잡한 논리적 조건문이 있을 때(예를 들어 d 가 아니라면, c가 아닌 a나 b를 매치), 하나의 정규표현식을 작성하는 것보다, 여러 str_detect() 호출을 논리 연산자와 함께 묶는 것이 쉬울 때가 많다. 예를 들어 모음을 포함하지 않는 모든 단어를 찾는 두 가지 방법이 있다. # Find all words containing at least one vowel, and negate no_vowels_1 &lt;- !str_detect(words, &quot;[aeiou]&quot;) # Find all words consisting only of consonants (non-vowels) no_vowels_2 &lt;- str_detect(words, &quot;^[^aeiou]+$&quot;) identical(no_vowels_1, no_vowels_2) ## [1] TRUE 결과는 같지만, 나는 첫 번째 방법이 이해하기가 훨씬 쉽다고 생각한다. 정규표현식이 지나치게 복잡해질 경우, 작은 조각들로 분해하여, 각 조각에 이름을 주고, 논리적 연산으로 결합해보자. str_detect() 는 일반적으로 패턴과 매칭하는 요소를 선택하는 데 사용한다. 논리형 서브셋하기, 또는 편리한 str_subset() 래퍼로 이 작업을 수행할 수 있다. words[str_detect(words, &quot;x$&quot;)] ## [1] &quot;box&quot; &quot;sex&quot; &quot;six&quot; &quot;tax&quot; str_subset(words, &quot;x$&quot;) ## [1] &quot;box&quot; &quot;sex&quot; &quot;six&quot; &quot;tax&quot; 그러나 가지고 있는 문자열은 일반적으로 데이터프레임의 열일 것이므로, 대신 filter 를 사용하는 것이 좋다. df &lt;- tibble( word = words, i = seq_along(word) ) df %&gt;% filter(str_detect(word, &quot;x$&quot;)) ## # A tibble: 4 x 2 ## word i ## &lt;chr&gt; &lt;int&gt; ## 1 box 108 ## 2 sex 747 ## 3 six 772 ## 4 tax 841 str_detect() 의 변형은 str_count() 이다. 단순히 yes 또는 no 대신, 하나의 문자열에서 몇 번 매칭되는지를 알려준다. x &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;) str_count(x, &quot;a&quot;) ## [1] 1 3 1 # On average, how many vowels per word? mean(str_count(words, &quot;[aeiou]&quot;)) ## [1] 1.991837 str_count() 는 mutate() 와 함께 쓰는 것이 자연스럽다. df %&gt;% mutate( vowels = str_count(word, &quot;[aeiou]&quot;), consonants = str_count(word, &quot;[^aeiou]&quot;) ) ## # A tibble: 980 x 4 ## word i vowels consonants ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 a 1 1 0 ## 2 able 2 2 2 ## 3 about 3 3 2 ## # ... with 977 more rows 매칭들끼리 서로 겹치지 않는다는 것을 주의하라. 예를 들어 \"abababa\" 에서 \"aba\" 패턴이 몇 번 매칭하는가? 정규표현식에선 세 번이 아닌 두 번이라고 답한다. str_count(&quot;abababa&quot;, &quot;aba&quot;) ## [1] 2 str_view_all(&quot;abababa&quot;, &quot;aba&quot;) str_view_all() 의 용법에 주의하라. 곧 배우겠지만 많은 stringr 함수는 짝으로 제공된다. 즉, 단일 매칭에 동작하는 함수와, 모든 매칭에 동작하는 함수가 있다. 후자는 접미사 _all 이 붙는다. 10.4.1.1 연습문제 다음 문제들을 두 가지 방식으로 각각 풀어보라. 하나의 정규표현식을 사용해보고 또, 여러 str_detect() 호출을 결합해보라. x 로 시작 하거나 끝나는 모든 단어를 찾아라. 모음으로 시작하고 자음으로 끝나는 모든 단어를 찾아라. 각기 다른 모음을 하나 이상씩 포함하는 단어가 있는가? 어떤 단어가 가장 많은 모음을 갖는가? 어떤 단어가 모음의 비율이 가장 높은가? (힌트: 분모는 무엇인가?) 10.4.2 매칭 추출 매칭한 실제 텍스트를 추출하려면 str_extract() 를 사용하라. 이를 보기 위해 좀 더 복잡한 예제가 필요하다. 하버드 문장데이터(http://bit.ly/Harvardsentences )를 보려고 하는데, 이는 VOIP 시스템을 테스트하도록 설계되었지만, 정규표현식을 연습하는 데에도 유용하다. 이들은 stringr::sentences 에서 제공된다. length(sentences) ## [1] 720 head(sentences) ## [1] &quot;The birch canoe slid on the smooth planks.&quot; ## [2] &quot;Glue the sheet to the dark blue background.&quot; ## [3] &quot;It&#39;s easy to tell the depth of a well.&quot; ## [4] &quot;These days a chicken leg is a rare dish.&quot; ## [5] &quot;Rice is often served in round bowls.&quot; ## [6] &quot;The juice of lemons makes fine punch.&quot; 색상을 포함하는 모든 문장을 찾고 싶다고 가정해보자. 먼저 색상 이름 벡터를 생성한 다음, 이를 하나의 정규표현식으로 변환한다. colours &lt;- c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;, &quot;purple&quot;) colour_match &lt;- str_c(colours, collapse = &quot;|&quot;) colour_match ## [1] &quot;red|orange|yellow|green|blue|purple&quot; 이제 색상을 포함하는 문장을 선택할 수 있고, 그런 다음 매칭된 색상이 무엇인지 추출할 수 있다. has_colour &lt;- str_subset(sentences, colour_match) matches &lt;- str_extract(has_colour, colour_match) head(matches) ## [1] &quot;blue&quot; &quot;blue&quot; &quot;red&quot; &quot;red&quot; &quot;red&quot; &quot;blue&quot; str_extract() 는 첫 번째 매칭만 추출한다는 것을 주의하라. 매칭이 두 개 이상인 모든 문장을 우선 선택해보면 이를 가장 쉽게 볼 수 있다. more &lt;- sentences[str_count(sentences, colour_match) &gt; 1] str_view_all(more, colour_match) str_extract(more, colour_match) ## [1] &quot;blue&quot; &quot;green&quot; &quot;orange&quot; 이는 stringr 함수의 일반적인 패턴이다. 매칭 하나로 작업하면 훨씬 단순한 데이터 구조를 사용할 수 있기 때문이다. 매칭 모두를 얻으려면 str_extract_all() 를 사용하면 된다. 이는 리스트를 반환한다. str_extract_all(more, colour_match) ## [[1]] ## [1] &quot;blue&quot; &quot;red&quot; ## ## [[2]] ## [1] &quot;green&quot; &quot;red&quot; ## ## [[3]] ## [1] &quot;orange&quot; &quot;red&quot; 리스트 와 반복 에서 리스트에 관해 자세한 내용을 배울 것이다. str_extract_all() 에서 simplify = TRUE 를 하면 짧은 매칭이 가장 긴 것과 같은 길이로 확장된 행렬을 반환한다. str_extract_all(more, colour_match, simplify = TRUE) ## [,1] [,2] ## [1,] &quot;blue&quot; &quot;red&quot; ## [2,] &quot;green&quot; &quot;red&quot; ## [3,] &quot;orange&quot; &quot;red&quot; x &lt;- c(&quot;a&quot;, &quot;a b&quot;, &quot;a b c&quot;) str_extract_all(x, &quot;[a-z]&quot;, simplify = TRUE) ## [,1] [,2] [,3] ## [1,] &quot;a&quot; &quot;&quot; &quot;&quot; ## [2,] &quot;a&quot; &quot;b&quot; &quot;&quot; ## [3,] &quot;a&quot; &quot;b&quot; &quot;c&quot; 10.4.2.1 연습문제 앞의 예에서 매칭된 정규표현식이 색상이 아닌 ’flickered’에 매칭한 것을 눈치챘을지 모르겠다. 이 문제를 해결하기 위해 정규식을 수정하라. 하버드 문장 데이터에서 다음을 추출하라. 각 문장의 첫 번째 단어. ing 로 끝나는 모든 단어. 모든 복수형. 10.4.3 그룹화 매칭 이 장 앞부분에서 연산 우선순위를 명확히 할 목적과 역참조 목적으로 괄호 사용에 대해 이야기했었다. 이 외에도 복잡한 매치의 일부를 추출하기 위해서도 괄호를 사용할 수 있다. 예를 들어 문장에서 명사를 추출하고 싶다고 가정하자. 휴리스틱 방법으로 ‘a’ 또는 ‘the’ 다음에 오는 단어를 찾아 볼 것이다. 정규표현식에서 ’단어’를 정의하는 것은 약간 까다롭기 때문에, 여기서 다음의 간단한 근사법을 이용한다. 적어도 하나 이상의 문자(공백 제외) 시퀀스. noun &lt;- &quot;(a|the) ([^ ]+)&quot; has_noun &lt;- sentences %&gt;% str_subset(noun) %&gt;% head(10) has_noun %&gt;% str_extract(noun) ## [1] &quot;the smooth&quot; &quot;the sheet&quot; &quot;the depth&quot; &quot;a chicken&quot; &quot;the parked&quot; ## [6] &quot;the sun&quot; &quot;the huge&quot; &quot;the ball&quot; &quot;the woman&quot; &quot;a helps&quot; str_extract() 는 완전한 매치를 제공하는 반면, str_match() 는 각각 개별 요소를 제공한다. str_match() 는 문자형 벡터 대신 행렬을 반환하는데, 이 행렬에는 완전한 매치가 하나의 열로, 그 다음으로 각 그룹마다 열이 하나씩 따른다. has_noun %&gt;% str_match(noun) ## [,1] [,2] [,3] ## [1,] &quot;the smooth&quot; &quot;the&quot; &quot;smooth&quot; ## [2,] &quot;the sheet&quot; &quot;the&quot; &quot;sheet&quot; ## [3,] &quot;the depth&quot; &quot;the&quot; &quot;depth&quot; ## [4,] &quot;a chicken&quot; &quot;a&quot; &quot;chicken&quot; ## [5,] &quot;the parked&quot; &quot;the&quot; &quot;parked&quot; ## [6,] &quot;the sun&quot; &quot;the&quot; &quot;sun&quot; ## [7,] &quot;the huge&quot; &quot;the&quot; &quot;huge&quot; ## [8,] &quot;the ball&quot; &quot;the&quot; &quot;ball&quot; ## [9,] &quot;the woman&quot; &quot;the&quot; &quot;woman&quot; ## [10,] &quot;a helps&quot; &quot;a&quot; &quot;helps&quot; (예상했지만, 명사 검출하는 이 휴리스틱 방법은 좋지 않다. smooth나 parked 같은 형용사도 검출하고 있다.) 데이터가 티블인 경우, tidyr::extract() 를 사용하는 것이 더 쉽다. 이 함수는 str_match() 처럼 동작하지만, 매치를 명명할 것을 사용자에게 요청하고, 그 후 새로운 열로 배치한다. tibble(sentence = sentences) %&gt;% tidyr::extract( sentence, c(&quot;article&quot;, &quot;noun&quot;), &quot;(a|the) ([^ ]+)&quot;, remove = FALSE ) ## # A tibble: 720 x 3 ## sentence article noun ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 The birch canoe slid on the smooth planks. the smooth ## 2 Glue the sheet to the dark blue background. the sheet ## 3 It&#39;s easy to tell the depth of a well. the depth ## # ... with 717 more rows str_extract() 처럼, 각 문자열의 모든 매치를 원한다면 str_match_all() 이 필요하다. 10.4.3.1 연습문제 ‘one,’ ‘two,’ ‘three’ 등과 같은 ‘숫자’ 다음에 오는 모든 단어를 구하라. 숫자와 단어 모두를 추출하라. 줄임말을 모두 찾아라. 아포스트로피 이전과 이후 조각을 분리하라. 10.4.4 매칭 치환 str_replace() 와 str_replace_all() 을 이용하여 매치를 새로운 문자열로 치환할 수 있다. 가장 간단한 용법은 패턴을 고정된 문자열로 치환하는 것이다. x &lt;- c(&quot;apple&quot;, &quot;pear&quot;, &quot;banana&quot;) str_replace(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-pple&quot; &quot;p-ar&quot; &quot;b-nana&quot; str_replace_all(x, &quot;[aeiou]&quot;, &quot;-&quot;) ## [1] &quot;-ppl-&quot; &quot;p--r&quot; &quot;b-n-n-&quot; str_replace_all() 을 사용하면 명명된 벡터를 제공하여 다중 치환을 수행할 수 있다. x &lt;- c(&quot;1 house&quot;, &quot;2 cars&quot;, &quot;3 people&quot;) str_replace_all(x, c(&quot;1&quot; = &quot;one&quot;, &quot;2&quot; = &quot;two&quot;, &quot;3&quot; = &quot;three&quot;)) ## [1] &quot;one house&quot; &quot;two cars&quot; &quot;three people&quot; 고정된 문자열로 치환하는 대신, 매치의 구성요소를 삽입하기 위해 역참조를 사용할 수 있다. 다음 코드는 두 번째와 세 번째 단어의 순서를 바꾼다. sentences %&gt;% str_replace(&quot;([^ ]+) ([^ ]+) ([^ ]+)&quot;, &quot;\\\\1 \\\\3 \\\\2&quot;) %&gt;% head(5) ## [1] &quot;The canoe birch slid on the smooth planks.&quot; ## [2] &quot;Glue sheet the to the dark blue background.&quot; ## [3] &quot;It&#39;s to easy tell the depth of a well.&quot; ## [4] &quot;These a days chicken leg is a rare dish.&quot; ## [5] &quot;Rice often is served in round bowls.&quot; 10.4.4.1 연습문제 문자열의 모든 슬래시를 역슬래시로 치환하라. replace_all() 을 사용하여 str_to_lower() 의 간단한 버전을 구현하라. 단어의 첫 번째와 마지막 문자를 바꿔라. 여전히 단어가 되는 문자열은 무엇인가? 10.4.5 문자열 분할 문자열을 조각으로 분할하려면 str_split() 을 사용하면 된다. 예를 들어 문장을 단어로 분할할 수 있다. sentences %&gt;% head(5) %&gt;% str_split(&quot; &quot;) ## [[1]] ## [1] &quot;The&quot; &quot;birch&quot; &quot;canoe&quot; &quot;slid&quot; &quot;on&quot; &quot;the&quot; &quot;smooth&quot; ## [8] &quot;planks.&quot; ## ## [[2]] ## [1] &quot;Glue&quot; &quot;the&quot; &quot;sheet&quot; &quot;to&quot; &quot;the&quot; ## [6] &quot;dark&quot; &quot;blue&quot; &quot;background.&quot; ## ## [[3]] ## [1] &quot;It&#39;s&quot; &quot;easy&quot; &quot;to&quot; &quot;tell&quot; &quot;the&quot; &quot;depth&quot; &quot;of&quot; &quot;a&quot; &quot;well.&quot; ## ## [[4]] ## [1] &quot;These&quot; &quot;days&quot; &quot;a&quot; &quot;chicken&quot; &quot;leg&quot; &quot;is&quot; &quot;a&quot; ## [8] &quot;rare&quot; &quot;dish.&quot; ## ## [[5]] ## [1] &quot;Rice&quot; &quot;is&quot; &quot;often&quot; &quot;served&quot; &quot;in&quot; &quot;round&quot; &quot;bowls.&quot; 각 구성요소가 포함하는 조각의 개수가 다를 수 있으므로, 이 함수는 리스트를 반환한다. 길이가 1인 벡터로 작업하는 경우, 가장 쉬운 것은 리스트의 첫 번째 요소를 추출하는 것이다. &quot;a|b|c|d&quot; %&gt;% str_split(&quot;\\\\|&quot;) %&gt;% .[[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; 한편, 리스트를 반환하는 다른 stringr 함수처럼 simplify = TRUE 를 사용하여 행렬을 반환할 수도 있다. sentences %&gt;% head(5) %&gt;% str_split(&quot; &quot;, simplify = TRUE) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;The&quot; &quot;birch&quot; &quot;canoe&quot; &quot;slid&quot; &quot;on&quot; &quot;the&quot; &quot;smooth&quot; &quot;planks.&quot; ## [2,] &quot;Glue&quot; &quot;the&quot; &quot;sheet&quot; &quot;to&quot; &quot;the&quot; &quot;dark&quot; &quot;blue&quot; &quot;background.&quot; ## [3,] &quot;It&#39;s&quot; &quot;easy&quot; &quot;to&quot; &quot;tell&quot; &quot;the&quot; &quot;depth&quot; &quot;of&quot; &quot;a&quot; ## [4,] &quot;These&quot; &quot;days&quot; &quot;a&quot; &quot;chicken&quot; &quot;leg&quot; &quot;is&quot; &quot;a&quot; &quot;rare&quot; ## [5,] &quot;Rice&quot; &quot;is&quot; &quot;often&quot; &quot;served&quot; &quot;in&quot; &quot;round&quot; &quot;bowls.&quot; &quot;&quot; ## [,9] ## [1,] &quot;&quot; ## [2,] &quot;&quot; ## [3,] &quot;well.&quot; ## [4,] &quot;dish.&quot; ## [5,] &quot;&quot; #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] #&gt; [1,] &quot;The&quot; &quot;birch&quot; &quot;canoe&quot; &quot;slid&quot; &quot;on&quot; &quot;the&quot; &quot;smooth&quot; #&gt; [2,] &quot;Glue&quot; &quot;the&quot; &quot;sheet&quot; &quot;to&quot; &quot;the&quot; &quot;dark&quot; &quot;blue&quot; #&gt; [3,] &quot;It&#39;s&quot; &quot;easy&quot; &quot;to&quot; &quot;tell&quot; &quot;the&quot; &quot;depth&quot; &quot;of&quot; #&gt; [4,] &quot;These&quot; &quot;days&quot; &quot;a&quot; &quot;chicken&quot; &quot;leg&quot; &quot;is&quot; &quot;a&quot; #&gt; [5,] &quot;Rice&quot; &quot;is&quot; &quot;often&quot; &quot;served&quot; &quot;in&quot; &quot;round&quot; &quot;bowls.&quot; #&gt; [,8] [,9] #&gt; [1,] &quot;planks.&quot; &quot;&quot; #&gt; [2,] &quot;background.&quot; &quot;&quot; #&gt; [3,] &quot;a&quot; &quot;well.&quot; #&gt; [4,] &quot;rare&quot; &quot;dish.&quot; #&gt; [5,] &quot;&quot; &quot;&quot; 조각을 최대 개수만큼 요청할 수도 있다. fields &lt;- c(&quot;Name: Hadley&quot;, &quot;Country: NZ&quot;, &quot;Age: 35&quot;) fields %&gt;% str_split(&quot;: &quot;, n = 2, simplify = TRUE) ## [,1] [,2] ## [1,] &quot;Name&quot; &quot;Hadley&quot; ## [2,] &quot;Country&quot; &quot;NZ&quot; ## [3,] &quot;Age&quot; &quot;35&quot; #&gt; [,1] [,2] #&gt; [1,] &quot;Name&quot; &quot;Hadley&quot; #&gt; [2,] &quot;Country&quot; &quot;NZ&quot; #&gt; [3,] &quot;Age&quot; &quot;35&quot; 또한, 패턴으로 문자열을 분할하는 대신 문자, 줄, 문장 및 단어 경계 (boundary() )로 분할할 수도 있다. x &lt;- &quot;This is a sentence. This is another sentence.&quot; str_view_all(x, boundary(&quot;word&quot;)) str_split(x, &quot; &quot;)[[1]] ## [1] &quot;This&quot; &quot;is&quot; &quot;a&quot; &quot;sentence.&quot; &quot;&quot; &quot;This&quot; ## [7] &quot;is&quot; &quot;another&quot; &quot;sentence.&quot; #&gt; [1] &quot;This&quot; &quot;is&quot; &quot;a&quot; &quot;sentence.&quot; &quot;&quot; &quot;This&quot; #&gt; [7] &quot;is&quot; &quot;another&quot; &quot;sentence.&quot; str_split(x, boundary(&quot;word&quot;))[[1]] ## [1] &quot;This&quot; &quot;is&quot; &quot;a&quot; &quot;sentence&quot; &quot;This&quot; &quot;is&quot; &quot;another&quot; ## [8] &quot;sentence&quot; #&gt; [1] &quot;This&quot; &quot;is&quot; &quot;a&quot; &quot;sentence&quot; &quot;This&quot; &quot;is&quot; #&gt; [7] &quot;another&quot; &quot;sentence&quot; 10.4.5.1 연습문제 \"apples, pears, and bananas\" 와 같은 문자열을 개별 구성요소로 분할하라. 왜 \" \" 보다 boundary(\"word\") 로 분할하는 것이 좋은가? 빈 문자열 (\"\" )로 분할하면 어떻게 되는가? 실험해 본 후, 설명서를 읽어라. 10.4.6 매치 찾기 str_locate() 와 str_locate_all() 을 사용하면 각 매치의 시작과 종료 위치를 알 수 있다. 이는 원하는 바를 완벽하게 수행하는 함수가 없을 때 특히 유용하다. str_locate() 를 사용하여 매칭 패턴을 찾을 수 있으며 str_sub() 를 사용하여, 매칭 패턴을 추출하거나 수정할 수 있다. 10.5 기타 패턴 유형 문자열로 된 패턴을 사용하면 자동으로 regex() 호출로 래핑된다. fruit &lt;- c(&quot;banana&quot;, &quot;Banana&quot;, &quot;BANANA&quot;) # The regular call: str_view(fruit, &quot;nana&quot;) # Is shorthand for str_view(fruit, regex(&quot;nana&quot;)) regex() 의 다른 인수를 사용하여 매치의 세부사항을 제어할 수 있다. ignore_case = TRUE 를 하면 문자가 대문자나 소문자 형태 모두로 매칭된다. 이때 항상 현재의 로케일을 사용한다. bananas &lt;- c(&quot;banana&quot;, &quot;Banana&quot;, &quot;BANANA&quot;) str_view(bananas, &quot;banana&quot;) str_view(bananas, regex(&quot;banana&quot;, ignore_case = TRUE)) multiline = TRUE 를 하면 ^ 와 $ 이 전체 문자열의 시작, 끝이 아니라, 각 라인의 시작과 끝이 매칭된다. x &lt;- &quot;Line 1\\nLine 2\\nLine 3&quot; str_extract_all(x, &quot;^Line&quot;)[[1]] ## [1] &quot;Line&quot; str_extract_all(x, regex(&quot;^Line&quot;, multiline = TRUE))[[1]] ## [1] &quot;Line&quot; &quot;Line&quot; &quot;Line&quot; comments = TRUE 를 하면 복잡한 정규표현식을 이해하기 쉽도록 설명과 공백을 사용할 수 있게 된다. # 뒤에 나오는 다른 문자들처럼 공백도 무시된다. 공백 문자를 매치하기 위해서는 “\\\\” 로 이스케이프 해야 한다. phone &lt;- regex(&quot; \\\\(? # optional opening parens (\\\\d{3}) # area code [) -]? # optional closing parens, space, or dash (\\\\d{3}) # another three numbers [ -]? # optional space or dash (\\\\d{3}) # three more numbers &quot;, comments = TRUE) str_match(&quot;514-791-8141&quot;, phone) ## [,1] [,2] [,3] [,4] ## [1,] &quot;514-791-814&quot; &quot;514&quot; &quot;791&quot; &quot;814&quot; dotall = TRUE 를 하면 . 이 \\n 을 포함한 모든 것에 매칭된다. str_detect(&quot;\\nX\\n&quot;, &quot;.X.&quot;) ## [1] FALSE str_detect(&quot;\\nX\\n&quot;, regex(&quot;.X.&quot;, dotall = TRUE)) ## [1] TRUE regex() 대신 사용할 수 있는 세 가지 함수가 있다. fixed() 는 지정된 일련의 바이트와 정확히 매치한다. 이 함수는 모든 특수 정규표현식을 무시하고 매우 낮은 수준에서 동작한다. 이를 사용하여 복잡한 이스케이프를 피할 수 있으며 정규표현식보다 훨씬 속도가 빠르다. 다음의 소규모 벤치마크는 단순한 예시에 대해 약 3배 빠르다는 것을 보여준다. microbenchmark::microbenchmark( fixed = str_detect(sentences, fixed(&quot;the&quot;)), regex = str_detect(sentences, &quot;the&quot;), times = 20 ) ## Unit: microseconds ## expr min lq mean median uq max neval ## fixed 71.2 75.20 86.000 77.20 81.45 174.6 20 ## regex 202.6 205.05 215.855 206.95 217.35 273.0 20 fixed() 를 비영어에 사용할 때는 조심하라. 같은 문자를 나타내는 방법이 여러 가지이기 때문에 문제가 되는 경우가 많다. 예를 들어 ’á’를 정의하는 방법에는 두 가지가 있다. 즉, 단일한 문자로 하거나, ’a’와 악센트로 하는 방법이다. a1 &lt;- &quot;\\u00e1&quot; a2 &lt;- &quot;a\\u0301&quot; c(a1, a2) ## [1] &quot;a&quot; &quot;a&lt;U+0301&gt;&quot; a1 == a2 ## [1] FALSE 동일하게 렌더링하지만 다르게 정의되었기 때문에 fixed() 가 매치를 찾지 못한다. 대신, 인간의 문자 비교 규칙을 존중하는 coll() (아래에 정의됨)을 사용할 수 있다. str_detect(a1, fixed(a2)) ## [1] FALSE str_detect(a1, coll(a2)) ## [1] TRUE coll() 은 표준 정렬(collation) 규칙을 사용하여 문자열을 비교한다. 대소문자를 구분하지 않는(case-insensitive) 매치를 수행할 때 유용하다. coll() 은 문자 비교 규칙을 제어하는 로케일 파라미터를 취한다는 것을 주의해야 한다. 불행하게도 세계의 각 지역은 다른 규칙을 사용한다! # That means you also need to be aware of the difference # when doing case insensitive matches: i &lt;- c(&quot;I&quot;, &quot;İ&quot;, &quot;i&quot;, &quot;ı&quot;) i ## [1] &quot;I&quot; &quot;&lt;U+0130&gt;&quot; &quot;i&quot; &quot;ı&quot; str_subset(i, coll(&quot;i&quot;, ignore_case = TRUE)) ## [1] &quot;I&quot; &quot;i&quot; str_subset(i, coll(&quot;i&quot;, ignore_case = TRUE, locale = &quot;tr&quot;)) ## [1] &quot;i&quot; fixed() 와 regex() 모두에 ignore_case 인수가 있지만, 로케일 선택을 허용하지는 않는다. 이들은 항상 기본 로케일을 사용한다. 다음 코드를 통해 이를 알아볼 수 있다. (stringi 에서 더 살펴보자) stringi::stri_locale_info() ## $Language ## [1] &quot;ko&quot; ## ## $Country ## [1] &quot;KR&quot; ## ## $Variant ## [1] &quot;&quot; ## ## $Name ## [1] &quot;ko_KR&quot; coll() 의 단점은 속도이다. 어느 문자가 같은지 인식하는 규칙이 복잡하기 때문에, coll() 은 regex() 와 fixed() 에 비해 상대적으로 느리다. str_split() 에서 보았듯이 boundary() 를 사용하여 경계를 매치할 수 있다. 다른 함수들과도 사용할 수 있다. x &lt;- &quot;This is a sentence.&quot; str_view_all(x, boundary(&quot;word&quot;)) str_extract_all(x, boundary(&quot;word&quot;)) ## [[1]] ## [1] &quot;This&quot; &quot;is&quot; &quot;a&quot; &quot;sentence&quot; 10.5.1 연습문제 regex() vs fixed() 를 사용하여, 어떻게 \\ 를 포함하는 모든 문자열을 찾겠는가? sentences 에서 가장 자주 나오는 단어 다섯 가지는 무엇인가? 10.6 정규 표현식의 기타 용도 베이스 R 의 다음의 두 함수도 정규표현식을 사용한다. apropos() 는 전역 환경에서 사용할 수 있는 모든 객체를 검색한다. 함수의 이름을 기억할 수 없는 경우에 유용하다. apropos(&quot;replace&quot;) ## [1] &quot;%+replace%&quot; &quot;replace&quot; &quot;replace.substring.wild&quot; ## [4] &quot;replace_na&quot; &quot;setReplaceMethod&quot; &quot;str_replace&quot; ## [7] &quot;str_replace_all&quot; &quot;str_replace_na&quot; &quot;theme_replace&quot; #&gt; [1] &quot;%+replace%&quot; &quot;replace&quot; &quot;replace_na&quot; #&gt; [4] &quot;setReplaceMethod&quot; &quot;str_replace&quot; &quot;str_replace_all&quot; #&gt; [7] &quot;str_replace_na&quot; &quot;theme_replace&quot; dir() 은 디렉터리에 있는 모든 파일을 나열한다. pattern 인자는 정규표현식을 취해, 매치하는 파일 이름만 반환한다. 예를 들어 현재 디렉터리에 있는 모든 R 파일(R 마크다운 파일의 경우의 패턴은 \"\\\\.Rmd$\")을 다음과 같이 찾을 수 있다. head(dir(pattern = &quot;\\\\.R$&quot;)) ## character(0) (*.Rmd 같은 ’글로브(globs) 패턴’에 익숙한 경우, glob2rx() 를 사용하여 이를 정규표현식으로 변환할 수 있다.) 10.7 stringi stringr 은 stringi 패키지 기반으로 만들어졌다. stringr 은 학습할 때 유용한데, 왜냐하면 이 패키지는 자주 사용하는 문자열 조작 함수들을 다루기 위해 엄선된 최소한의 함수들만 보여주기 때문이다. 반면, stringi 는 전체를 포괄하도록 설계되었고, 필요한 거의 모든 함수를 포함한다. stringi 에는 234 개의 함수가 있지만, stringr 에는 46개가 있다. stringr 에서 잘 안될 경우, stringi 에서 한 번 찾아보는 것이 좋다. 두 패키지는 매우 유사하게 동작하므로, stringr 에서 배운 것을 자연스럽게 활용할 수 있을 것이다. 주요 차이점은 접두사이다(str_ 과 stri_ ). 10.7.1 연습문제 다음을 수행하는 stringi 함수를 찾아라. 단어의 수를 계산. 중복 문자열을 찾음. 랜덤 텍스트를 생성. stri_sort() 에서 정렬에 사용할 언어를 어떻게 제어하겠는가? Reference https://sulgik.github.io/r4ds/strings.html "],["Using-RegEx.html", "Chapter 11 정규 표현식의 활용 패키지 불러오기 11.1 패턴 찾기 함수 11.2 패턴 대체 함수 11.3 문자 벡터의 분할 11.4 stringr 패키지 함수", " Chapter 11 정규 표현식의 활용 이전 장에서 정규 표현식의 일반적인 내용, R이 정규 표현식을 처리하는 특별한 방식, 그리고 정규 표현식으로 문자열을 조작하는 데 사용할 수 있는 함수들을 간단히 소개하였다. 이 장에서는 정규 표현식의 함수에 대해 자세히 설명하고 그 사용법을 보여주는 몇 가지 예를 살펴 볼 것이다. 패키지 불러오기 library(tidyverse) 11.1 패턴 찾기 함수 grep(), grepl(), regexpr(), gregexpr() 및 regexec() 등과 같은 처음 5 개의 grep()-류의 함수를 살펴볼 것이다. 이 함수들의 목표는 일치하는 것을 찾는 것으로 모두 같다. 이들의 차이점은 출력 형식이다. 기본적으로 이러한 함수에는 두 가지 주요 인수, 즉 패턴 (예 : 정규식)과 일치에 사용되는 텍스트가 필요하다. 이 함수들의 기본 사용법은 다음과 같다. `grep(pattern, text)` : text내의 pattern의 위치 색인 값 (정수형) `grepl(pattern, text)` : text 내 pattern의 일치 여부 (logical 형) `regexpr(pattern, text)` : pattern과 일치하는 위치에 대한 자세한 정보 출력 (정수형) `gregexpr(pattern, text)` : text의 각 개별 요소별로 pattern과 일치하는 자세한 위치 정보 출력 (list 형) `regexec(pattern, text)` : text의 각 개별 요소별로 pattern과 일치하는 자세한 위치 정보 출력 (list 형) 각 함수에는 추가되는 또 다른 인수들이 있지만 잊지 말아야 할 중요한 인수는 패턴과 텍스트이다. 11.1.1 grep() 함수 grep() 함수는 문자열 벡터의 패턴을 일치시킬 수 있는 가장 기본적인 함수이다. 11.1.1.1 grep() 함수의 인수와 출력 : 첫 번째 인수는 일치시킬 패턴을 지정하는 정규 표현식입니다. 두 번째 인수는 검색 할 텍스트 문자열이 포함된 문자형 벡터이다. 출력은 디폴트로 일치하는 텍스트 벡터 요소의 색인 값이다. 일치하는 것이 없으면 출력은 빈 정수 벡터이다. # some text text &lt;- c(&quot;one word&quot;, &quot;a sentence&quot;, &quot;you and me&quot;, &quot;three two one&quot;) # pattern pattern &lt;- &quot;one&quot; # default usage grep(pattern, text) ## [1] 1 4 출력에서 볼 수 있듯이 grep() 함수는 숫자 벡터를 반환한다. 이는 text 벡터의 첫 번째와 네 번째 요소가 일치함을 나타낸다. 대조적으로, 두 번째와 세 번째 요소는 일치하지 않는 것이다. 11.1.1.2 인수 값을 사용하여 출력이 표시되는 방식을 수정할 수 있다. 색인을 반환하는 대신에, value = TRUE를 선택하면 grep()함수는 문자열 벡터의 내용(해당 요소의 값)을 반환한다. # with &#39;value&#39; (showing matched text) grep(pattern, text, value = TRUE) ## [1] &quot;one word&quot; &quot;three two one&quot; 11.1.1.3 또 다른 재미있는 인수는 invert이다. 이 매개 변수를 사용하여 값을 invert = TRUE로 설정하면 일치하지 않는 문자열을 얻을 수 있다. # with &#39;invert&#39; (showing unmatched parts) grep(pattern, text, invert = TRUE) ## [1] 2 3 # same with &#39;values&#39; grep(pattern, text, invert = TRUE, value = TRUE) ## [1] &quot;a sentence&quot; &quot;you and me&quot; 요약하면, grep() 함수를 사용하여 일치하는 패턴을 포함하거나, 포함하지 않는 요소만 가져 오기 위해, 문자형 벡터의 부분 집합을 구하는데 사용할 수 있는 것이다. 11.1.2 grepl() 함수 grepl() 함수를 사용하면 grep() 함수와 비슷한 작업을 수행할 수 있다. 차이점은 출력이 숫자 색인번호가 아니라 논리값 (TRUE /FALSE)이라는 점에 있다. 따라서 grepl() 함수를 ’grep-logical’로 생각할 수 있다. 앞의 예제와 동일한 텍스트 문자열을 사용하여 grepl() 함수를 살펴보면 다음과 같다. # some text text &lt;- c(&quot;one word&quot;, &quot;a sentence&quot;, &quot;you and me&quot;, &quot;three two one&quot;) # pattern pattern &lt;- &quot;one&quot; # default usage grepl(pattern, text) ## [1] TRUE FALSE FALSE TRUE 문자형 벡터와 같은 길이의 논리형 벡터를 얻는다. 패턴과 일치하는 요소들은 TRUE 값을 갖는다. 패턴과 일치하지 않는 요소는 FALSE 값을 갖는다. 11.1.3 regexpr() 함수 주어진 문자열에서 패턴이 있는 요소의 위치를 정확히 찾으려면 regexpr() 함수를 사용할 수 있다. 이 함수는 grep()보다 자세한 정보를 반환한다 : 텍스트 벡터의 어떤 요소가 실제로 정규 표현식 패턴을 포함하고 있는가 정규 표현식 패턴과 일치하는 부분 문자열의 위치를 확인한다. # some text text &lt;- c(&quot;one word&quot;, &quot;a sentence&quot;, &quot;you and me&quot;, &quot;three two one&quot;) # default usage regexpr(&quot;one&quot;, text) ## [1] 1 -1 -1 11 ## attr(,&quot;match.length&quot;) ## [1] 3 -1 -1 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 언뜻 보면 regexpr() 함수의 출력이 약간 복잡해 보일 수도 있지만 해석하기는 매우 간단하다. 출력에는 세 개의 요소가 표시된다. 첫 번째 요소는 첫 번째 일치의 시작 위치를 제공하는 text의 길이(length)와 같은 요소 수를 갖는 정수 벡터이다. 이 예에서 숫자 1은 패턴 “one”이 text의 첫 번째 요소(“one word”) 에서 1의 위치에서 시작함을 나타낸다. 음수 색인 -1은 일치하는 항목이 없음(“a sentence,” “you and me”의 경우)을 나타낸다. 숫자 11은 text의 네 번째 요소(“three two one”)에서 “one”과 일치하는 부분 문자열의 위치를 나타낸다. match.length 속성은 text의 각 요소에서 일치하는 길이(length)를 제공한다. -1의 음수 값은 해당 요소에 일치하는 것이 없음을 의미한다. 마지막으로, 속성 useBytes의 값은 TRUE이다. 이는 문자단위가 아니라 바이트 단위로 일치를 수행하는 것을 의미한다. 11.1.4 gregexpr() 함수 gregexpr() 함수는 regexpr() 함수와 실질적으로 동일한 기능을 수행한다. 문자열 벡터 text의 각 요소를 개별적으로 검색하여 패턴이 문자열 벡터와 일치하는 위치를 확인해 준다. 유일한 차이점은 gregexpr() 함수는 list 형식으로 출력한다는 것이다. 다시 말해, gregexpr()은 text와 동일한 길이(요소 갯수)의 list를 반환한다. 각 요소는 regexpr() 함수의 반환 값과 형식이 동일하다. 단, 모든 일치(불일치)의 시작 위치도 제공한다. # some text text &lt;- c(&quot;one word&quot;, &quot;a sentence&quot;, &quot;you and me&quot;, &quot;three two one&quot;) # pattern pattern &lt;- &quot;one&quot; # default usage gregexpr(pattern, text) ## [[1]] ## [1] 1 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[2]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[3]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[4]] ## [1] 11 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE regexpr() 함수의 결과를 11.1.5 regexec() 함수 regexec() 함수는 출력이 text와 길이가 같은 list라는 점에서 gregexpr()에 매우 가깝다. list의 각 요소는 일치의 시작 위치를 포함한다. 값이 -1이면 일치하는 항목이 없음을 나타낸다. 또한 list의 각 요소에는 일치 길이를 제공하는 “match.length” 속성이 있다(일치하지 않는 경우 -1): # some text text &lt;- c(&quot;one word&quot;, &quot;a sentence&quot;, &quot;you and me&quot;, &quot;three two one&quot;) # pattern pat &lt;- &quot;one&quot; # default usage regexec(pat, text) ## [[1]] ## [1] 1 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[2]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[3]] ## [1] -1 ## attr(,&quot;match.length&quot;) ## [1] -1 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE ## ## [[4]] ## [1] 11 ## attr(,&quot;match.length&quot;) ## [1] 3 ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE # handy function to extract matched term x &lt;- regexpr(pattern, text) substring(text, x, x + attr(x, &quot;match.length&quot;) - 1) # 부분 문자열 반환 ## [1] &quot;one&quot; &quot;&quot; &quot;&quot; &quot;one&quot; # with NA regexpr(pattern, c(text, NA)) ## [1] 1 -1 -1 11 NA ## attr(,&quot;match.length&quot;) ## [1] 3 -1 -1 3 NA ## attr(,&quot;index.type&quot;) ## [1] &quot;chars&quot; ## attr(,&quot;useBytes&quot;) ## [1] TRUE 11.2 패턴 대체 함수 때때로 주어진 문자열 벡터에서 패턴을 찾는 것이 우리가 원하는 전부이다. 그러나 한 패턴을 다른 패턴으로 대체하는 것에 관심이 있을 수도 있다. 이를 위해 대체 함수 sub() 함수와 gsub() 함수를 사용할 수 있다. sub() 함수와 gsub() 함수의 차이점은 전자가 패턴의 첫 번째 항목 만 대체하고 후자는 모든 일치 항목을 대체한다는 것이다. 대체 함수에는 일치하는 정규 표현식 pattern, 일치하는 패턴의 replacement 및 일치하는 text의 세 가지 주요 인수가 필요하다. 기본 사용법은 다음과 같다: `sub(pattern, replacement, text)` : 주어진 `text`에서 처음 나타나는 `pattern`을 `replacement`로 대체한다. `gsub(pattern, replacement, text)` : 11.2.1 sub() 함수를 이용한 첫 번째 일치의 대체 sub() 함수는 주어진 text에서 처음 나타나는 패턴을 대체한다. 즉, 문자열 벡터의 각 요소에 패턴이 여러 번 나타나면 첫 번째 패턴만 바꾸는 것이다. 예를 들어 다음과 같이 다양한 문자열을 포함하는 text 벡터가 있다고 가정하자: Rstring &lt;- c(&quot;The R Foundation&quot;, &quot;for Statistical Computing&quot;, &quot;R is FREE software&quot;, &quot;R is a collaborative project&quot;) 패턴 \"R\"을 새로운 패턴 \"RR\"로 바꾸는 것이 우리의 목표라고 상상해자. sub() 함수를 사용하면 다음과 같다: # string Rstring &lt;- c(&quot;The R Foundation&quot;, &quot;for Statistical Computing&quot;, &quot;R is FREE software&quot;, &quot;R is a collaborative project&quot;) # substitute &#39;R&#39; with &#39;RR&#39; sub(&quot;R&quot;, &quot;RR&quot;, Rstring) ## [1] &quot;The RR Foundation&quot; &quot;for Statistical Computing&quot; ## [3] &quot;RR is FREE software&quot; &quot;RR is a collaborative project&quot; 결과에서 문자 “R”의 첫 번째 항목만 text 벡터의 각 요소에서 바뀐다. 세 번째 요소에 있는 FREE라는 단어에도 “R”이 포함되어 있지만 대체되지 않았다. 이것은 첫 번째 패턴이 아니기 때문이다. 11.2.2 gsub() 함수를 이용한 모든 일치 대체 첫 번째 발생한 패턴만이 아니라 모든 일치하는 패턴을 대체하려면 gsub()를 사용해야 한다(종합적 대체). 마지막 예제와 동일한 벡터 Rstring과 pattern을 사용하여, gsub() 함수를 적용하면 다음과 같다: # string Rstring &lt;- c(&quot;The R Foundation&quot;, &quot;for Statistical Computing&quot;, &quot;R is FREE software&quot;, &quot;R is a collaborative project&quot;) # substitute gsub(&quot;R&quot;, &quot;RR&quot;, Rstring) ## [1] &quot;The RR Foundation&quot; &quot;for Statistical Computing&quot; ## [3] &quot;RR is FRREE software&quot; &quot;RR is a collaborative project&quot; Rstring의 세 번째 요소를 제외하고 sub()와 거의 동일하다. FREE 단어에서 R의 발생이 고려되어, gsub() 함수가 FREE를 FRREE로 변경하였다. 11.3 문자 벡터의 분할 패턴 찾기 및 패턴 대체 연산 외에도 패턴을 기반으로 문자열을 분할하는 또 다른 일반적인 작업이 있다. 이를 위해 R에는 strsplit() 함수가 있다. 이 함수는 정규 표현식의 일치에 따라 문자형 벡터의 요소를 하위 문자열로 분할하도록 설계되었다. 도움말 문서(help (strsplit))를 확인하면 strsplit() 함수의 기본적인 사용에 두 가지 주요 인수가 필요하다는 것을 알 수 있다. `strsplit(x, split)` x는 문자형 벡터이고 split은 정규 표현식 패턴이다. 그러나 다른 grep() 함수에서 사용했던 것과 같은 표기법을 유지하려면 x를 text로 그리고 pattern을 split으로 생각하는 것이 좋다. 이런 식으로 strsplit() 함수의 사용법을 다음과 같이 표현할 수 있다: `strsplit(text, pattern)` strsplit()을 사용할 수있는 일반적인 작업 중 하나는 문자열을 개별 구성 요소 (예 : 단어)로 나누려는 경우이다. 예를 들어, 주어진 문장 내에서 각 단어를 문자열로 분리하려면 빈 공간 \" \"을 분할 패턴(split)으로 지정하면된다. # a sentence sentence &lt;- c(&quot;R is a collaborative project with many contributors&quot;) # split into words strsplit(sentence, &quot; &quot;) ## [[1]] ## [1] &quot;R&quot; &quot;is&quot; &quot;a&quot; &quot;collaborative&quot; ## [5] &quot;project&quot; &quot;with&quot; &quot;many&quot; &quot;contributors&quot; 하나의 sentence 문자열이 strsplit() 함수에 의해 8 개의 벡터 요소로 분리되었다. 출력 형식은 list 형식이다. 또 다른 기본적인 예는 전화번호와 같이 대시(\"-\")로 연결된 숫자 세트를 부분적으로 분할하는 것이다: # telephone numbers tels &lt;- c(&quot;010-548-2##8&quot;, &quot;010-2##1-2440&quot;, &quot;010-7##2-1300&quot;) # split each number into its portions strsplit(tels, &quot;-&quot;) ## [[1]] ## [1] &quot;010&quot; &quot;548&quot; &quot;2##8&quot; ## ## [[2]] ## [1] &quot;010&quot; &quot;2##1&quot; &quot;2440&quot; ## ## [[3]] ## [1] &quot;010&quot; &quot;7##2&quot; &quot;1300&quot; 11.4 stringr 패키지 함수 이전 장에서는 정규식을 위한 R 의 stringr 패키지의 함수들에 대하여 간략하게 살펴보았다. 앞에서 언급했듯이 모든 stringr 패키지의 함수들은 공통적인 함수의 구조를 공유한다. `str_function(string, pattern)` 주요 두 인수는 처리 될 string 벡터와 일치하는 단일 pattern (예 : 정규 표현식)이다. 또한 모든 함수의 이름은 접두사 str_로 시작하고 처리할 행동의 이름이 온다. 예를 들어, 첫 번째 발생 위치를 찾으려면 str_locate(); 모든 일치하는 위치를 찾으려면 str_locate.all()을 사용한다. 11.4.1 str_detect() 함수를 이용한 패턴의 발견 string 벡터에 pattern이 있는지 여부를 감지하기 위해 str_detect() 함수를 사용할 수 있다. 실제로 이 함수는 grepl()와 유사하다. 즉, 결과는 논리형을 반환한다. library(stringr) # some objects some_objs &lt;- c(&quot;pen&quot;, &quot;pencil&quot;, &quot;marker&quot;, &quot;spray&quot;) # detect phones str_detect(some_objs, &quot;pen&quot;) ## [1] TRUE TRUE FALSE FALSE # select detected macthes some_objs[str_detect(some_objs, &quot;pen&quot;)] ## [1] &quot;pen&quot; &quot;pencil&quot; str_detect() 함수의 출력은 지정된 string과 길이가 같은 이진 벡터(TRUE/FALSE)이다. string에서 일치하는 항목이 발견되면 TRUE이고, 그렇지 않으면 FALSE이다. 다음은 pattern이 day-month-year의 날짜와 일치하는 더 정교한 예이다. # some strings strings &lt;- c(&quot;12 Jun 2002&quot;, &quot; 8 September 2004 &quot;, &quot;22-July-2009 &quot;, &quot;01 01 2001&quot;, &quot;date&quot;, &quot;02.06.2000&quot;, &quot;xxx-yyy-zzzz&quot;, &quot;$2,600&quot;) # date pattern (month as text) dates &lt;- &quot;([0-9]{1,2})[- .]([a-zA-Z]+)[- .]([0-9]{4})&quot; # detect dates str_detect(strings, dates) ## [1] TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE # select detected macthes strings[str_detect(strings, dates)] ## [1] &quot;12 Jun 2002&quot; &quot; 8 September 2004 &quot; &quot;22-July-2009 &quot; 11.4.2 str_extract() 함수를 이용한 첫 번째 일치 추출 pattern이 포함된 string을 추출하기 위해 str_extract() 함수를 사용할 수 있다. 실제로 이 함수는 주어진 pattern과 일치하는 string의 첫 번째 부분을 추출한다. 예를 들어 Paris에 대한 트윗이있는 문자형 벡터가 있고 해시 태그를 추출한다고 가정하자. # [a-zA-Z]{1}과 같은 #hashtag pattern을 정의하면 된다. # tweets about &#39;Paris&#39; paris_tweets &lt;- c( &quot;#Paris is chock-full of cultural and culinary attractions&quot;, &quot;Some time in #Paris along Canal St.-Martin famous by #Amelie&quot;, &quot;While you&#39;re in #Paris, stop at cafe: http://goo.gl/yaCbW&quot;, &quot;Paris, the city of light&quot;) # hashtag pattern hash &lt;- &quot;#[a-zA-Z]{1,}&quot; # extract (first) hashtag str_extract(paris_tweets, hash) ## [1] &quot;#Paris&quot; &quot;#Paris&quot; &quot;#Paris&quot; NA str_extract() 함수의 출력은 string 즉, paris_tweets와 길이가 같은 벡터이다. pattern과 일치하지 않는 요소는 NA로 표시된다. str_extract() 함수는 첫 번째 pattern하고만 일치한다. 두 번째 요소에 있는 \"#Amelie\" 해시 태그는 추출되지 않았다. 11.4.3 str_extract_all() 함수를 이용한 모든 일치 추출 str_extract() 함수이외에도 stringr 패키지는 str_extract_all() 함수를 제공한다. 함수의 이름에서 알 수 있듯이 str_extract_all() 함수를 사용하여 string 벡터의 모든 패턴을 추출한다. 출력 결과는 list 형이다. 이전 예제와 동일한 string을 사용하여 다음과 같이 모든 해시 태그 일치를 추출 할 수 있다. # extract (all) hashtags str_extract_all(paris_tweets, &quot;#[a-zA-Z]{1,}&quot;) ## [[1]] ## [1] &quot;#Paris&quot; ## ## [[2]] ## [1] &quot;#Paris&quot; &quot;#Amelie&quot; ## ## [[3]] ## [1] &quot;#Paris&quot; ## ## [[4]] ## character(0) str_extract() 함수와 비교하여 str_extract_all() 함수의 출력은 string과 동일한 길이의 list 형 이다. 또한 pattern과 일치하지 않는 요소는 NA 대신 빈 문자형 벡터 character (0)로 표시된다. 11.4.4 str_match() 함수를 이용한 첫 번째 일치 추출 str_extract() 함수와 밀접한 관련이 있는 함수로 stringr 패키지가 제공하는 또 다른 추출 함수는 str_match() 함수이다. 이 함수는 일치하는 패턴을 추출 할 뿐만 아니라, 일치하는 각 그룹을 정규 표현식 문자 클래스 패턴으로 표시한다. # string vector strings &lt;- c(&quot;12 Jun 2002&quot;, &quot; 8 September 2004 &quot;, &quot;22-July-2009 &quot;, &quot;01 01 2001&quot;, &quot;date&quot;, &quot;02.06.2000&quot;, &quot;xxx-yyy-zzzz&quot;, &quot;$2,600&quot;) # date pattern (month as text) dates &lt;- &quot;([0-9]{1,2})[- .]([a-zA-Z]+)[- .]([0-9]{4})&quot; # extract first matched group str_match(strings, dates) ## [,1] [,2] [,3] [,4] ## [1,] &quot;12 Jun 2002&quot; &quot;12&quot; &quot;Jun&quot; &quot;2002&quot; ## [2,] &quot;8 September 2004&quot; &quot;8&quot; &quot;September&quot; &quot;2004&quot; ## [3,] &quot;22-July-2009&quot; &quot;22&quot; &quot;July&quot; &quot;2009&quot; ## [4,] NA NA NA NA ## [5,] NA NA NA NA ## [6,] NA NA NA NA ## [7,] NA NA NA NA ## [8,] NA NA NA NA 출력은 벡터가 아니라 문자 행렬이다. 각각의 행은 첫 번째 열은 strings 요소가 패턴과 일치하는 경우 그 요소 값을 표시하고, 다른 열은 각각의 포착된 요소들을 표기하고 있다. dates 패턴과 일치하지 않는 요소의 경우는 NA로 출력이 된다. 11.4.5 str_match_all() 함수를 이용한 모든 일치 추출 우리가 찾고 있는 것이 string 벡터에서 모든 패턴을 추출하는 경우 str_extract() 함수 대신 str_extract_all() 함수를 사용해야 한다. # tweets about &#39;Paris&#39; paris_tweets &lt;- c( &quot;#Paris is chock-full of cultural and culinary attractions&quot;, &quot;Some time in #Paris along Canal St.-Martin famous by #Amelie&quot;, &quot;While you&#39;re in #Paris, stop at cafe: http://goo.gl/yaCbW&quot;, &quot;Paris, the city of light&quot;) # match (all) hashtags in &#39;paris_tweets&#39; str_match_all(paris_tweets, &quot;#[a-zA-Z]{1,}&quot;) ## [[1]] ## [,1] ## [1,] &quot;#Paris&quot; ## ## [[2]] ## [,1] ## [1,] &quot;#Paris&quot; ## [2,] &quot;#Amelie&quot; ## ## [[3]] ## [,1] ## [1,] &quot;#Paris&quot; ## ## [[4]] ## [,1] str_match () 함수와 비교하여 str_match_all() 함수의 출력은 list이다. 또한 list의 각 요소는 해시 태그와 일치하는 행의 수를 갖는 행렬이다. pattern과 일치하는 것이 없는 요소는 아무 것도 출력되지 않는다. 11.4.6 str_locate() 함수를 이용한 첫 번째 일치 위치 확인 정규 표현식 패턴을 감지, 추출 및 일치시키는 것 외에도 stringr 패키지는 패턴의 발생 위치를 찾을 수 있게 해준다. string 벡터에서 pattern의 첫 번째 발생 위치를 찾으려면 str_locate() 함수를 사용해야 한다. # tweets about &#39;Paris&#39; paris_tweets &lt;- c( &quot;#Paris is chock-full of cultural and culinary attractions&quot;, &quot;Some time in #Paris along Canal St.-Martin famous by #Amelie&quot;, &quot;While you&#39;re in #Paris, stop at cafe: http://goo.gl/yaCbW&quot;, &quot;Paris, the city of light&quot;) # locate position of (first) hashtag str_locate(paris_tweets, &quot;#[a-zA-Z]{1,}&quot;) ## start end ## [1,] 1 6 ## [2,] 14 19 ## [3,] 17 22 ## [4,] NA NA str_locate() 함수의 출력은 두 개의 열과 (string) 벡터의 요소 만큼의 행을 가지는 행렬이다. 출력의 첫 번째 열은 시작 위치(start)이고, 두 번째 열은 종료 위치(end)이다. 앞의 예에서 결과는 4행 2열의 행렬이다. 첫 번째 행은 첫 번째 트윗의 해시 태그에 해당하는데, 위치 1에서 시작하여 위치 6에서 끝나고 있음을 보여주고 있다. 두 번째 행은 두 번째 트윗의 해시 태그에 해당하며, 시작 위치는 14 번째 문자이고 끝 위치는 19 번째 문자이다. 네 번째 행은 네 번째 트윗에 해당하며, 해시 태그가 없으므로 해당 행의 값은 NA입니다. 11.4.7 str_locate_all() 함수를 이용한 모든 일치 위치 확인 string 벡터에서 첫 번째 패턴뿐만 아니라 모든 패턴의 발생 위치를 찾으려면 str_locate_all() 함수를 사용해야 한다. # tweets about &#39;Paris&#39; paris_tweets &lt;- c( &quot;#Paris is chock-full of cultural and culinary attractions&quot;, &quot;Some time in #Paris along Canal St.-Martin famous by #Amelie&quot;, &quot;While you&#39;re in #Paris, stop at cafe: http://goo.gl/yaCbW&quot;, &quot;Paris, the city of light&quot;) # locate (all) hashtags in &#39;paris_tweets&#39; str_locate_all(paris_tweets, &quot;#[a-zA-Z]{1,}&quot;) ## [[1]] ## start end ## [1,] 1 6 ## ## [[2]] ## start end ## [1,] 14 19 ## [2,] 54 60 ## ## [[3]] ## start end ## [1,] 17 22 ## ## [[4]] ## start end str_locate() 함수와 비교하여 str_locate_all() 함수의 출력은 제공된 string 벡터와 동일한 길이의 list 이다. 각 list의 요소는 차례로 두 개의 열을 갖는 행렬이다. pattern과 일치하지 않는 요소들은 NA 대신 아무것도 표시가 되지 않는다. str_locate_all() 함수를 Paris 트윗에 적용한 결과를 보면, 두 번째 요소에 #Paris와 #Amelie 해시 태그의 시작 및 끝 위치가 표시되어 있음을 알 수 있다. 결과적으로 네 번째 요소는 연관된 트윗에 해시 태그가 없음을 보여 주고 있다. 11.4.8 str_replace() 함수를 이용한 첫 번째 일치 대체 string 벡터에서 처음 일치하는 패턴을 대체하기 위해서는 str_replace() 함수를 사용할 수 있다. 사용법은 다음과 같다: `str_replace(string, pattern, replacement)` str_replace() 함수에는 string과 pattern 이라는 두 개의 인수 이외에도 replacement (대체)을 나타내는 세 번째 인수가 필요하다. San Francisco, Barcelona, Naples 그리고 Paris 등의 도시 이름이 벡터로 있다고 가정해 보자. 각 이름의 첫 번째 모음을 세미콜론(;)으로 바꾸려고 한다고 가정하자. 이를 수행하는 방법은 다음과 같다: # city names cities &lt;- c(&quot;San Francisco&quot;, &quot;Barcelona&quot;, &quot;Naples&quot;, &quot;Paris&quot;) # replace first matched vowel str_replace(cities, &quot;[aeiou]&quot;, &quot;;&quot;) # 각각의 도시명에서 첫번째 모음을 ;으로 바꿈 ## [1] &quot;S;n Francisco&quot; &quot;B;rcelona&quot; &quot;N;ples&quot; &quot;P;ris&quot; 이제 각 이름에서 첫 번째 자음을 바꿔 보자. 부정 클래스(negated class)로 패턴을 수정하면 된다: # replace first matched consonant str_replace(cities, &quot;[^aeiou]&quot;, &quot;;&quot;) ## [1] &quot;;an Francisco&quot; &quot;;arcelona&quot; &quot;;aples&quot; &quot;;aris&quot; 11.4.9 str_replace_all() 함수를 이용한 모든 일치 대체 string에서 일치하는 pattern의 모든 항목을 바꾸려면 str_replace_all() 함수를 사용할 수 있다. 다시 한 번 도시 이름(cities)을 가진 벡터를 고려하고 각 이름에 있는 모든 모음을 바꾸고 싶다고 가정 해 보자: # city names cities &lt;- c(&quot;San Francisco&quot;, &quot;Barcelona&quot;, &quot;Naples&quot;, &quot;Paris&quot;) # replace all matched vowel str_replace_all(cities, pattern = &quot;[aeiou]&quot;, &quot;;&quot;) ## [1] &quot;S;n Fr;nc;sc;&quot; &quot;B;rc;l;n;&quot; &quot;N;pl;s&quot; &quot;P;r;s&quot; 다른 방법으로, 각 이름에 있는 모든 자음을 세미콜론(;)으로 바꾸려면 pattern을 부정 클래스(^)인 \"[^aeiou]\"로 변경하면 된다. # replace all matched consonants str_replace_all(cities, pattern = &quot;[^aeiou]&quot;, &quot;;&quot;) ## [1] &quot;;a;;;;a;;i;;o&quot; &quot;;a;;e;o;a&quot; &quot;;a;;e;&quot; &quot;;a;i;&quot; 11.4.10 str_split() 함수를 이용한 문자열 분할 strsplit() 함수와 유사하게 stringr 패키지는 문자 벡터를 여러 조각으로 분리하는 str_split() 함수를 제공한다. 이 함수의 사용은 다음과 같은 형식을 따른다: `str_split(string, pattern, n = Inf)` 인수 n은 분할할 최대의 개수이다. 디폴트 값(n = Inf)은 가능한 모든 분할 위치가 사용됨을 의미한다. 하나의 문장을 개별 단어들로 나누고자 할 때, strsplit() 함수와 같은 예를 살펴보자: # a sentence sentence &lt;- c(&quot;R is a collaborative project with many contributors&quot;) # split into words str_split(sentence, &quot; &quot;) %&gt;% unlist() ## [1] &quot;R&quot; &quot;is&quot; &quot;a&quot; &quot;collaborative&quot; ## [5] &quot;project&quot; &quot;with&quot; &quot;many&quot; &quot;contributors&quot; 마찬가지로 “-”로 연결된 전화번호 숫자를 부분 부분 분리하여 보자. # telephone numbers tels &lt;- c(&quot;510-548-2238&quot;, &quot;707-231-2440&quot;, &quot;650-752-1300&quot;) # split each number into its portions str_split(tels, &quot;-&quot;) ## [[1]] ## [1] &quot;510&quot; &quot;548&quot; &quot;2238&quot; ## ## [[2]] ## [1] &quot;707&quot; &quot;231&quot; &quot;2440&quot; ## ## [[3]] ## [1] &quot;650&quot; &quot;752&quot; &quot;1300&quot; 결과는 문자형 벡터의 list 이다. string 벡터의 각 요소는 결과 list의 요소에 해당한다. list의 각 요소는 일치로부터 발생하는 분할 벡터 (즉, 분할 개수)를 포함할 것이다. 인수 n의 사용을 보여주기 위해, \"chocolate\", \"vanilla\", \"cinnamon\", \"mint\", 그리고 \"lemon\" 등을 요소로 하는 flavors벡터를 생각해 보자. 모음의 클래스([aeiou])를 pattern으로 정의하는 각 flavors 이름을 분할한다고 가정하자: # string flavors &lt;- c(&quot;chocolate&quot;, &quot;vanilla&quot;, &quot;cinnamon&quot;, &quot;mint&quot;, &quot;lemon&quot;) # split by vowels str_split(flavors, &quot;[aeiou]&quot;) ## [[1]] ## [1] &quot;ch&quot; &quot;c&quot; &quot;l&quot; &quot;t&quot; &quot;&quot; ## ## [[2]] ## [1] &quot;v&quot; &quot;n&quot; &quot;ll&quot; &quot;&quot; ## ## [[3]] ## [1] &quot;c&quot; &quot;nn&quot; &quot;m&quot; &quot;n&quot; ## ## [[4]] ## [1] &quot;m&quot; &quot;nt&quot; ## ## [[5]] ## [1] &quot;l&quot; &quot;m&quot; &quot;n&quot; 이제 최대 개수를 n = 2로 수정한다. 이는 str_split() 함수가 각 요소를 최대 2 개로 분할한다는 의미이다. 우리는 다음과 같은 결과를 얻을 것이다: # split by first vowel str_split(flavors, &quot;[aeiou]&quot;, n = 2) ## [[1]] ## [1] &quot;ch&quot; &quot;colate&quot; ## ## [[2]] ## [1] &quot;v&quot; &quot;nilla&quot; ## ## [[3]] ## [1] &quot;c&quot; &quot;nnamon&quot; ## ## [[4]] ## [1] &quot;m&quot; &quot;nt&quot; ## ## [[5]] ## [1] &quot;l&quot; &quot;mon&quot; 11.4.11 str_split_fixed() 함수를 이용한 문자열 분할 str_split() 함수 이외에도 string을 고정된 수의 조각으로 나누는 str_ split_fixed() 함수도 있다. 사용 형식은 다음과 같다: `str_split_fixed(string, pattern, n)` 인수 n에는 기본값이 없다. 다시 말해, 조각의 수를 나타내기 위해 정수를 지정해야 한다. 동일한 flavors 벡터와 일치하는 pattern으로 문자 “n”을 다시 고려하기로 한다. n = 2 인 str_split_fixed() 함수의 동작을 살펴보기로 한다. # string flavors &lt;- c(&quot;chocolate&quot;, &quot;vanilla&quot;, &quot;cinnamon&quot;, &quot;mint&quot;, &quot;lemon&quot;) # split flavors into 2 pieces str_split_fixed(flavors, &quot;n&quot;, 2) ## [,1] [,2] ## [1,] &quot;chocolate&quot; &quot;&quot; ## [2,] &quot;va&quot; &quot;illa&quot; ## [3,] &quot;ci&quot; &quot;namon&quot; ## [4,] &quot;mi&quot; &quot;t&quot; ## [5,] &quot;lemo&quot; &quot;&quot; 출력은 n = 2만큼 2개의 컬럼을 가진 문자 행렬이다. \"chocolate\"에는 문자 \"n\"이 포함되어 있지 않으므로 두 번째 열의 해당 값은 \"\"로 유지된다. 반대로 \"lemon\"과 관련된 두 번째 열의 값도 비어 있다. 그러나 이것은이 flavor가 \"lemo\"와 \"\"로 분리되기 때문이다. n의 값을 n = 3으로 변경하면 3 개의 열이있는 행렬이 생성된다. # split favors into 3 pieces str_split_fixed(flavors, &quot;n&quot;, 3) ## [,1] [,2] [,3] ## [1,] &quot;chocolate&quot; &quot;&quot; &quot;&quot; ## [2,] &quot;va&quot; &quot;illa&quot; &quot;&quot; ## [3,] &quot;ci&quot; &quot;&quot; &quot;amon&quot; ## [4,] &quot;mi&quot; &quot;t&quot; &quot;&quot; ## [5,] &quot;lemo&quot; &quot;&quot; &quot;&quot; "]]
